{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9feda6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import statistics\n",
    "import time\n",
    "#from imblearn.over_sampling import *\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest, AdaBoostClassifier, RandomForestRegressor, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support as score, recall_score\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, QuantileTransformer, StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# import umap\n",
    "from sklearn import tree\n",
    "#import graphviz\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Conv1DTranspose, Flatten, Dropout, Input, concatenate, LSTM,UpSampling1D, Reshape, TimeDistributed\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2947972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c109b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1e20d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_nd(a, window, steps = None, axis = None, gen_data = False):\n",
    "        \"\"\"\n",
    "        Create a windowed view over `n`-dimensional input that uses an \n",
    "        `m`-dimensional window, with `m <= n`\n",
    "        \n",
    "        Parameters\n",
    "        -------------\n",
    "        a : Array-like\n",
    "            The array to create the view on\n",
    "            \n",
    "        window : tuple or int\n",
    "            If int, the size of the window in `axis`, or in all dimensions if \n",
    "            `axis == None`\n",
    "            \n",
    "            If tuple, the shape of the desired window.  `window.size` must be:\n",
    "                equal to `len(axis)` if `axis != None`, else \n",
    "                equal to `len(a.shape)`, or \n",
    "                1\n",
    "                \n",
    "        steps : tuple, int or None\n",
    "            The offset between consecutive windows in desired dimension\n",
    "            If None, offset is one in all dimensions\n",
    "            If int, the offset for all windows over `axis`\n",
    "            If tuple, the steps along each `axis`.  \n",
    "                `len(steps)` must me equal to `len(axis)`\n",
    "    \n",
    "        axis : tuple, int or None\n",
    "            The axes over which to apply the window\n",
    "            If None, apply over all dimensions\n",
    "            if tuple or int, the dimensions over which to apply the window\n",
    "\n",
    "        gen_data : boolean\n",
    "            returns data needed for a generator\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        a_view : ndarray\n",
    "            A windowed view on the input array `a`, or `a, wshp`, where `whsp` is the window shape needed for creating the generator\n",
    "            \n",
    "        \"\"\"\n",
    "        ashp = np.array(a.shape)\n",
    "        \n",
    "        if axis != None:\n",
    "            axs = np.array(axis, ndmin = 1)\n",
    "            assert np.all(np.in1d(axs, np.arange(ashp.size))), \"Axes out of range\"\n",
    "        else:\n",
    "            axs = np.arange(ashp.size)\n",
    "            \n",
    "        window = np.array(window, ndmin = 1)\n",
    "        assert (window.size == axs.size) | (window.size == 1), \"Window dims and axes don't match\"\n",
    "        wshp = ashp.copy()\n",
    "        wshp[axs] = window\n",
    "        assert np.all(wshp <= ashp), \"Window is bigger than input array in axes\"\n",
    "        \n",
    "        stp = np.ones_like(ashp)\n",
    "        if steps:\n",
    "            steps = np.array(steps, ndmin = 1)\n",
    "            assert np.all(steps > 0), \"Only positive steps allowed\"\n",
    "            assert (steps.size == axs.size) | (steps.size == 1), \"Steps and axes don't match\"\n",
    "            stp[axs] = steps\n",
    "    \n",
    "        astr = np.array(a.strides)\n",
    "        \n",
    "        shape = tuple((ashp - wshp) // stp + 1) + tuple(wshp)\n",
    "        strides = tuple(astr * stp) + tuple(astr)\n",
    "        \n",
    "        as_strided = np.lib.stride_tricks.as_strided\n",
    "        a_view = np.squeeze(as_strided(a, \n",
    "                                     shape = shape, \n",
    "                                     strides = strides))\n",
    "        if gen_data :\n",
    "            return a_view, shape[:-wshp.size]\n",
    "        else:\n",
    "            return a_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "392a77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_mse_iqr(autoencoder,train_data):\n",
    "    if(\"pyod\" in str(type(autoencoder))):\n",
    "        return get_threshold_ml_score_iqr(autoencoder,train_data)\n",
    "    \n",
    "    train_predicted = autoencoder.predict(train_data,verbose=0)\n",
    "\n",
    "    mse = np.mean(np.mean(np.power(train_data - train_predicted, 2), axis=2),axis=1)\n",
    "    \n",
    "    iqr = np.quantile(mse,0.75) - np.quantile(mse, 0.25)\n",
    "    up_bound = np.quantile(mse,0.75) + 1.5*iqr\n",
    "    bottom_bound = np.quantile(mse,0.25) - 1.5*iqr\n",
    "    \n",
    "    thres = [up_bound,bottom_bound]\n",
    "    return thres\n",
    "\n",
    "def get_threshold_mse_percentage(autoencoder,train_data,outlier_percentage):\n",
    "    train_predicted = autoencoder.predict(train_data,verbose=0)\n",
    "    \n",
    "    mse = np.mean(np.mean(np.power(train_data - train_predicted, 2), axis=2),axis=1)\n",
    "    #mse = np.mean(np.power(train_data - train_predicted, 2),axis=1)\n",
    "    \n",
    "    thresh = np.quantile(mse, 1-outlier_percentage)\n",
    "    return [thresh]\n",
    "\n",
    "\n",
    "#Predict outliers in \"df\" using \"autoencoder\" model and \"threshold_mse\" as anomaly limit\n",
    "def detect_outliers(autoencoder, df, threshold_mse):\n",
    "    if(len(threshold_mse)==2):\n",
    "        return detect_outliers_range(autoencoder, df, threshold_mse)\n",
    "    pred=autoencoder.predict(df,verbose=0)\n",
    "\n",
    "    mse = np.mean(np.mean(np.power(df - pred, 2), axis=2),axis=1)\n",
    "    #mse = np.mean(np.power(df - pred, 2),axis=1)\n",
    "    \n",
    "    #mse_plot = mse[mse>np.percentile(mse,0.95)]\n",
    "    #plt.hist(mse_plot, bins=100)\n",
    "    #plt.show()\n",
    "    outliers = [(np.array(mse) < threshold_mse)]\n",
    "    return outliers\n",
    "\n",
    "\n",
    "\n",
    "def detect_outliers_range(autoencoder, df, threshold_mse):\n",
    "    pred=autoencoder.predict(df)\n",
    "\n",
    "    mse = np.mean(np.mean(np.power(df - pred, 2), axis=2),axis=1)\n",
    "    #mse = np.mean(np.power(df - pred, 2),axis=1)\n",
    "\n",
    "    up_bound = threshold_mse[0]\n",
    "    bottom_bound = threshold_mse[1]\n",
    "    outliers = [(np.array(mse) < up_bound)&(np.array(mse) > bottom_bound)]\n",
    "    #outliers = [(np.array(mse) < up_bound)]\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af74ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"./LwHBench/data/\"\n",
    "n_samples_device = 800  # 10000\n",
    "window = 10\n",
    "n_recursive_windows = 10\n",
    "jump = 10\n",
    "initial_window = window\n",
    "test_size = 0.2\n",
    "feat_list = list(range(5,18))\n",
    "feat_list.append(117)\n",
    "feat_list=[5,6,7,8,9,11,12,14,15,17,117]\n",
    "n_feat_selec = 15\n",
    "model_1 = \"3_\"\n",
    "model_2 = \"4_\"\n",
    "# Dataset to be read and processed\n",
    "mac_model_file = \"./LwHBench/MAC-Model.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "026a57a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "feat_gpu_e4_5f_01_53_3f_03\n"
     ]
    }
   ],
   "source": [
    "file_names=sorted(os.listdir(dataset_dir))\n",
    "df_dict={}\n",
    "for f in file_names:\n",
    "    print(f)\n",
    "    df_dict[f]=pd.read_csv(dataset_dir+f,index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abb176fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2013d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_model = {}\n",
    "with open(mac_model_file) as f:\n",
    "    for line in f:\n",
    "        p = line.split(\" \")\n",
    "        mac_model[p[0]] = p[3]\n",
    "for f in file_names:\n",
    "    df_dict[f][\"label\"] = df_dict[f][\"label\"].apply(lambda x: mac_model[str(x)]+ \"_\" + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "965666d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_labels={}\n",
    "for f in file_names:\n",
    "    df_labels[f] = df_dict[f][\"label\"]\n",
    "    df_dict[f] = df_dict[f].iloc[:,2:-1]#[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece9536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96d0e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_train={}\n",
    "df_dict_test={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad645ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in file_names:\n",
    "    train_idx, test_idx = next(StratifiedKFold(n_splits=5).split(df_dict[f],df_labels[f]))\n",
    "    df_dict_train[f], df_dict_test[f] = df_dict[f].iloc[train_idx], df_dict[f].iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "292f8224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu_sleep_1s</th>\n",
       "      <th>cpu_sleep_2s</th>\n",
       "      <th>cpu_sleep_5s</th>\n",
       "      <th>cpu_sleep_10s</th>\n",
       "      <th>cpu_sleep_120s</th>\n",
       "      <th>cpu_hash</th>\n",
       "      <th>cpu_pseudorandom</th>\n",
       "      <th>cpu_urandom</th>\n",
       "      <th>cpu_fib</th>\n",
       "      <th>gpu_matrixmul</th>\n",
       "      <th>gpu_sum</th>\n",
       "      <th>gpu_scopy</th>\n",
       "      <th>mem_list</th>\n",
       "      <th>mem_reserve</th>\n",
       "      <th>mem_csvread</th>\n",
       "      <th>storage_read_1</th>\n",
       "      <th>storage_read_2</th>\n",
       "      <th>storage_read_3</th>\n",
       "      <th>storage_read_4</th>\n",
       "      <th>storage_read_5</th>\n",
       "      <th>storage_read_6</th>\n",
       "      <th>storage_read_7</th>\n",
       "      <th>storage_read_8</th>\n",
       "      <th>storage_read_9</th>\n",
       "      <th>storage_read_10</th>\n",
       "      <th>storage_read_11</th>\n",
       "      <th>storage_read_12</th>\n",
       "      <th>storage_read_13</th>\n",
       "      <th>storage_read_14</th>\n",
       "      <th>storage_read_15</th>\n",
       "      <th>storage_read_16</th>\n",
       "      <th>storage_read_17</th>\n",
       "      <th>storage_read_18</th>\n",
       "      <th>storage_read_19</th>\n",
       "      <th>storage_read_20</th>\n",
       "      <th>storage_read_21</th>\n",
       "      <th>storage_read_22</th>\n",
       "      <th>storage_read_23</th>\n",
       "      <th>storage_read_24</th>\n",
       "      <th>storage_read_25</th>\n",
       "      <th>storage_read_26</th>\n",
       "      <th>storage_read_27</th>\n",
       "      <th>storage_read_28</th>\n",
       "      <th>storage_read_29</th>\n",
       "      <th>storage_read_30</th>\n",
       "      <th>storage_read_31</th>\n",
       "      <th>storage_read_32</th>\n",
       "      <th>storage_read_33</th>\n",
       "      <th>storage_read_34</th>\n",
       "      <th>storage_read_35</th>\n",
       "      <th>storage_read_36</th>\n",
       "      <th>storage_read_37</th>\n",
       "      <th>storage_read_38</th>\n",
       "      <th>storage_read_39</th>\n",
       "      <th>storage_read_40</th>\n",
       "      <th>storage_read_41</th>\n",
       "      <th>storage_read_42</th>\n",
       "      <th>storage_read_43</th>\n",
       "      <th>storage_read_44</th>\n",
       "      <th>storage_read_45</th>\n",
       "      <th>storage_read_46</th>\n",
       "      <th>storage_read_47</th>\n",
       "      <th>storage_read_48</th>\n",
       "      <th>storage_read_49</th>\n",
       "      <th>storage_read_50</th>\n",
       "      <th>storage_read_51</th>\n",
       "      <th>storage_read_52</th>\n",
       "      <th>storage_read_53</th>\n",
       "      <th>storage_read_54</th>\n",
       "      <th>storage_read_55</th>\n",
       "      <th>storage_read_56</th>\n",
       "      <th>storage_read_57</th>\n",
       "      <th>storage_read_58</th>\n",
       "      <th>storage_read_59</th>\n",
       "      <th>storage_read_60</th>\n",
       "      <th>storage_read_61</th>\n",
       "      <th>storage_read_62</th>\n",
       "      <th>storage_read_63</th>\n",
       "      <th>storage_read_64</th>\n",
       "      <th>storage_read_65</th>\n",
       "      <th>storage_read_66</th>\n",
       "      <th>storage_read_67</th>\n",
       "      <th>storage_read_68</th>\n",
       "      <th>storage_read_69</th>\n",
       "      <th>storage_read_70</th>\n",
       "      <th>storage_read_71</th>\n",
       "      <th>storage_read_72</th>\n",
       "      <th>storage_read_73</th>\n",
       "      <th>storage_read_74</th>\n",
       "      <th>storage_read_75</th>\n",
       "      <th>storage_read_76</th>\n",
       "      <th>storage_read_77</th>\n",
       "      <th>storage_read_78</th>\n",
       "      <th>storage_read_79</th>\n",
       "      <th>storage_read_80</th>\n",
       "      <th>storage_read_81</th>\n",
       "      <th>storage_read_82</th>\n",
       "      <th>storage_read_83</th>\n",
       "      <th>storage_read_84</th>\n",
       "      <th>storage_read_85</th>\n",
       "      <th>storage_read_86</th>\n",
       "      <th>storage_read_87</th>\n",
       "      <th>storage_read_88</th>\n",
       "      <th>storage_read_89</th>\n",
       "      <th>storage_read_90</th>\n",
       "      <th>storage_read_91</th>\n",
       "      <th>storage_read_92</th>\n",
       "      <th>storage_read_93</th>\n",
       "      <th>storage_read_94</th>\n",
       "      <th>storage_read_95</th>\n",
       "      <th>storage_read_96</th>\n",
       "      <th>storage_read_97</th>\n",
       "      <th>storage_read_98</th>\n",
       "      <th>storage_read_99</th>\n",
       "      <th>storage_read_100</th>\n",
       "      <th>storage_write_1</th>\n",
       "      <th>storage_write_2</th>\n",
       "      <th>storage_write_3</th>\n",
       "      <th>storage_write_4</th>\n",
       "      <th>storage_write_5</th>\n",
       "      <th>storage_write_6</th>\n",
       "      <th>storage_write_7</th>\n",
       "      <th>storage_write_8</th>\n",
       "      <th>storage_write_9</th>\n",
       "      <th>storage_write_10</th>\n",
       "      <th>storage_write_11</th>\n",
       "      <th>storage_write_12</th>\n",
       "      <th>storage_write_13</th>\n",
       "      <th>storage_write_14</th>\n",
       "      <th>storage_write_15</th>\n",
       "      <th>storage_write_16</th>\n",
       "      <th>storage_write_17</th>\n",
       "      <th>storage_write_18</th>\n",
       "      <th>storage_write_19</th>\n",
       "      <th>storage_write_20</th>\n",
       "      <th>storage_write_21</th>\n",
       "      <th>storage_write_22</th>\n",
       "      <th>storage_write_23</th>\n",
       "      <th>storage_write_24</th>\n",
       "      <th>storage_write_25</th>\n",
       "      <th>storage_write_26</th>\n",
       "      <th>storage_write_27</th>\n",
       "      <th>storage_write_28</th>\n",
       "      <th>storage_write_29</th>\n",
       "      <th>storage_write_30</th>\n",
       "      <th>storage_write_31</th>\n",
       "      <th>storage_write_32</th>\n",
       "      <th>storage_write_33</th>\n",
       "      <th>storage_write_34</th>\n",
       "      <th>storage_write_35</th>\n",
       "      <th>storage_write_36</th>\n",
       "      <th>storage_write_37</th>\n",
       "      <th>storage_write_38</th>\n",
       "      <th>storage_write_39</th>\n",
       "      <th>storage_write_40</th>\n",
       "      <th>storage_write_41</th>\n",
       "      <th>storage_write_42</th>\n",
       "      <th>storage_write_43</th>\n",
       "      <th>storage_write_44</th>\n",
       "      <th>storage_write_45</th>\n",
       "      <th>storage_write_46</th>\n",
       "      <th>storage_write_47</th>\n",
       "      <th>storage_write_48</th>\n",
       "      <th>storage_write_49</th>\n",
       "      <th>storage_write_50</th>\n",
       "      <th>storage_write_51</th>\n",
       "      <th>storage_write_52</th>\n",
       "      <th>storage_write_53</th>\n",
       "      <th>storage_write_54</th>\n",
       "      <th>storage_write_55</th>\n",
       "      <th>storage_write_56</th>\n",
       "      <th>storage_write_57</th>\n",
       "      <th>storage_write_58</th>\n",
       "      <th>storage_write_59</th>\n",
       "      <th>storage_write_60</th>\n",
       "      <th>storage_write_61</th>\n",
       "      <th>storage_write_62</th>\n",
       "      <th>storage_write_63</th>\n",
       "      <th>storage_write_64</th>\n",
       "      <th>storage_write_65</th>\n",
       "      <th>storage_write_66</th>\n",
       "      <th>storage_write_67</th>\n",
       "      <th>storage_write_68</th>\n",
       "      <th>storage_write_69</th>\n",
       "      <th>storage_write_70</th>\n",
       "      <th>storage_write_71</th>\n",
       "      <th>storage_write_72</th>\n",
       "      <th>storage_write_73</th>\n",
       "      <th>storage_write_74</th>\n",
       "      <th>storage_write_75</th>\n",
       "      <th>storage_write_76</th>\n",
       "      <th>storage_write_77</th>\n",
       "      <th>storage_write_78</th>\n",
       "      <th>storage_write_79</th>\n",
       "      <th>storage_write_80</th>\n",
       "      <th>storage_write_81</th>\n",
       "      <th>storage_write_82</th>\n",
       "      <th>storage_write_83</th>\n",
       "      <th>storage_write_84</th>\n",
       "      <th>storage_write_85</th>\n",
       "      <th>storage_write_86</th>\n",
       "      <th>storage_write_87</th>\n",
       "      <th>storage_write_88</th>\n",
       "      <th>storage_write_89</th>\n",
       "      <th>storage_write_90</th>\n",
       "      <th>storage_write_91</th>\n",
       "      <th>storage_write_92</th>\n",
       "      <th>storage_write_93</th>\n",
       "      <th>storage_write_94</th>\n",
       "      <th>storage_write_95</th>\n",
       "      <th>storage_write_96</th>\n",
       "      <th>storage_write_97</th>\n",
       "      <th>storage_write_98</th>\n",
       "      <th>storage_write_99</th>\n",
       "      <th>storage_write_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10349</th>\n",
       "      <td>500.040883</td>\n",
       "      <td>1000.037750</td>\n",
       "      <td>2500.063642</td>\n",
       "      <td>705.127493</td>\n",
       "      <td>4166.311095</td>\n",
       "      <td>43243</td>\n",
       "      <td>18734</td>\n",
       "      <td>2757221312</td>\n",
       "      <td>3642399</td>\n",
       "      <td>552160088</td>\n",
       "      <td>19131818</td>\n",
       "      <td>29319986</td>\n",
       "      <td>807211</td>\n",
       "      <td>286972957</td>\n",
       "      <td>36634049</td>\n",
       "      <td>10956195</td>\n",
       "      <td>8879891</td>\n",
       "      <td>10534201</td>\n",
       "      <td>10324112</td>\n",
       "      <td>10279520</td>\n",
       "      <td>12725391</td>\n",
       "      <td>8485656</td>\n",
       "      <td>8849984</td>\n",
       "      <td>10541404</td>\n",
       "      <td>10826660</td>\n",
       "      <td>8563748</td>\n",
       "      <td>11004380</td>\n",
       "      <td>8680561</td>\n",
       "      <td>8872650</td>\n",
       "      <td>8740967</td>\n",
       "      <td>10861548</td>\n",
       "      <td>8302880</td>\n",
       "      <td>10621681</td>\n",
       "      <td>8135847</td>\n",
       "      <td>8250622</td>\n",
       "      <td>9552474</td>\n",
       "      <td>8295178</td>\n",
       "      <td>8207197</td>\n",
       "      <td>10453517</td>\n",
       "      <td>8250382</td>\n",
       "      <td>8506175</td>\n",
       "      <td>8602413</td>\n",
       "      <td>8409657</td>\n",
       "      <td>10415962</td>\n",
       "      <td>12601356</td>\n",
       "      <td>8167587</td>\n",
       "      <td>6137634</td>\n",
       "      <td>5492829</td>\n",
       "      <td>5998544</td>\n",
       "      <td>5891860</td>\n",
       "      <td>7814591</td>\n",
       "      <td>5529272</td>\n",
       "      <td>6217429</td>\n",
       "      <td>5991803</td>\n",
       "      <td>6185449</td>\n",
       "      <td>6902642</td>\n",
       "      <td>5980136</td>\n",
       "      <td>7421468</td>\n",
       "      <td>5681677</td>\n",
       "      <td>5966192</td>\n",
       "      <td>6109616</td>\n",
       "      <td>7567891</td>\n",
       "      <td>5846990</td>\n",
       "      <td>6112060</td>\n",
       "      <td>97310474</td>\n",
       "      <td>17336658</td>\n",
       "      <td>13796783</td>\n",
       "      <td>18713268</td>\n",
       "      <td>19894066</td>\n",
       "      <td>18332663</td>\n",
       "      <td>14661660</td>\n",
       "      <td>19257501</td>\n",
       "      <td>15475056</td>\n",
       "      <td>8225753</td>\n",
       "      <td>10487868</td>\n",
       "      <td>8711097</td>\n",
       "      <td>13304050</td>\n",
       "      <td>8412879</td>\n",
       "      <td>10373481</td>\n",
       "      <td>10470535</td>\n",
       "      <td>16536448</td>\n",
       "      <td>8223530</td>\n",
       "      <td>10340000</td>\n",
       "      <td>10688828</td>\n",
       "      <td>8955038</td>\n",
       "      <td>12202825</td>\n",
       "      <td>10595663</td>\n",
       "      <td>8486823</td>\n",
       "      <td>8729727</td>\n",
       "      <td>16683279</td>\n",
       "      <td>8353251</td>\n",
       "      <td>10586755</td>\n",
       "      <td>10801437</td>\n",
       "      <td>12082993</td>\n",
       "      <td>8381621</td>\n",
       "      <td>8410435</td>\n",
       "      <td>8652209</td>\n",
       "      <td>8350547</td>\n",
       "      <td>14692345</td>\n",
       "      <td>8516878</td>\n",
       "      <td>8561044</td>\n",
       "      <td>10250409</td>\n",
       "      <td>13190273</td>\n",
       "      <td>8769430</td>\n",
       "      <td>10986805</td>\n",
       "      <td>8454508</td>\n",
       "      <td>10891473</td>\n",
       "      <td>8417138</td>\n",
       "      <td>8533933</td>\n",
       "      <td>10391721</td>\n",
       "      <td>35806246</td>\n",
       "      <td>8826651</td>\n",
       "      <td>8717912</td>\n",
       "      <td>8454972</td>\n",
       "      <td>8442490</td>\n",
       "      <td>216608</td>\n",
       "      <td>202423</td>\n",
       "      <td>195257</td>\n",
       "      <td>187535</td>\n",
       "      <td>188441</td>\n",
       "      <td>187998</td>\n",
       "      <td>185386</td>\n",
       "      <td>184164</td>\n",
       "      <td>190424</td>\n",
       "      <td>184905</td>\n",
       "      <td>234738</td>\n",
       "      <td>190812</td>\n",
       "      <td>185016</td>\n",
       "      <td>184960</td>\n",
       "      <td>182534</td>\n",
       "      <td>181294</td>\n",
       "      <td>187220</td>\n",
       "      <td>186405</td>\n",
       "      <td>184331</td>\n",
       "      <td>184867</td>\n",
       "      <td>184127</td>\n",
       "      <td>183127</td>\n",
       "      <td>184368</td>\n",
       "      <td>179942</td>\n",
       "      <td>185590</td>\n",
       "      <td>180812</td>\n",
       "      <td>187738</td>\n",
       "      <td>181571</td>\n",
       "      <td>185072</td>\n",
       "      <td>182701</td>\n",
       "      <td>185887</td>\n",
       "      <td>180683</td>\n",
       "      <td>183812</td>\n",
       "      <td>182349</td>\n",
       "      <td>186627</td>\n",
       "      <td>185127</td>\n",
       "      <td>188553</td>\n",
       "      <td>179979</td>\n",
       "      <td>182942</td>\n",
       "      <td>180090</td>\n",
       "      <td>186405</td>\n",
       "      <td>180739</td>\n",
       "      <td>183220</td>\n",
       "      <td>178831</td>\n",
       "      <td>185645</td>\n",
       "      <td>184090</td>\n",
       "      <td>184997</td>\n",
       "      <td>183960</td>\n",
       "      <td>181072</td>\n",
       "      <td>180219</td>\n",
       "      <td>183164</td>\n",
       "      <td>179720</td>\n",
       "      <td>182590</td>\n",
       "      <td>178016</td>\n",
       "      <td>185756</td>\n",
       "      <td>176349</td>\n",
       "      <td>186572</td>\n",
       "      <td>179294</td>\n",
       "      <td>181867</td>\n",
       "      <td>180757</td>\n",
       "      <td>183405</td>\n",
       "      <td>179349</td>\n",
       "      <td>190164</td>\n",
       "      <td>214423</td>\n",
       "      <td>182849</td>\n",
       "      <td>181349</td>\n",
       "      <td>187923</td>\n",
       "      <td>181405</td>\n",
       "      <td>183738</td>\n",
       "      <td>180923</td>\n",
       "      <td>185738</td>\n",
       "      <td>177868</td>\n",
       "      <td>184535</td>\n",
       "      <td>182442</td>\n",
       "      <td>182109</td>\n",
       "      <td>181052</td>\n",
       "      <td>184201</td>\n",
       "      <td>179794</td>\n",
       "      <td>184720</td>\n",
       "      <td>181312</td>\n",
       "      <td>184979</td>\n",
       "      <td>179997</td>\n",
       "      <td>181905</td>\n",
       "      <td>180664</td>\n",
       "      <td>183924</td>\n",
       "      <td>178368</td>\n",
       "      <td>186034</td>\n",
       "      <td>179776</td>\n",
       "      <td>184590</td>\n",
       "      <td>181035</td>\n",
       "      <td>180219</td>\n",
       "      <td>180997</td>\n",
       "      <td>185664</td>\n",
       "      <td>179367</td>\n",
       "      <td>184960</td>\n",
       "      <td>180924</td>\n",
       "      <td>185590</td>\n",
       "      <td>180720</td>\n",
       "      <td>183368</td>\n",
       "      <td>179145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10350</th>\n",
       "      <td>500.043892</td>\n",
       "      <td>1000.049142</td>\n",
       "      <td>2500.060357</td>\n",
       "      <td>705.128289</td>\n",
       "      <td>4166.333592</td>\n",
       "      <td>42912</td>\n",
       "      <td>18630</td>\n",
       "      <td>2755367052</td>\n",
       "      <td>3601859</td>\n",
       "      <td>568743733</td>\n",
       "      <td>19298939</td>\n",
       "      <td>29348125</td>\n",
       "      <td>833581</td>\n",
       "      <td>286450666</td>\n",
       "      <td>36525075</td>\n",
       "      <td>10795582</td>\n",
       "      <td>9772153</td>\n",
       "      <td>8823315</td>\n",
       "      <td>10422384</td>\n",
       "      <td>15996450</td>\n",
       "      <td>38316159</td>\n",
       "      <td>12400058</td>\n",
       "      <td>8424617</td>\n",
       "      <td>14942744</td>\n",
       "      <td>10697621</td>\n",
       "      <td>11156077</td>\n",
       "      <td>8476227</td>\n",
       "      <td>12822886</td>\n",
       "      <td>8509727</td>\n",
       "      <td>8604929</td>\n",
       "      <td>8468505</td>\n",
       "      <td>10756490</td>\n",
       "      <td>14898819</td>\n",
       "      <td>10789249</td>\n",
       "      <td>8433821</td>\n",
       "      <td>8444746</td>\n",
       "      <td>12655759</td>\n",
       "      <td>11120207</td>\n",
       "      <td>8535319</td>\n",
       "      <td>8449709</td>\n",
       "      <td>12146284</td>\n",
       "      <td>8657799</td>\n",
       "      <td>38305863</td>\n",
       "      <td>10510586</td>\n",
       "      <td>11589089</td>\n",
       "      <td>8958665</td>\n",
       "      <td>8582374</td>\n",
       "      <td>8519690</td>\n",
       "      <td>8638781</td>\n",
       "      <td>42290935</td>\n",
       "      <td>8383710</td>\n",
       "      <td>8366525</td>\n",
       "      <td>10543327</td>\n",
       "      <td>13446729</td>\n",
       "      <td>8562244</td>\n",
       "      <td>11058375</td>\n",
       "      <td>8488875</td>\n",
       "      <td>12396652</td>\n",
       "      <td>10391459</td>\n",
       "      <td>10351811</td>\n",
       "      <td>10561641</td>\n",
       "      <td>12953847</td>\n",
       "      <td>12409115</td>\n",
       "      <td>10677140</td>\n",
       "      <td>8804297</td>\n",
       "      <td>8901499</td>\n",
       "      <td>11119837</td>\n",
       "      <td>10872655</td>\n",
       "      <td>8407654</td>\n",
       "      <td>8264675</td>\n",
       "      <td>10957710</td>\n",
       "      <td>8384802</td>\n",
       "      <td>8519338</td>\n",
       "      <td>10820045</td>\n",
       "      <td>11123633</td>\n",
       "      <td>8390562</td>\n",
       "      <td>8462875</td>\n",
       "      <td>10507050</td>\n",
       "      <td>10178128</td>\n",
       "      <td>16382574</td>\n",
       "      <td>8761501</td>\n",
       "      <td>10717954</td>\n",
       "      <td>8531560</td>\n",
       "      <td>10897303</td>\n",
       "      <td>10484143</td>\n",
       "      <td>12811571</td>\n",
       "      <td>8488820</td>\n",
       "      <td>15389367</td>\n",
       "      <td>8672187</td>\n",
       "      <td>8966090</td>\n",
       "      <td>8564948</td>\n",
       "      <td>10642362</td>\n",
       "      <td>10904969</td>\n",
       "      <td>10565104</td>\n",
       "      <td>8309026</td>\n",
       "      <td>8398710</td>\n",
       "      <td>11412777</td>\n",
       "      <td>11117744</td>\n",
       "      <td>10269720</td>\n",
       "      <td>10484975</td>\n",
       "      <td>12959735</td>\n",
       "      <td>8814519</td>\n",
       "      <td>8323007</td>\n",
       "      <td>12631073</td>\n",
       "      <td>10974987</td>\n",
       "      <td>8929813</td>\n",
       "      <td>8664836</td>\n",
       "      <td>8474154</td>\n",
       "      <td>10504975</td>\n",
       "      <td>15641122</td>\n",
       "      <td>8475338</td>\n",
       "      <td>8388229</td>\n",
       "      <td>8444432</td>\n",
       "      <td>11467017</td>\n",
       "      <td>8686724</td>\n",
       "      <td>230811</td>\n",
       "      <td>202367</td>\n",
       "      <td>189571</td>\n",
       "      <td>187479</td>\n",
       "      <td>189404</td>\n",
       "      <td>188516</td>\n",
       "      <td>186590</td>\n",
       "      <td>185831</td>\n",
       "      <td>189256</td>\n",
       "      <td>186034</td>\n",
       "      <td>181015</td>\n",
       "      <td>184330</td>\n",
       "      <td>186312</td>\n",
       "      <td>183089</td>\n",
       "      <td>185571</td>\n",
       "      <td>184053</td>\n",
       "      <td>183645</td>\n",
       "      <td>186404</td>\n",
       "      <td>183793</td>\n",
       "      <td>184627</td>\n",
       "      <td>183035</td>\n",
       "      <td>185442</td>\n",
       "      <td>183108</td>\n",
       "      <td>184479</td>\n",
       "      <td>185757</td>\n",
       "      <td>184867</td>\n",
       "      <td>230330</td>\n",
       "      <td>190961</td>\n",
       "      <td>184498</td>\n",
       "      <td>178442</td>\n",
       "      <td>183404</td>\n",
       "      <td>184793</td>\n",
       "      <td>186887</td>\n",
       "      <td>185182</td>\n",
       "      <td>183479</td>\n",
       "      <td>184590</td>\n",
       "      <td>181682</td>\n",
       "      <td>182794</td>\n",
       "      <td>184108</td>\n",
       "      <td>183719</td>\n",
       "      <td>183294</td>\n",
       "      <td>185108</td>\n",
       "      <td>182034</td>\n",
       "      <td>174942</td>\n",
       "      <td>183405</td>\n",
       "      <td>184367</td>\n",
       "      <td>190534</td>\n",
       "      <td>185757</td>\n",
       "      <td>180979</td>\n",
       "      <td>182867</td>\n",
       "      <td>187016</td>\n",
       "      <td>184145</td>\n",
       "      <td>183961</td>\n",
       "      <td>185645</td>\n",
       "      <td>186182</td>\n",
       "      <td>184608</td>\n",
       "      <td>184257</td>\n",
       "      <td>183905</td>\n",
       "      <td>186294</td>\n",
       "      <td>182738</td>\n",
       "      <td>184794</td>\n",
       "      <td>182867</td>\n",
       "      <td>185793</td>\n",
       "      <td>183923</td>\n",
       "      <td>182793</td>\n",
       "      <td>184905</td>\n",
       "      <td>182367</td>\n",
       "      <td>184072</td>\n",
       "      <td>186182</td>\n",
       "      <td>184793</td>\n",
       "      <td>183164</td>\n",
       "      <td>182553</td>\n",
       "      <td>181757</td>\n",
       "      <td>184275</td>\n",
       "      <td>185516</td>\n",
       "      <td>181664</td>\n",
       "      <td>183868</td>\n",
       "      <td>183072</td>\n",
       "      <td>184145</td>\n",
       "      <td>183553</td>\n",
       "      <td>208700</td>\n",
       "      <td>188146</td>\n",
       "      <td>184849</td>\n",
       "      <td>183627</td>\n",
       "      <td>186109</td>\n",
       "      <td>183238</td>\n",
       "      <td>183701</td>\n",
       "      <td>184553</td>\n",
       "      <td>185053</td>\n",
       "      <td>184497</td>\n",
       "      <td>182794</td>\n",
       "      <td>184664</td>\n",
       "      <td>180312</td>\n",
       "      <td>182998</td>\n",
       "      <td>184719</td>\n",
       "      <td>182145</td>\n",
       "      <td>184886</td>\n",
       "      <td>182090</td>\n",
       "      <td>184664</td>\n",
       "      <td>185682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10351</th>\n",
       "      <td>500.039681</td>\n",
       "      <td>1000.038321</td>\n",
       "      <td>2500.063183</td>\n",
       "      <td>705.129506</td>\n",
       "      <td>4166.352651</td>\n",
       "      <td>43262</td>\n",
       "      <td>18591</td>\n",
       "      <td>2753894653</td>\n",
       "      <td>3553273</td>\n",
       "      <td>569251160</td>\n",
       "      <td>19136788</td>\n",
       "      <td>30155809</td>\n",
       "      <td>807395</td>\n",
       "      <td>286975644</td>\n",
       "      <td>36466956</td>\n",
       "      <td>10553972</td>\n",
       "      <td>11369034</td>\n",
       "      <td>11923137</td>\n",
       "      <td>9033180</td>\n",
       "      <td>137116065</td>\n",
       "      <td>9458322</td>\n",
       "      <td>8654037</td>\n",
       "      <td>8839646</td>\n",
       "      <td>8192674</td>\n",
       "      <td>10194200</td>\n",
       "      <td>12287687</td>\n",
       "      <td>8653316</td>\n",
       "      <td>8610649</td>\n",
       "      <td>8500226</td>\n",
       "      <td>8475466</td>\n",
       "      <td>8650575</td>\n",
       "      <td>12449315</td>\n",
       "      <td>8355542</td>\n",
       "      <td>8403412</td>\n",
       "      <td>8565428</td>\n",
       "      <td>8799498</td>\n",
       "      <td>8681259</td>\n",
       "      <td>19021753</td>\n",
       "      <td>8826646</td>\n",
       "      <td>8220285</td>\n",
       "      <td>8392819</td>\n",
       "      <td>10618471</td>\n",
       "      <td>8873146</td>\n",
       "      <td>10709359</td>\n",
       "      <td>10419030</td>\n",
       "      <td>10470269</td>\n",
       "      <td>10877893</td>\n",
       "      <td>8066287</td>\n",
       "      <td>8223229</td>\n",
       "      <td>10504103</td>\n",
       "      <td>8735648</td>\n",
       "      <td>8158064</td>\n",
       "      <td>8133157</td>\n",
       "      <td>8239803</td>\n",
       "      <td>8644667</td>\n",
       "      <td>12644237</td>\n",
       "      <td>8358060</td>\n",
       "      <td>8225970</td>\n",
       "      <td>8660389</td>\n",
       "      <td>8518447</td>\n",
       "      <td>8504429</td>\n",
       "      <td>12533369</td>\n",
       "      <td>8689333</td>\n",
       "      <td>8477762</td>\n",
       "      <td>11506495</td>\n",
       "      <td>8358542</td>\n",
       "      <td>8709241</td>\n",
       "      <td>10614027</td>\n",
       "      <td>11632215</td>\n",
       "      <td>8550261</td>\n",
       "      <td>8873256</td>\n",
       "      <td>8482540</td>\n",
       "      <td>8532818</td>\n",
       "      <td>15824394</td>\n",
       "      <td>8830350</td>\n",
       "      <td>8485058</td>\n",
       "      <td>8497595</td>\n",
       "      <td>11886693</td>\n",
       "      <td>8894422</td>\n",
       "      <td>10706747</td>\n",
       "      <td>8527169</td>\n",
       "      <td>11778510</td>\n",
       "      <td>8781740</td>\n",
       "      <td>8727389</td>\n",
       "      <td>8651815</td>\n",
       "      <td>16139815</td>\n",
       "      <td>8840701</td>\n",
       "      <td>10429474</td>\n",
       "      <td>10289087</td>\n",
       "      <td>10259087</td>\n",
       "      <td>15087479</td>\n",
       "      <td>12543331</td>\n",
       "      <td>8513447</td>\n",
       "      <td>8334728</td>\n",
       "      <td>49994365</td>\n",
       "      <td>8215618</td>\n",
       "      <td>8604742</td>\n",
       "      <td>10609323</td>\n",
       "      <td>12144078</td>\n",
       "      <td>8253432</td>\n",
       "      <td>8037491</td>\n",
       "      <td>19018142</td>\n",
       "      <td>8976236</td>\n",
       "      <td>14604671</td>\n",
       "      <td>8491854</td>\n",
       "      <td>8458781</td>\n",
       "      <td>8644519</td>\n",
       "      <td>12173688</td>\n",
       "      <td>8200359</td>\n",
       "      <td>10443159</td>\n",
       "      <td>10640156</td>\n",
       "      <td>12070560</td>\n",
       "      <td>8194655</td>\n",
       "      <td>8352542</td>\n",
       "      <td>8501466</td>\n",
       "      <td>231441</td>\n",
       "      <td>206663</td>\n",
       "      <td>195774</td>\n",
       "      <td>191534</td>\n",
       "      <td>195608</td>\n",
       "      <td>189182</td>\n",
       "      <td>193127</td>\n",
       "      <td>187053</td>\n",
       "      <td>187553</td>\n",
       "      <td>190108</td>\n",
       "      <td>185589</td>\n",
       "      <td>185664</td>\n",
       "      <td>187590</td>\n",
       "      <td>185793</td>\n",
       "      <td>185108</td>\n",
       "      <td>182016</td>\n",
       "      <td>188127</td>\n",
       "      <td>184830</td>\n",
       "      <td>185738</td>\n",
       "      <td>187923</td>\n",
       "      <td>183164</td>\n",
       "      <td>184572</td>\n",
       "      <td>220479</td>\n",
       "      <td>199127</td>\n",
       "      <td>190109</td>\n",
       "      <td>182813</td>\n",
       "      <td>188886</td>\n",
       "      <td>184682</td>\n",
       "      <td>187738</td>\n",
       "      <td>184868</td>\n",
       "      <td>188498</td>\n",
       "      <td>187498</td>\n",
       "      <td>184368</td>\n",
       "      <td>185275</td>\n",
       "      <td>181534</td>\n",
       "      <td>183738</td>\n",
       "      <td>193219</td>\n",
       "      <td>185571</td>\n",
       "      <td>185608</td>\n",
       "      <td>186349</td>\n",
       "      <td>186571</td>\n",
       "      <td>182813</td>\n",
       "      <td>185423</td>\n",
       "      <td>185701</td>\n",
       "      <td>185608</td>\n",
       "      <td>185349</td>\n",
       "      <td>183442</td>\n",
       "      <td>187164</td>\n",
       "      <td>189386</td>\n",
       "      <td>181960</td>\n",
       "      <td>188145</td>\n",
       "      <td>184367</td>\n",
       "      <td>191701</td>\n",
       "      <td>183090</td>\n",
       "      <td>187794</td>\n",
       "      <td>183942</td>\n",
       "      <td>184405</td>\n",
       "      <td>184942</td>\n",
       "      <td>185034</td>\n",
       "      <td>183590</td>\n",
       "      <td>185608</td>\n",
       "      <td>182904</td>\n",
       "      <td>188238</td>\n",
       "      <td>187182</td>\n",
       "      <td>193645</td>\n",
       "      <td>183497</td>\n",
       "      <td>189738</td>\n",
       "      <td>185460</td>\n",
       "      <td>187182</td>\n",
       "      <td>185775</td>\n",
       "      <td>188349</td>\n",
       "      <td>185108</td>\n",
       "      <td>184682</td>\n",
       "      <td>184849</td>\n",
       "      <td>184090</td>\n",
       "      <td>212312</td>\n",
       "      <td>185071</td>\n",
       "      <td>177219</td>\n",
       "      <td>183423</td>\n",
       "      <td>178553</td>\n",
       "      <td>176442</td>\n",
       "      <td>180145</td>\n",
       "      <td>183571</td>\n",
       "      <td>179071</td>\n",
       "      <td>180683</td>\n",
       "      <td>177312</td>\n",
       "      <td>179775</td>\n",
       "      <td>176794</td>\n",
       "      <td>182794</td>\n",
       "      <td>183627</td>\n",
       "      <td>182201</td>\n",
       "      <td>177793</td>\n",
       "      <td>186386</td>\n",
       "      <td>178183</td>\n",
       "      <td>179923</td>\n",
       "      <td>174146</td>\n",
       "      <td>176572</td>\n",
       "      <td>179812</td>\n",
       "      <td>187275</td>\n",
       "      <td>182664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>500.039327</td>\n",
       "      <td>1000.038061</td>\n",
       "      <td>2500.066088</td>\n",
       "      <td>705.132254</td>\n",
       "      <td>4166.365106</td>\n",
       "      <td>43444</td>\n",
       "      <td>18260</td>\n",
       "      <td>2756862974</td>\n",
       "      <td>3585430</td>\n",
       "      <td>556565840</td>\n",
       "      <td>19362930</td>\n",
       "      <td>29342168</td>\n",
       "      <td>839858</td>\n",
       "      <td>337877879</td>\n",
       "      <td>36580929</td>\n",
       "      <td>14537336</td>\n",
       "      <td>10880021</td>\n",
       "      <td>9218139</td>\n",
       "      <td>10104958</td>\n",
       "      <td>14400023</td>\n",
       "      <td>9441487</td>\n",
       "      <td>8200413</td>\n",
       "      <td>10281141</td>\n",
       "      <td>12383425</td>\n",
       "      <td>10691005</td>\n",
       "      <td>8175765</td>\n",
       "      <td>8236209</td>\n",
       "      <td>8402465</td>\n",
       "      <td>14494374</td>\n",
       "      <td>10124384</td>\n",
       "      <td>10174661</td>\n",
       "      <td>10475842</td>\n",
       "      <td>14446245</td>\n",
       "      <td>8164710</td>\n",
       "      <td>10297863</td>\n",
       "      <td>8988623</td>\n",
       "      <td>12411405</td>\n",
       "      <td>8431095</td>\n",
       "      <td>8638296</td>\n",
       "      <td>8454150</td>\n",
       "      <td>14667649</td>\n",
       "      <td>8296616</td>\n",
       "      <td>8353151</td>\n",
       "      <td>8210154</td>\n",
       "      <td>8654481</td>\n",
       "      <td>12512570</td>\n",
       "      <td>10654913</td>\n",
       "      <td>8538409</td>\n",
       "      <td>8632647</td>\n",
       "      <td>14245766</td>\n",
       "      <td>8354670</td>\n",
       "      <td>8470798</td>\n",
       "      <td>10749819</td>\n",
       "      <td>13440037</td>\n",
       "      <td>8550352</td>\n",
       "      <td>8609333</td>\n",
       "      <td>8438354</td>\n",
       "      <td>8402632</td>\n",
       "      <td>15373805</td>\n",
       "      <td>10484490</td>\n",
       "      <td>10554563</td>\n",
       "      <td>10229382</td>\n",
       "      <td>13219005</td>\n",
       "      <td>8731257</td>\n",
       "      <td>19218173</td>\n",
       "      <td>8630721</td>\n",
       "      <td>10224253</td>\n",
       "      <td>10340196</td>\n",
       "      <td>10393288</td>\n",
       "      <td>10106051</td>\n",
       "      <td>12323110</td>\n",
       "      <td>8414503</td>\n",
       "      <td>8578111</td>\n",
       "      <td>51290837</td>\n",
       "      <td>8305726</td>\n",
       "      <td>8478335</td>\n",
       "      <td>10768022</td>\n",
       "      <td>11733712</td>\n",
       "      <td>8332781</td>\n",
       "      <td>8727201</td>\n",
       "      <td>37670116</td>\n",
       "      <td>8313523</td>\n",
       "      <td>14102287</td>\n",
       "      <td>8417725</td>\n",
       "      <td>8587518</td>\n",
       "      <td>8106971</td>\n",
       "      <td>11671120</td>\n",
       "      <td>8380392</td>\n",
       "      <td>10593747</td>\n",
       "      <td>9990942</td>\n",
       "      <td>13421741</td>\n",
       "      <td>8099989</td>\n",
       "      <td>8337930</td>\n",
       "      <td>9794444</td>\n",
       "      <td>13672608</td>\n",
       "      <td>8370689</td>\n",
       "      <td>8488835</td>\n",
       "      <td>8143470</td>\n",
       "      <td>8434725</td>\n",
       "      <td>11667065</td>\n",
       "      <td>10441879</td>\n",
       "      <td>10184217</td>\n",
       "      <td>10116199</td>\n",
       "      <td>13860272</td>\n",
       "      <td>8283912</td>\n",
       "      <td>8162210</td>\n",
       "      <td>10321826</td>\n",
       "      <td>12093021</td>\n",
       "      <td>8624351</td>\n",
       "      <td>8241190</td>\n",
       "      <td>10282456</td>\n",
       "      <td>10056107</td>\n",
       "      <td>15757540</td>\n",
       "      <td>8070230</td>\n",
       "      <td>8206376</td>\n",
       "      <td>228108</td>\n",
       "      <td>206534</td>\n",
       "      <td>191349</td>\n",
       "      <td>179127</td>\n",
       "      <td>184793</td>\n",
       "      <td>186886</td>\n",
       "      <td>186646</td>\n",
       "      <td>181609</td>\n",
       "      <td>181609</td>\n",
       "      <td>181146</td>\n",
       "      <td>184886</td>\n",
       "      <td>185386</td>\n",
       "      <td>189109</td>\n",
       "      <td>184831</td>\n",
       "      <td>181775</td>\n",
       "      <td>183146</td>\n",
       "      <td>186219</td>\n",
       "      <td>185683</td>\n",
       "      <td>186238</td>\n",
       "      <td>184386</td>\n",
       "      <td>178146</td>\n",
       "      <td>182090</td>\n",
       "      <td>181775</td>\n",
       "      <td>182294</td>\n",
       "      <td>183127</td>\n",
       "      <td>180719</td>\n",
       "      <td>184738</td>\n",
       "      <td>185571</td>\n",
       "      <td>184720</td>\n",
       "      <td>185719</td>\n",
       "      <td>185108</td>\n",
       "      <td>180868</td>\n",
       "      <td>183868</td>\n",
       "      <td>178720</td>\n",
       "      <td>185831</td>\n",
       "      <td>180701</td>\n",
       "      <td>189793</td>\n",
       "      <td>180034</td>\n",
       "      <td>185868</td>\n",
       "      <td>178720</td>\n",
       "      <td>185682</td>\n",
       "      <td>181942</td>\n",
       "      <td>184275</td>\n",
       "      <td>177590</td>\n",
       "      <td>185423</td>\n",
       "      <td>186775</td>\n",
       "      <td>186905</td>\n",
       "      <td>185775</td>\n",
       "      <td>183849</td>\n",
       "      <td>179330</td>\n",
       "      <td>181720</td>\n",
       "      <td>181850</td>\n",
       "      <td>221922</td>\n",
       "      <td>189368</td>\n",
       "      <td>187683</td>\n",
       "      <td>186553</td>\n",
       "      <td>179349</td>\n",
       "      <td>184905</td>\n",
       "      <td>184812</td>\n",
       "      <td>181349</td>\n",
       "      <td>188108</td>\n",
       "      <td>180034</td>\n",
       "      <td>180812</td>\n",
       "      <td>186590</td>\n",
       "      <td>182015</td>\n",
       "      <td>184756</td>\n",
       "      <td>186961</td>\n",
       "      <td>178572</td>\n",
       "      <td>183035</td>\n",
       "      <td>182682</td>\n",
       "      <td>188534</td>\n",
       "      <td>183590</td>\n",
       "      <td>181850</td>\n",
       "      <td>181238</td>\n",
       "      <td>180793</td>\n",
       "      <td>182183</td>\n",
       "      <td>184812</td>\n",
       "      <td>182220</td>\n",
       "      <td>185219</td>\n",
       "      <td>183331</td>\n",
       "      <td>183294</td>\n",
       "      <td>183164</td>\n",
       "      <td>186515</td>\n",
       "      <td>177238</td>\n",
       "      <td>183831</td>\n",
       "      <td>179294</td>\n",
       "      <td>179683</td>\n",
       "      <td>183534</td>\n",
       "      <td>179979</td>\n",
       "      <td>181627</td>\n",
       "      <td>181849</td>\n",
       "      <td>183997</td>\n",
       "      <td>183812</td>\n",
       "      <td>185571</td>\n",
       "      <td>182571</td>\n",
       "      <td>180164</td>\n",
       "      <td>185960</td>\n",
       "      <td>183552</td>\n",
       "      <td>187053</td>\n",
       "      <td>184460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10353</th>\n",
       "      <td>500.043627</td>\n",
       "      <td>1000.038242</td>\n",
       "      <td>2500.064738</td>\n",
       "      <td>705.139614</td>\n",
       "      <td>4166.374021</td>\n",
       "      <td>43324</td>\n",
       "      <td>18145</td>\n",
       "      <td>2757565967</td>\n",
       "      <td>3594137</td>\n",
       "      <td>558119705</td>\n",
       "      <td>19231244</td>\n",
       "      <td>29338145</td>\n",
       "      <td>882708</td>\n",
       "      <td>287203626</td>\n",
       "      <td>36602053</td>\n",
       "      <td>15664613</td>\n",
       "      <td>11333253</td>\n",
       "      <td>8560925</td>\n",
       "      <td>11797950</td>\n",
       "      <td>11933189</td>\n",
       "      <td>9116787</td>\n",
       "      <td>8448334</td>\n",
       "      <td>8363113</td>\n",
       "      <td>8476000</td>\n",
       "      <td>14165248</td>\n",
       "      <td>8215338</td>\n",
       "      <td>8295615</td>\n",
       "      <td>8959623</td>\n",
       "      <td>12777287</td>\n",
       "      <td>8655517</td>\n",
       "      <td>10105438</td>\n",
       "      <td>10478266</td>\n",
       "      <td>14652443</td>\n",
       "      <td>8371799</td>\n",
       "      <td>8423816</td>\n",
       "      <td>8471741</td>\n",
       "      <td>46869360</td>\n",
       "      <td>8785922</td>\n",
       "      <td>8527110</td>\n",
       "      <td>8396112</td>\n",
       "      <td>8843569</td>\n",
       "      <td>8571573</td>\n",
       "      <td>11682915</td>\n",
       "      <td>8488481</td>\n",
       "      <td>11019813</td>\n",
       "      <td>8387521</td>\n",
       "      <td>8489630</td>\n",
       "      <td>8276652</td>\n",
       "      <td>9835017</td>\n",
       "      <td>8621850</td>\n",
       "      <td>8626961</td>\n",
       "      <td>8549592</td>\n",
       "      <td>37950625</td>\n",
       "      <td>10452323</td>\n",
       "      <td>12527143</td>\n",
       "      <td>8822736</td>\n",
       "      <td>9263766</td>\n",
       "      <td>8357299</td>\n",
       "      <td>8540703</td>\n",
       "      <td>9111676</td>\n",
       "      <td>10458711</td>\n",
       "      <td>8559185</td>\n",
       "      <td>8507426</td>\n",
       "      <td>8579776</td>\n",
       "      <td>8746330</td>\n",
       "      <td>8138283</td>\n",
       "      <td>11175015</td>\n",
       "      <td>8595406</td>\n",
       "      <td>8902364</td>\n",
       "      <td>8332965</td>\n",
       "      <td>8361039</td>\n",
       "      <td>10378713</td>\n",
       "      <td>12787657</td>\n",
       "      <td>8145043</td>\n",
       "      <td>8312744</td>\n",
       "      <td>8731626</td>\n",
       "      <td>9014585</td>\n",
       "      <td>8505092</td>\n",
       "      <td>10009366</td>\n",
       "      <td>8416168</td>\n",
       "      <td>8670220</td>\n",
       "      <td>8173819</td>\n",
       "      <td>11315161</td>\n",
       "      <td>8706034</td>\n",
       "      <td>10193845</td>\n",
       "      <td>8395020</td>\n",
       "      <td>13228150</td>\n",
       "      <td>8414112</td>\n",
       "      <td>8699331</td>\n",
       "      <td>10276658</td>\n",
       "      <td>14740368</td>\n",
       "      <td>19832494</td>\n",
       "      <td>9120454</td>\n",
       "      <td>8469223</td>\n",
       "      <td>8499963</td>\n",
       "      <td>12941210</td>\n",
       "      <td>11575268</td>\n",
       "      <td>10465656</td>\n",
       "      <td>8591943</td>\n",
       "      <td>12923118</td>\n",
       "      <td>8777033</td>\n",
       "      <td>8478963</td>\n",
       "      <td>9835609</td>\n",
       "      <td>13224206</td>\n",
       "      <td>8787755</td>\n",
       "      <td>8390613</td>\n",
       "      <td>10190604</td>\n",
       "      <td>10415175</td>\n",
       "      <td>16058700</td>\n",
       "      <td>8202801</td>\n",
       "      <td>8540888</td>\n",
       "      <td>8601314</td>\n",
       "      <td>12820082</td>\n",
       "      <td>8374002</td>\n",
       "      <td>10188733</td>\n",
       "      <td>225126</td>\n",
       "      <td>202459</td>\n",
       "      <td>186867</td>\n",
       "      <td>187553</td>\n",
       "      <td>188071</td>\n",
       "      <td>187904</td>\n",
       "      <td>188441</td>\n",
       "      <td>186627</td>\n",
       "      <td>226348</td>\n",
       "      <td>181923</td>\n",
       "      <td>172571</td>\n",
       "      <td>181498</td>\n",
       "      <td>173368</td>\n",
       "      <td>176571</td>\n",
       "      <td>171979</td>\n",
       "      <td>173923</td>\n",
       "      <td>174034</td>\n",
       "      <td>171775</td>\n",
       "      <td>175275</td>\n",
       "      <td>179312</td>\n",
       "      <td>174367</td>\n",
       "      <td>176108</td>\n",
       "      <td>173497</td>\n",
       "      <td>180961</td>\n",
       "      <td>178293</td>\n",
       "      <td>176868</td>\n",
       "      <td>177183</td>\n",
       "      <td>174164</td>\n",
       "      <td>175609</td>\n",
       "      <td>174461</td>\n",
       "      <td>176923</td>\n",
       "      <td>180831</td>\n",
       "      <td>179034</td>\n",
       "      <td>176386</td>\n",
       "      <td>173145</td>\n",
       "      <td>171015</td>\n",
       "      <td>178498</td>\n",
       "      <td>175812</td>\n",
       "      <td>173331</td>\n",
       "      <td>175627</td>\n",
       "      <td>177405</td>\n",
       "      <td>177904</td>\n",
       "      <td>172997</td>\n",
       "      <td>175071</td>\n",
       "      <td>174831</td>\n",
       "      <td>179405</td>\n",
       "      <td>174220</td>\n",
       "      <td>173164</td>\n",
       "      <td>176071</td>\n",
       "      <td>173127</td>\n",
       "      <td>174035</td>\n",
       "      <td>177664</td>\n",
       "      <td>177571</td>\n",
       "      <td>177571</td>\n",
       "      <td>174849</td>\n",
       "      <td>173664</td>\n",
       "      <td>175738</td>\n",
       "      <td>176053</td>\n",
       "      <td>172386</td>\n",
       "      <td>178627</td>\n",
       "      <td>176071</td>\n",
       "      <td>173738</td>\n",
       "      <td>176219</td>\n",
       "      <td>174219</td>\n",
       "      <td>210015</td>\n",
       "      <td>183109</td>\n",
       "      <td>175775</td>\n",
       "      <td>175571</td>\n",
       "      <td>178479</td>\n",
       "      <td>176238</td>\n",
       "      <td>181719</td>\n",
       "      <td>177145</td>\n",
       "      <td>175312</td>\n",
       "      <td>182886</td>\n",
       "      <td>174942</td>\n",
       "      <td>177571</td>\n",
       "      <td>171739</td>\n",
       "      <td>174572</td>\n",
       "      <td>177257</td>\n",
       "      <td>175886</td>\n",
       "      <td>171738</td>\n",
       "      <td>176164</td>\n",
       "      <td>175479</td>\n",
       "      <td>174979</td>\n",
       "      <td>177905</td>\n",
       "      <td>174405</td>\n",
       "      <td>178034</td>\n",
       "      <td>176145</td>\n",
       "      <td>171127</td>\n",
       "      <td>176830</td>\n",
       "      <td>173293</td>\n",
       "      <td>173460</td>\n",
       "      <td>175849</td>\n",
       "      <td>168998</td>\n",
       "      <td>176256</td>\n",
       "      <td>177016</td>\n",
       "      <td>173367</td>\n",
       "      <td>174146</td>\n",
       "      <td>178108</td>\n",
       "      <td>174423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51739</th>\n",
       "      <td>500.040494</td>\n",
       "      <td>1000.027344</td>\n",
       "      <td>2500.038198</td>\n",
       "      <td>705.077545</td>\n",
       "      <td>4166.104198</td>\n",
       "      <td>43646</td>\n",
       "      <td>18696</td>\n",
       "      <td>2769726041</td>\n",
       "      <td>3577067</td>\n",
       "      <td>559555083</td>\n",
       "      <td>19160410</td>\n",
       "      <td>30594409</td>\n",
       "      <td>895244</td>\n",
       "      <td>333743717</td>\n",
       "      <td>36821632</td>\n",
       "      <td>10745917</td>\n",
       "      <td>9429923</td>\n",
       "      <td>13311667</td>\n",
       "      <td>11560662</td>\n",
       "      <td>10736806</td>\n",
       "      <td>15042896</td>\n",
       "      <td>8530494</td>\n",
       "      <td>11009968</td>\n",
       "      <td>11111152</td>\n",
       "      <td>9166058</td>\n",
       "      <td>8552865</td>\n",
       "      <td>13175171</td>\n",
       "      <td>8720528</td>\n",
       "      <td>9103503</td>\n",
       "      <td>10554310</td>\n",
       "      <td>18416816</td>\n",
       "      <td>8975338</td>\n",
       "      <td>10906415</td>\n",
       "      <td>8576920</td>\n",
       "      <td>8515625</td>\n",
       "      <td>13422147</td>\n",
       "      <td>8981968</td>\n",
       "      <td>11190669</td>\n",
       "      <td>8561457</td>\n",
       "      <td>10545495</td>\n",
       "      <td>8690102</td>\n",
       "      <td>10635383</td>\n",
       "      <td>8335961</td>\n",
       "      <td>12287446</td>\n",
       "      <td>8895840</td>\n",
       "      <td>8663678</td>\n",
       "      <td>10553365</td>\n",
       "      <td>12711808</td>\n",
       "      <td>10673067</td>\n",
       "      <td>8389756</td>\n",
       "      <td>8359183</td>\n",
       "      <td>10379295</td>\n",
       "      <td>12528570</td>\n",
       "      <td>10969099</td>\n",
       "      <td>8670621</td>\n",
       "      <td>8652548</td>\n",
       "      <td>10550440</td>\n",
       "      <td>39944207</td>\n",
       "      <td>8389738</td>\n",
       "      <td>10560773</td>\n",
       "      <td>10561421</td>\n",
       "      <td>8061577</td>\n",
       "      <td>10291408</td>\n",
       "      <td>10779399</td>\n",
       "      <td>8870248</td>\n",
       "      <td>12336870</td>\n",
       "      <td>8387109</td>\n",
       "      <td>8441533</td>\n",
       "      <td>8678733</td>\n",
       "      <td>9984154</td>\n",
       "      <td>8366145</td>\n",
       "      <td>10805324</td>\n",
       "      <td>8647382</td>\n",
       "      <td>10256019</td>\n",
       "      <td>8349905</td>\n",
       "      <td>10523607</td>\n",
       "      <td>10931970</td>\n",
       "      <td>10458515</td>\n",
       "      <td>10473312</td>\n",
       "      <td>8897988</td>\n",
       "      <td>8904247</td>\n",
       "      <td>10592698</td>\n",
       "      <td>10284166</td>\n",
       "      <td>10645271</td>\n",
       "      <td>8708176</td>\n",
       "      <td>8212278</td>\n",
       "      <td>10063170</td>\n",
       "      <td>8608993</td>\n",
       "      <td>8872729</td>\n",
       "      <td>10399184</td>\n",
       "      <td>15170931</td>\n",
       "      <td>8495125</td>\n",
       "      <td>8894359</td>\n",
       "      <td>10181892</td>\n",
       "      <td>10564106</td>\n",
       "      <td>25030421</td>\n",
       "      <td>9560755</td>\n",
       "      <td>10371851</td>\n",
       "      <td>10836861</td>\n",
       "      <td>20334727</td>\n",
       "      <td>9053671</td>\n",
       "      <td>12760438</td>\n",
       "      <td>8553624</td>\n",
       "      <td>10949804</td>\n",
       "      <td>8850878</td>\n",
       "      <td>8448312</td>\n",
       "      <td>10734659</td>\n",
       "      <td>11196281</td>\n",
       "      <td>10785306</td>\n",
       "      <td>8586234</td>\n",
       "      <td>108780991</td>\n",
       "      <td>8453552</td>\n",
       "      <td>8562735</td>\n",
       "      <td>10457979</td>\n",
       "      <td>8459255</td>\n",
       "      <td>226367</td>\n",
       "      <td>196811</td>\n",
       "      <td>179293</td>\n",
       "      <td>183904</td>\n",
       "      <td>184367</td>\n",
       "      <td>181053</td>\n",
       "      <td>182886</td>\n",
       "      <td>182089</td>\n",
       "      <td>181756</td>\n",
       "      <td>183867</td>\n",
       "      <td>180959</td>\n",
       "      <td>182978</td>\n",
       "      <td>184070</td>\n",
       "      <td>179515</td>\n",
       "      <td>183552</td>\n",
       "      <td>182867</td>\n",
       "      <td>183182</td>\n",
       "      <td>181367</td>\n",
       "      <td>182256</td>\n",
       "      <td>223459</td>\n",
       "      <td>189163</td>\n",
       "      <td>181423</td>\n",
       "      <td>181274</td>\n",
       "      <td>179664</td>\n",
       "      <td>179978</td>\n",
       "      <td>181959</td>\n",
       "      <td>180830</td>\n",
       "      <td>181867</td>\n",
       "      <td>180719</td>\n",
       "      <td>179941</td>\n",
       "      <td>178831</td>\n",
       "      <td>179886</td>\n",
       "      <td>183052</td>\n",
       "      <td>178237</td>\n",
       "      <td>180442</td>\n",
       "      <td>182812</td>\n",
       "      <td>179868</td>\n",
       "      <td>177978</td>\n",
       "      <td>178793</td>\n",
       "      <td>179775</td>\n",
       "      <td>180923</td>\n",
       "      <td>181200</td>\n",
       "      <td>179923</td>\n",
       "      <td>180719</td>\n",
       "      <td>178034</td>\n",
       "      <td>175793</td>\n",
       "      <td>181386</td>\n",
       "      <td>177090</td>\n",
       "      <td>179848</td>\n",
       "      <td>177867</td>\n",
       "      <td>181978</td>\n",
       "      <td>180478</td>\n",
       "      <td>185349</td>\n",
       "      <td>177793</td>\n",
       "      <td>180164</td>\n",
       "      <td>181460</td>\n",
       "      <td>179885</td>\n",
       "      <td>180015</td>\n",
       "      <td>178757</td>\n",
       "      <td>179923</td>\n",
       "      <td>178090</td>\n",
       "      <td>176016</td>\n",
       "      <td>183793</td>\n",
       "      <td>178793</td>\n",
       "      <td>177942</td>\n",
       "      <td>178608</td>\n",
       "      <td>182627</td>\n",
       "      <td>176885</td>\n",
       "      <td>180886</td>\n",
       "      <td>183515</td>\n",
       "      <td>182923</td>\n",
       "      <td>179831</td>\n",
       "      <td>182682</td>\n",
       "      <td>183015</td>\n",
       "      <td>208348</td>\n",
       "      <td>184868</td>\n",
       "      <td>179293</td>\n",
       "      <td>184089</td>\n",
       "      <td>181163</td>\n",
       "      <td>179775</td>\n",
       "      <td>177886</td>\n",
       "      <td>179867</td>\n",
       "      <td>181571</td>\n",
       "      <td>183348</td>\n",
       "      <td>178775</td>\n",
       "      <td>182385</td>\n",
       "      <td>177627</td>\n",
       "      <td>180533</td>\n",
       "      <td>177905</td>\n",
       "      <td>177571</td>\n",
       "      <td>182571</td>\n",
       "      <td>178700</td>\n",
       "      <td>178626</td>\n",
       "      <td>178442</td>\n",
       "      <td>178793</td>\n",
       "      <td>177294</td>\n",
       "      <td>185293</td>\n",
       "      <td>179145</td>\n",
       "      <td>179701</td>\n",
       "      <td>182218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51740</th>\n",
       "      <td>500.046285</td>\n",
       "      <td>1000.042346</td>\n",
       "      <td>2500.071883</td>\n",
       "      <td>705.145639</td>\n",
       "      <td>4166.354530</td>\n",
       "      <td>43836</td>\n",
       "      <td>19436</td>\n",
       "      <td>2764013566</td>\n",
       "      <td>3489859</td>\n",
       "      <td>534479891</td>\n",
       "      <td>19226276</td>\n",
       "      <td>29216097</td>\n",
       "      <td>848859</td>\n",
       "      <td>288541265</td>\n",
       "      <td>36634524</td>\n",
       "      <td>14061342</td>\n",
       "      <td>8291044</td>\n",
       "      <td>11233637</td>\n",
       "      <td>8545764</td>\n",
       "      <td>8280082</td>\n",
       "      <td>8913833</td>\n",
       "      <td>10617515</td>\n",
       "      <td>8400006</td>\n",
       "      <td>10427666</td>\n",
       "      <td>8536968</td>\n",
       "      <td>8455246</td>\n",
       "      <td>8351654</td>\n",
       "      <td>8508449</td>\n",
       "      <td>8773224</td>\n",
       "      <td>20673186</td>\n",
       "      <td>8536449</td>\n",
       "      <td>8503264</td>\n",
       "      <td>8494024</td>\n",
       "      <td>25049057</td>\n",
       "      <td>22475275</td>\n",
       "      <td>11262081</td>\n",
       "      <td>8363191</td>\n",
       "      <td>8737224</td>\n",
       "      <td>8291360</td>\n",
       "      <td>8219435</td>\n",
       "      <td>8472376</td>\n",
       "      <td>11065917</td>\n",
       "      <td>8568041</td>\n",
       "      <td>8543338</td>\n",
       "      <td>10569257</td>\n",
       "      <td>8506875</td>\n",
       "      <td>8299989</td>\n",
       "      <td>10316593</td>\n",
       "      <td>8503505</td>\n",
       "      <td>8939314</td>\n",
       "      <td>8508727</td>\n",
       "      <td>8361617</td>\n",
       "      <td>8524726</td>\n",
       "      <td>10814457</td>\n",
       "      <td>8372174</td>\n",
       "      <td>11061362</td>\n",
       "      <td>8883278</td>\n",
       "      <td>8689928</td>\n",
       "      <td>10365815</td>\n",
       "      <td>15182218</td>\n",
       "      <td>10810828</td>\n",
       "      <td>8575559</td>\n",
       "      <td>8520356</td>\n",
       "      <td>8544042</td>\n",
       "      <td>11174954</td>\n",
       "      <td>10876883</td>\n",
       "      <td>8457505</td>\n",
       "      <td>8673947</td>\n",
       "      <td>11468264</td>\n",
       "      <td>8820723</td>\n",
       "      <td>8567023</td>\n",
       "      <td>10860846</td>\n",
       "      <td>11391839</td>\n",
       "      <td>8842686</td>\n",
       "      <td>19812124</td>\n",
       "      <td>8946573</td>\n",
       "      <td>8791057</td>\n",
       "      <td>16361185</td>\n",
       "      <td>8533967</td>\n",
       "      <td>10285427</td>\n",
       "      <td>10425740</td>\n",
       "      <td>14478042</td>\n",
       "      <td>8404877</td>\n",
       "      <td>10849198</td>\n",
       "      <td>8573393</td>\n",
       "      <td>11482042</td>\n",
       "      <td>8369284</td>\n",
       "      <td>8366118</td>\n",
       "      <td>425288531</td>\n",
       "      <td>16584794</td>\n",
       "      <td>8028567</td>\n",
       "      <td>8464932</td>\n",
       "      <td>11595003</td>\n",
       "      <td>8473635</td>\n",
       "      <td>8138972</td>\n",
       "      <td>10260020</td>\n",
       "      <td>11467672</td>\n",
       "      <td>8666207</td>\n",
       "      <td>10387038</td>\n",
       "      <td>10282057</td>\n",
       "      <td>10161966</td>\n",
       "      <td>15367902</td>\n",
       "      <td>10421462</td>\n",
       "      <td>10333816</td>\n",
       "      <td>10445888</td>\n",
       "      <td>13501332</td>\n",
       "      <td>8430543</td>\n",
       "      <td>10671941</td>\n",
       "      <td>8216823</td>\n",
       "      <td>40377534</td>\n",
       "      <td>8543653</td>\n",
       "      <td>10606720</td>\n",
       "      <td>8618171</td>\n",
       "      <td>13969326</td>\n",
       "      <td>8597634</td>\n",
       "      <td>225849</td>\n",
       "      <td>199479</td>\n",
       "      <td>186868</td>\n",
       "      <td>189220</td>\n",
       "      <td>184108</td>\n",
       "      <td>184960</td>\n",
       "      <td>193275</td>\n",
       "      <td>184554</td>\n",
       "      <td>185479</td>\n",
       "      <td>182331</td>\n",
       "      <td>183498</td>\n",
       "      <td>182294</td>\n",
       "      <td>182294</td>\n",
       "      <td>176257</td>\n",
       "      <td>185701</td>\n",
       "      <td>180257</td>\n",
       "      <td>184665</td>\n",
       "      <td>182146</td>\n",
       "      <td>178664</td>\n",
       "      <td>178702</td>\n",
       "      <td>231701</td>\n",
       "      <td>186165</td>\n",
       "      <td>177090</td>\n",
       "      <td>181905</td>\n",
       "      <td>179849</td>\n",
       "      <td>181257</td>\n",
       "      <td>185201</td>\n",
       "      <td>176665</td>\n",
       "      <td>181276</td>\n",
       "      <td>176054</td>\n",
       "      <td>184850</td>\n",
       "      <td>180220</td>\n",
       "      <td>181701</td>\n",
       "      <td>181072</td>\n",
       "      <td>182664</td>\n",
       "      <td>182646</td>\n",
       "      <td>185238</td>\n",
       "      <td>178072</td>\n",
       "      <td>183350</td>\n",
       "      <td>179757</td>\n",
       "      <td>182479</td>\n",
       "      <td>182091</td>\n",
       "      <td>184812</td>\n",
       "      <td>181368</td>\n",
       "      <td>182071</td>\n",
       "      <td>176979</td>\n",
       "      <td>182331</td>\n",
       "      <td>181035</td>\n",
       "      <td>184276</td>\n",
       "      <td>179683</td>\n",
       "      <td>181238</td>\n",
       "      <td>180831</td>\n",
       "      <td>184164</td>\n",
       "      <td>178609</td>\n",
       "      <td>180183</td>\n",
       "      <td>178035</td>\n",
       "      <td>180942</td>\n",
       "      <td>178942</td>\n",
       "      <td>188628</td>\n",
       "      <td>181961</td>\n",
       "      <td>184443</td>\n",
       "      <td>179479</td>\n",
       "      <td>181220</td>\n",
       "      <td>179609</td>\n",
       "      <td>182905</td>\n",
       "      <td>177054</td>\n",
       "      <td>178961</td>\n",
       "      <td>181794</td>\n",
       "      <td>180572</td>\n",
       "      <td>178349</td>\n",
       "      <td>183405</td>\n",
       "      <td>181924</td>\n",
       "      <td>183498</td>\n",
       "      <td>187627</td>\n",
       "      <td>213386</td>\n",
       "      <td>188442</td>\n",
       "      <td>181108</td>\n",
       "      <td>181387</td>\n",
       "      <td>184331</td>\n",
       "      <td>180035</td>\n",
       "      <td>185145</td>\n",
       "      <td>178220</td>\n",
       "      <td>181350</td>\n",
       "      <td>178554</td>\n",
       "      <td>183887</td>\n",
       "      <td>184794</td>\n",
       "      <td>184424</td>\n",
       "      <td>185165</td>\n",
       "      <td>179405</td>\n",
       "      <td>183961</td>\n",
       "      <td>183368</td>\n",
       "      <td>182239</td>\n",
       "      <td>183498</td>\n",
       "      <td>178572</td>\n",
       "      <td>181701</td>\n",
       "      <td>183405</td>\n",
       "      <td>179405</td>\n",
       "      <td>180220</td>\n",
       "      <td>181109</td>\n",
       "      <td>181832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51741</th>\n",
       "      <td>500.041816</td>\n",
       "      <td>1000.035840</td>\n",
       "      <td>2500.057229</td>\n",
       "      <td>705.130076</td>\n",
       "      <td>4166.106153</td>\n",
       "      <td>43031</td>\n",
       "      <td>18593</td>\n",
       "      <td>2768830858</td>\n",
       "      <td>3577655</td>\n",
       "      <td>568154883</td>\n",
       "      <td>19318557</td>\n",
       "      <td>29244759</td>\n",
       "      <td>832140</td>\n",
       "      <td>332662028</td>\n",
       "      <td>36817669</td>\n",
       "      <td>221950930</td>\n",
       "      <td>301029073</td>\n",
       "      <td>270859580</td>\n",
       "      <td>515871519</td>\n",
       "      <td>66502963</td>\n",
       "      <td>13899109</td>\n",
       "      <td>8511975</td>\n",
       "      <td>11440466</td>\n",
       "      <td>8873342</td>\n",
       "      <td>8550530</td>\n",
       "      <td>10883842</td>\n",
       "      <td>13664260</td>\n",
       "      <td>10706714</td>\n",
       "      <td>8309069</td>\n",
       "      <td>8158515</td>\n",
       "      <td>8521994</td>\n",
       "      <td>12121330</td>\n",
       "      <td>10794046</td>\n",
       "      <td>8408217</td>\n",
       "      <td>8541400</td>\n",
       "      <td>12661454</td>\n",
       "      <td>8890619</td>\n",
       "      <td>8683436</td>\n",
       "      <td>10993711</td>\n",
       "      <td>12029108</td>\n",
       "      <td>8503327</td>\n",
       "      <td>8533605</td>\n",
       "      <td>8597752</td>\n",
       "      <td>8818510</td>\n",
       "      <td>17061913</td>\n",
       "      <td>8594974</td>\n",
       "      <td>8773231</td>\n",
       "      <td>9003841</td>\n",
       "      <td>11484336</td>\n",
       "      <td>8612511</td>\n",
       "      <td>12725491</td>\n",
       "      <td>8817009</td>\n",
       "      <td>11495521</td>\n",
       "      <td>8714473</td>\n",
       "      <td>8821176</td>\n",
       "      <td>9265820</td>\n",
       "      <td>13714389</td>\n",
       "      <td>8666974</td>\n",
       "      <td>8627826</td>\n",
       "      <td>9018118</td>\n",
       "      <td>8547567</td>\n",
       "      <td>13605149</td>\n",
       "      <td>10844157</td>\n",
       "      <td>9387263</td>\n",
       "      <td>8749473</td>\n",
       "      <td>11568575</td>\n",
       "      <td>8723640</td>\n",
       "      <td>8942341</td>\n",
       "      <td>10617363</td>\n",
       "      <td>13064802</td>\n",
       "      <td>8523383</td>\n",
       "      <td>11026674</td>\n",
       "      <td>8578178</td>\n",
       "      <td>24698248</td>\n",
       "      <td>13979201</td>\n",
       "      <td>8772399</td>\n",
       "      <td>8402494</td>\n",
       "      <td>8289403</td>\n",
       "      <td>11379152</td>\n",
       "      <td>8891009</td>\n",
       "      <td>12734972</td>\n",
       "      <td>8470994</td>\n",
       "      <td>11670816</td>\n",
       "      <td>8811621</td>\n",
       "      <td>8407754</td>\n",
       "      <td>8323347</td>\n",
       "      <td>13188208</td>\n",
       "      <td>37612145</td>\n",
       "      <td>10137071</td>\n",
       "      <td>10231144</td>\n",
       "      <td>10281107</td>\n",
       "      <td>13505613</td>\n",
       "      <td>10125422</td>\n",
       "      <td>8181015</td>\n",
       "      <td>8437772</td>\n",
       "      <td>11977832</td>\n",
       "      <td>8704510</td>\n",
       "      <td>8287773</td>\n",
       "      <td>12731769</td>\n",
       "      <td>11889629</td>\n",
       "      <td>8305773</td>\n",
       "      <td>8260662</td>\n",
       "      <td>8381328</td>\n",
       "      <td>10625474</td>\n",
       "      <td>13328911</td>\n",
       "      <td>8362958</td>\n",
       "      <td>8665567</td>\n",
       "      <td>8946453</td>\n",
       "      <td>11349207</td>\n",
       "      <td>8320162</td>\n",
       "      <td>12359587</td>\n",
       "      <td>8756083</td>\n",
       "      <td>11043137</td>\n",
       "      <td>8270922</td>\n",
       "      <td>8361199</td>\n",
       "      <td>226850</td>\n",
       "      <td>202738</td>\n",
       "      <td>191590</td>\n",
       "      <td>188387</td>\n",
       "      <td>184239</td>\n",
       "      <td>181942</td>\n",
       "      <td>182684</td>\n",
       "      <td>184573</td>\n",
       "      <td>198221</td>\n",
       "      <td>183869</td>\n",
       "      <td>183572</td>\n",
       "      <td>183591</td>\n",
       "      <td>181943</td>\n",
       "      <td>179294</td>\n",
       "      <td>180387</td>\n",
       "      <td>178887</td>\n",
       "      <td>181165</td>\n",
       "      <td>182573</td>\n",
       "      <td>183554</td>\n",
       "      <td>179721</td>\n",
       "      <td>184850</td>\n",
       "      <td>177388</td>\n",
       "      <td>179479</td>\n",
       "      <td>178202</td>\n",
       "      <td>182609</td>\n",
       "      <td>178424</td>\n",
       "      <td>185461</td>\n",
       "      <td>178998</td>\n",
       "      <td>179906</td>\n",
       "      <td>179332</td>\n",
       "      <td>181425</td>\n",
       "      <td>180646</td>\n",
       "      <td>181739</td>\n",
       "      <td>177869</td>\n",
       "      <td>177887</td>\n",
       "      <td>181961</td>\n",
       "      <td>182443</td>\n",
       "      <td>177369</td>\n",
       "      <td>180165</td>\n",
       "      <td>176276</td>\n",
       "      <td>180147</td>\n",
       "      <td>175295</td>\n",
       "      <td>180869</td>\n",
       "      <td>179461</td>\n",
       "      <td>179535</td>\n",
       "      <td>182350</td>\n",
       "      <td>180257</td>\n",
       "      <td>176924</td>\n",
       "      <td>180313</td>\n",
       "      <td>180443</td>\n",
       "      <td>182314</td>\n",
       "      <td>177332</td>\n",
       "      <td>184868</td>\n",
       "      <td>181480</td>\n",
       "      <td>183683</td>\n",
       "      <td>178739</td>\n",
       "      <td>185665</td>\n",
       "      <td>180072</td>\n",
       "      <td>182221</td>\n",
       "      <td>179276</td>\n",
       "      <td>183979</td>\n",
       "      <td>179479</td>\n",
       "      <td>207313</td>\n",
       "      <td>181147</td>\n",
       "      <td>173998</td>\n",
       "      <td>172814</td>\n",
       "      <td>176350</td>\n",
       "      <td>172925</td>\n",
       "      <td>173351</td>\n",
       "      <td>172462</td>\n",
       "      <td>173295</td>\n",
       "      <td>171091</td>\n",
       "      <td>171332</td>\n",
       "      <td>174813</td>\n",
       "      <td>178795</td>\n",
       "      <td>172572</td>\n",
       "      <td>174979</td>\n",
       "      <td>178202</td>\n",
       "      <td>176017</td>\n",
       "      <td>172998</td>\n",
       "      <td>174887</td>\n",
       "      <td>174091</td>\n",
       "      <td>174128</td>\n",
       "      <td>173276</td>\n",
       "      <td>177942</td>\n",
       "      <td>177405</td>\n",
       "      <td>171572</td>\n",
       "      <td>169221</td>\n",
       "      <td>172221</td>\n",
       "      <td>178554</td>\n",
       "      <td>175961</td>\n",
       "      <td>175684</td>\n",
       "      <td>171220</td>\n",
       "      <td>175535</td>\n",
       "      <td>177368</td>\n",
       "      <td>173573</td>\n",
       "      <td>175313</td>\n",
       "      <td>173720</td>\n",
       "      <td>176294</td>\n",
       "      <td>176165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51742</th>\n",
       "      <td>500.040198</td>\n",
       "      <td>1000.032283</td>\n",
       "      <td>2500.048801</td>\n",
       "      <td>705.104443</td>\n",
       "      <td>4165.975927</td>\n",
       "      <td>42830</td>\n",
       "      <td>18547</td>\n",
       "      <td>2766675247</td>\n",
       "      <td>3664469</td>\n",
       "      <td>565349888</td>\n",
       "      <td>19303718</td>\n",
       "      <td>29887673</td>\n",
       "      <td>872049</td>\n",
       "      <td>286242830</td>\n",
       "      <td>36470084</td>\n",
       "      <td>10538250</td>\n",
       "      <td>14598163</td>\n",
       "      <td>9213336</td>\n",
       "      <td>8499211</td>\n",
       "      <td>10372197</td>\n",
       "      <td>15847672</td>\n",
       "      <td>8360194</td>\n",
       "      <td>8366860</td>\n",
       "      <td>8523285</td>\n",
       "      <td>10572861</td>\n",
       "      <td>31762991</td>\n",
       "      <td>8483396</td>\n",
       "      <td>10773897</td>\n",
       "      <td>8937189</td>\n",
       "      <td>12264256</td>\n",
       "      <td>8558525</td>\n",
       "      <td>10747638</td>\n",
       "      <td>8679154</td>\n",
       "      <td>12187423</td>\n",
       "      <td>8488304</td>\n",
       "      <td>9172835</td>\n",
       "      <td>99176371</td>\n",
       "      <td>190001584</td>\n",
       "      <td>165877385</td>\n",
       "      <td>158582850</td>\n",
       "      <td>95162810</td>\n",
       "      <td>10693620</td>\n",
       "      <td>8580044</td>\n",
       "      <td>10705972</td>\n",
       "      <td>10870175</td>\n",
       "      <td>8382767</td>\n",
       "      <td>8381194</td>\n",
       "      <td>8329842</td>\n",
       "      <td>8856950</td>\n",
       "      <td>12796641</td>\n",
       "      <td>8647711</td>\n",
       "      <td>9266354</td>\n",
       "      <td>8940393</td>\n",
       "      <td>10474418</td>\n",
       "      <td>10545584</td>\n",
       "      <td>12815659</td>\n",
       "      <td>8884078</td>\n",
       "      <td>8560747</td>\n",
       "      <td>10442510</td>\n",
       "      <td>10788619</td>\n",
       "      <td>9019874</td>\n",
       "      <td>12716753</td>\n",
       "      <td>8503933</td>\n",
       "      <td>8711987</td>\n",
       "      <td>10775934</td>\n",
       "      <td>8195325</td>\n",
       "      <td>44548114</td>\n",
       "      <td>10726064</td>\n",
       "      <td>9026744</td>\n",
       "      <td>8445915</td>\n",
       "      <td>8507748</td>\n",
       "      <td>8452342</td>\n",
       "      <td>8772246</td>\n",
       "      <td>10350067</td>\n",
       "      <td>8427267</td>\n",
       "      <td>8871375</td>\n",
       "      <td>9076799</td>\n",
       "      <td>8532933</td>\n",
       "      <td>8453897</td>\n",
       "      <td>10826378</td>\n",
       "      <td>8773135</td>\n",
       "      <td>12721326</td>\n",
       "      <td>8321676</td>\n",
       "      <td>8820357</td>\n",
       "      <td>9187835</td>\n",
       "      <td>10663898</td>\n",
       "      <td>12077850</td>\n",
       "      <td>10707120</td>\n",
       "      <td>8944022</td>\n",
       "      <td>10376270</td>\n",
       "      <td>14255277</td>\n",
       "      <td>204156921</td>\n",
       "      <td>11073784</td>\n",
       "      <td>8657728</td>\n",
       "      <td>8620637</td>\n",
       "      <td>11086617</td>\n",
       "      <td>9195539</td>\n",
       "      <td>10913934</td>\n",
       "      <td>9769349</td>\n",
       "      <td>10543973</td>\n",
       "      <td>8680376</td>\n",
       "      <td>8475656</td>\n",
       "      <td>8847838</td>\n",
       "      <td>10940193</td>\n",
       "      <td>11764926</td>\n",
       "      <td>8283324</td>\n",
       "      <td>8308861</td>\n",
       "      <td>10414160</td>\n",
       "      <td>35778257</td>\n",
       "      <td>10405549</td>\n",
       "      <td>8629303</td>\n",
       "      <td>10616899</td>\n",
       "      <td>36756805</td>\n",
       "      <td>8406101</td>\n",
       "      <td>8237047</td>\n",
       "      <td>227443</td>\n",
       "      <td>206184</td>\n",
       "      <td>189739</td>\n",
       "      <td>189351</td>\n",
       "      <td>183480</td>\n",
       "      <td>185628</td>\n",
       "      <td>186498</td>\n",
       "      <td>179869</td>\n",
       "      <td>188813</td>\n",
       "      <td>180832</td>\n",
       "      <td>178850</td>\n",
       "      <td>183850</td>\n",
       "      <td>185832</td>\n",
       "      <td>180702</td>\n",
       "      <td>188980</td>\n",
       "      <td>179017</td>\n",
       "      <td>186776</td>\n",
       "      <td>179739</td>\n",
       "      <td>180202</td>\n",
       "      <td>181406</td>\n",
       "      <td>185999</td>\n",
       "      <td>183332</td>\n",
       "      <td>188202</td>\n",
       "      <td>180610</td>\n",
       "      <td>180794</td>\n",
       "      <td>179869</td>\n",
       "      <td>187239</td>\n",
       "      <td>183295</td>\n",
       "      <td>182055</td>\n",
       "      <td>179666</td>\n",
       "      <td>178054</td>\n",
       "      <td>179295</td>\n",
       "      <td>186424</td>\n",
       "      <td>177647</td>\n",
       "      <td>179425</td>\n",
       "      <td>181276</td>\n",
       "      <td>188091</td>\n",
       "      <td>184554</td>\n",
       "      <td>184276</td>\n",
       "      <td>175814</td>\n",
       "      <td>179739</td>\n",
       "      <td>176832</td>\n",
       "      <td>180776</td>\n",
       "      <td>180462</td>\n",
       "      <td>176369</td>\n",
       "      <td>182517</td>\n",
       "      <td>225590</td>\n",
       "      <td>187554</td>\n",
       "      <td>172794</td>\n",
       "      <td>177018</td>\n",
       "      <td>179128</td>\n",
       "      <td>176351</td>\n",
       "      <td>180443</td>\n",
       "      <td>175240</td>\n",
       "      <td>175573</td>\n",
       "      <td>179832</td>\n",
       "      <td>177499</td>\n",
       "      <td>179647</td>\n",
       "      <td>178795</td>\n",
       "      <td>184461</td>\n",
       "      <td>185332</td>\n",
       "      <td>184536</td>\n",
       "      <td>182758</td>\n",
       "      <td>181850</td>\n",
       "      <td>185962</td>\n",
       "      <td>185406</td>\n",
       "      <td>181554</td>\n",
       "      <td>182258</td>\n",
       "      <td>184591</td>\n",
       "      <td>183591</td>\n",
       "      <td>187535</td>\n",
       "      <td>183517</td>\n",
       "      <td>186998</td>\n",
       "      <td>184684</td>\n",
       "      <td>179350</td>\n",
       "      <td>179036</td>\n",
       "      <td>178221</td>\n",
       "      <td>182147</td>\n",
       "      <td>186610</td>\n",
       "      <td>180684</td>\n",
       "      <td>188776</td>\n",
       "      <td>178591</td>\n",
       "      <td>184646</td>\n",
       "      <td>183054</td>\n",
       "      <td>180887</td>\n",
       "      <td>181684</td>\n",
       "      <td>183055</td>\n",
       "      <td>177980</td>\n",
       "      <td>181591</td>\n",
       "      <td>178091</td>\n",
       "      <td>185350</td>\n",
       "      <td>181980</td>\n",
       "      <td>178869</td>\n",
       "      <td>181684</td>\n",
       "      <td>180498</td>\n",
       "      <td>183906</td>\n",
       "      <td>186480</td>\n",
       "      <td>180406</td>\n",
       "      <td>183017</td>\n",
       "      <td>177332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51743</th>\n",
       "      <td>500.039308</td>\n",
       "      <td>1000.041784</td>\n",
       "      <td>2500.047537</td>\n",
       "      <td>705.098534</td>\n",
       "      <td>4165.903198</td>\n",
       "      <td>43027</td>\n",
       "      <td>18672</td>\n",
       "      <td>2759093169</td>\n",
       "      <td>3661968</td>\n",
       "      <td>570866534</td>\n",
       "      <td>19270255</td>\n",
       "      <td>29490628</td>\n",
       "      <td>843365</td>\n",
       "      <td>335024670</td>\n",
       "      <td>36537098</td>\n",
       "      <td>10911628</td>\n",
       "      <td>34655518</td>\n",
       "      <td>30765175</td>\n",
       "      <td>8200165</td>\n",
       "      <td>12525709</td>\n",
       "      <td>13031576</td>\n",
       "      <td>30771897</td>\n",
       "      <td>8417053</td>\n",
       "      <td>10604185</td>\n",
       "      <td>8616403</td>\n",
       "      <td>13326334</td>\n",
       "      <td>8394071</td>\n",
       "      <td>8321757</td>\n",
       "      <td>8498349</td>\n",
       "      <td>11396717</td>\n",
       "      <td>10464075</td>\n",
       "      <td>12792281</td>\n",
       "      <td>8680551</td>\n",
       "      <td>10435409</td>\n",
       "      <td>8316739</td>\n",
       "      <td>31280987</td>\n",
       "      <td>8380535</td>\n",
       "      <td>16536126</td>\n",
       "      <td>9164677</td>\n",
       "      <td>8325702</td>\n",
       "      <td>8368775</td>\n",
       "      <td>8771087</td>\n",
       "      <td>30250919</td>\n",
       "      <td>10234743</td>\n",
       "      <td>8309368</td>\n",
       "      <td>37465740</td>\n",
       "      <td>10245559</td>\n",
       "      <td>8334776</td>\n",
       "      <td>8419498</td>\n",
       "      <td>10762647</td>\n",
       "      <td>10198151</td>\n",
       "      <td>8428701</td>\n",
       "      <td>10577593</td>\n",
       "      <td>9118195</td>\n",
       "      <td>10683851</td>\n",
       "      <td>121613525</td>\n",
       "      <td>184841752</td>\n",
       "      <td>32005537</td>\n",
       "      <td>8440774</td>\n",
       "      <td>8488516</td>\n",
       "      <td>8515182</td>\n",
       "      <td>12773670</td>\n",
       "      <td>8404478</td>\n",
       "      <td>8671754</td>\n",
       "      <td>8709625</td>\n",
       "      <td>12353100</td>\n",
       "      <td>8481645</td>\n",
       "      <td>10656037</td>\n",
       "      <td>8520645</td>\n",
       "      <td>12852726</td>\n",
       "      <td>8477719</td>\n",
       "      <td>8683958</td>\n",
       "      <td>10759111</td>\n",
       "      <td>12914466</td>\n",
       "      <td>8393423</td>\n",
       "      <td>8403572</td>\n",
       "      <td>8488533</td>\n",
       "      <td>8618440</td>\n",
       "      <td>10127356</td>\n",
       "      <td>10800592</td>\n",
       "      <td>8739328</td>\n",
       "      <td>8859179</td>\n",
       "      <td>10626537</td>\n",
       "      <td>8491552</td>\n",
       "      <td>8609366</td>\n",
       "      <td>12850855</td>\n",
       "      <td>10143318</td>\n",
       "      <td>8639329</td>\n",
       "      <td>8785810</td>\n",
       "      <td>8955660</td>\n",
       "      <td>8627274</td>\n",
       "      <td>12390340</td>\n",
       "      <td>8597459</td>\n",
       "      <td>8685329</td>\n",
       "      <td>8541182</td>\n",
       "      <td>10543093</td>\n",
       "      <td>9054845</td>\n",
       "      <td>11005979</td>\n",
       "      <td>9027678</td>\n",
       "      <td>10336373</td>\n",
       "      <td>8583459</td>\n",
       "      <td>8733106</td>\n",
       "      <td>10385317</td>\n",
       "      <td>14261698</td>\n",
       "      <td>8253850</td>\n",
       "      <td>8613903</td>\n",
       "      <td>8640237</td>\n",
       "      <td>10522594</td>\n",
       "      <td>32691958</td>\n",
       "      <td>10649389</td>\n",
       "      <td>8178480</td>\n",
       "      <td>8178202</td>\n",
       "      <td>11877307</td>\n",
       "      <td>8553348</td>\n",
       "      <td>10298336</td>\n",
       "      <td>233203</td>\n",
       "      <td>205202</td>\n",
       "      <td>191258</td>\n",
       "      <td>188554</td>\n",
       "      <td>185221</td>\n",
       "      <td>184869</td>\n",
       "      <td>185518</td>\n",
       "      <td>184481</td>\n",
       "      <td>182406</td>\n",
       "      <td>182425</td>\n",
       "      <td>187017</td>\n",
       "      <td>183054</td>\n",
       "      <td>188592</td>\n",
       "      <td>183592</td>\n",
       "      <td>186554</td>\n",
       "      <td>182351</td>\n",
       "      <td>180962</td>\n",
       "      <td>185332</td>\n",
       "      <td>182351</td>\n",
       "      <td>181554</td>\n",
       "      <td>182813</td>\n",
       "      <td>183702</td>\n",
       "      <td>180962</td>\n",
       "      <td>185777</td>\n",
       "      <td>182498</td>\n",
       "      <td>183351</td>\n",
       "      <td>181129</td>\n",
       "      <td>185332</td>\n",
       "      <td>185258</td>\n",
       "      <td>230091</td>\n",
       "      <td>195535</td>\n",
       "      <td>185165</td>\n",
       "      <td>186591</td>\n",
       "      <td>184146</td>\n",
       "      <td>186295</td>\n",
       "      <td>183962</td>\n",
       "      <td>186961</td>\n",
       "      <td>185999</td>\n",
       "      <td>187573</td>\n",
       "      <td>183795</td>\n",
       "      <td>185110</td>\n",
       "      <td>184870</td>\n",
       "      <td>184202</td>\n",
       "      <td>182147</td>\n",
       "      <td>184721</td>\n",
       "      <td>184924</td>\n",
       "      <td>187592</td>\n",
       "      <td>183925</td>\n",
       "      <td>185406</td>\n",
       "      <td>182758</td>\n",
       "      <td>186258</td>\n",
       "      <td>183813</td>\n",
       "      <td>186369</td>\n",
       "      <td>182758</td>\n",
       "      <td>184147</td>\n",
       "      <td>183610</td>\n",
       "      <td>186239</td>\n",
       "      <td>181758</td>\n",
       "      <td>184110</td>\n",
       "      <td>184036</td>\n",
       "      <td>185888</td>\n",
       "      <td>184091</td>\n",
       "      <td>185461</td>\n",
       "      <td>184906</td>\n",
       "      <td>185258</td>\n",
       "      <td>182258</td>\n",
       "      <td>184703</td>\n",
       "      <td>183202</td>\n",
       "      <td>188683</td>\n",
       "      <td>183165</td>\n",
       "      <td>187147</td>\n",
       "      <td>182758</td>\n",
       "      <td>182351</td>\n",
       "      <td>184240</td>\n",
       "      <td>187110</td>\n",
       "      <td>183018</td>\n",
       "      <td>187425</td>\n",
       "      <td>182739</td>\n",
       "      <td>185295</td>\n",
       "      <td>183351</td>\n",
       "      <td>182850</td>\n",
       "      <td>185850</td>\n",
       "      <td>212035</td>\n",
       "      <td>178314</td>\n",
       "      <td>177221</td>\n",
       "      <td>173666</td>\n",
       "      <td>176721</td>\n",
       "      <td>172480</td>\n",
       "      <td>176851</td>\n",
       "      <td>175406</td>\n",
       "      <td>180332</td>\n",
       "      <td>172424</td>\n",
       "      <td>175203</td>\n",
       "      <td>175851</td>\n",
       "      <td>180166</td>\n",
       "      <td>175351</td>\n",
       "      <td>172573</td>\n",
       "      <td>175035</td>\n",
       "      <td>172925</td>\n",
       "      <td>172943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41395 rows × 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cpu_sleep_1s  cpu_sleep_2s  cpu_sleep_5s  cpu_sleep_10s  \\\n",
       "10349    500.040883   1000.037750   2500.063642     705.127493   \n",
       "10350    500.043892   1000.049142   2500.060357     705.128289   \n",
       "10351    500.039681   1000.038321   2500.063183     705.129506   \n",
       "10352    500.039327   1000.038061   2500.066088     705.132254   \n",
       "10353    500.043627   1000.038242   2500.064738     705.139614   \n",
       "...             ...           ...           ...            ...   \n",
       "51739    500.040494   1000.027344   2500.038198     705.077545   \n",
       "51740    500.046285   1000.042346   2500.071883     705.145639   \n",
       "51741    500.041816   1000.035840   2500.057229     705.130076   \n",
       "51742    500.040198   1000.032283   2500.048801     705.104443   \n",
       "51743    500.039308   1000.041784   2500.047537     705.098534   \n",
       "\n",
       "       cpu_sleep_120s  cpu_hash  cpu_pseudorandom  cpu_urandom  cpu_fib  \\\n",
       "10349     4166.311095     43243             18734   2757221312  3642399   \n",
       "10350     4166.333592     42912             18630   2755367052  3601859   \n",
       "10351     4166.352651     43262             18591   2753894653  3553273   \n",
       "10352     4166.365106     43444             18260   2756862974  3585430   \n",
       "10353     4166.374021     43324             18145   2757565967  3594137   \n",
       "...               ...       ...               ...          ...      ...   \n",
       "51739     4166.104198     43646             18696   2769726041  3577067   \n",
       "51740     4166.354530     43836             19436   2764013566  3489859   \n",
       "51741     4166.106153     43031             18593   2768830858  3577655   \n",
       "51742     4165.975927     42830             18547   2766675247  3664469   \n",
       "51743     4165.903198     43027             18672   2759093169  3661968   \n",
       "\n",
       "       gpu_matrixmul   gpu_sum  gpu_scopy  mem_list  mem_reserve  mem_csvread  \\\n",
       "10349      552160088  19131818   29319986    807211    286972957     36634049   \n",
       "10350      568743733  19298939   29348125    833581    286450666     36525075   \n",
       "10351      569251160  19136788   30155809    807395    286975644     36466956   \n",
       "10352      556565840  19362930   29342168    839858    337877879     36580929   \n",
       "10353      558119705  19231244   29338145    882708    287203626     36602053   \n",
       "...              ...       ...        ...       ...          ...          ...   \n",
       "51739      559555083  19160410   30594409    895244    333743717     36821632   \n",
       "51740      534479891  19226276   29216097    848859    288541265     36634524   \n",
       "51741      568154883  19318557   29244759    832140    332662028     36817669   \n",
       "51742      565349888  19303718   29887673    872049    286242830     36470084   \n",
       "51743      570866534  19270255   29490628    843365    335024670     36537098   \n",
       "\n",
       "       storage_read_1  storage_read_2  storage_read_3  storage_read_4  \\\n",
       "10349        10956195         8879891        10534201        10324112   \n",
       "10350        10795582         9772153         8823315        10422384   \n",
       "10351        10553972        11369034        11923137         9033180   \n",
       "10352        14537336        10880021         9218139        10104958   \n",
       "10353        15664613        11333253         8560925        11797950   \n",
       "...               ...             ...             ...             ...   \n",
       "51739        10745917         9429923        13311667        11560662   \n",
       "51740        14061342         8291044        11233637         8545764   \n",
       "51741       221950930       301029073       270859580       515871519   \n",
       "51742        10538250        14598163         9213336         8499211   \n",
       "51743        10911628        34655518        30765175         8200165   \n",
       "\n",
       "       storage_read_5  storage_read_6  storage_read_7  storage_read_8  \\\n",
       "10349        10279520        12725391         8485656         8849984   \n",
       "10350        15996450        38316159        12400058         8424617   \n",
       "10351       137116065         9458322         8654037         8839646   \n",
       "10352        14400023         9441487         8200413        10281141   \n",
       "10353        11933189         9116787         8448334         8363113   \n",
       "...               ...             ...             ...             ...   \n",
       "51739        10736806        15042896         8530494        11009968   \n",
       "51740         8280082         8913833        10617515         8400006   \n",
       "51741        66502963        13899109         8511975        11440466   \n",
       "51742        10372197        15847672         8360194         8366860   \n",
       "51743        12525709        13031576        30771897         8417053   \n",
       "\n",
       "       storage_read_9  storage_read_10  storage_read_11  storage_read_12  \\\n",
       "10349        10541404         10826660          8563748         11004380   \n",
       "10350        14942744         10697621         11156077          8476227   \n",
       "10351         8192674         10194200         12287687          8653316   \n",
       "10352        12383425         10691005          8175765          8236209   \n",
       "10353         8476000         14165248          8215338          8295615   \n",
       "...               ...              ...              ...              ...   \n",
       "51739        11111152          9166058          8552865         13175171   \n",
       "51740        10427666          8536968          8455246          8351654   \n",
       "51741         8873342          8550530         10883842         13664260   \n",
       "51742         8523285         10572861         31762991          8483396   \n",
       "51743        10604185          8616403         13326334          8394071   \n",
       "\n",
       "       storage_read_13  storage_read_14  storage_read_15  storage_read_16  \\\n",
       "10349          8680561          8872650          8740967         10861548   \n",
       "10350         12822886          8509727          8604929          8468505   \n",
       "10351          8610649          8500226          8475466          8650575   \n",
       "10352          8402465         14494374         10124384         10174661   \n",
       "10353          8959623         12777287          8655517         10105438   \n",
       "...                ...              ...              ...              ...   \n",
       "51739          8720528          9103503         10554310         18416816   \n",
       "51740          8508449          8773224         20673186          8536449   \n",
       "51741         10706714          8309069          8158515          8521994   \n",
       "51742         10773897          8937189         12264256          8558525   \n",
       "51743          8321757          8498349         11396717         10464075   \n",
       "\n",
       "       storage_read_17  storage_read_18  storage_read_19  storage_read_20  \\\n",
       "10349          8302880         10621681          8135847          8250622   \n",
       "10350         10756490         14898819         10789249          8433821   \n",
       "10351         12449315          8355542          8403412          8565428   \n",
       "10352         10475842         14446245          8164710         10297863   \n",
       "10353         10478266         14652443          8371799          8423816   \n",
       "...                ...              ...              ...              ...   \n",
       "51739          8975338         10906415          8576920          8515625   \n",
       "51740          8503264          8494024         25049057         22475275   \n",
       "51741         12121330         10794046          8408217          8541400   \n",
       "51742         10747638          8679154         12187423          8488304   \n",
       "51743         12792281          8680551         10435409          8316739   \n",
       "\n",
       "       storage_read_21  storage_read_22  storage_read_23  storage_read_24  \\\n",
       "10349          9552474          8295178          8207197         10453517   \n",
       "10350          8444746         12655759         11120207          8535319   \n",
       "10351          8799498          8681259         19021753          8826646   \n",
       "10352          8988623         12411405          8431095          8638296   \n",
       "10353          8471741         46869360          8785922          8527110   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         13422147          8981968         11190669          8561457   \n",
       "51740         11262081          8363191          8737224          8291360   \n",
       "51741         12661454          8890619          8683436         10993711   \n",
       "51742          9172835         99176371        190001584        165877385   \n",
       "51743         31280987          8380535         16536126          9164677   \n",
       "\n",
       "       storage_read_25  storage_read_26  storage_read_27  storage_read_28  \\\n",
       "10349          8250382          8506175          8602413          8409657   \n",
       "10350          8449709         12146284          8657799         38305863   \n",
       "10351          8220285          8392819         10618471          8873146   \n",
       "10352          8454150         14667649          8296616          8353151   \n",
       "10353          8396112          8843569          8571573         11682915   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         10545495          8690102         10635383          8335961   \n",
       "51740          8219435          8472376         11065917          8568041   \n",
       "51741         12029108          8503327          8533605          8597752   \n",
       "51742        158582850         95162810         10693620          8580044   \n",
       "51743          8325702          8368775          8771087         30250919   \n",
       "\n",
       "       storage_read_29  storage_read_30  storage_read_31  storage_read_32  \\\n",
       "10349         10415962         12601356          8167587          6137634   \n",
       "10350         10510586         11589089          8958665          8582374   \n",
       "10351         10709359         10419030         10470269         10877893   \n",
       "10352          8210154          8654481         12512570         10654913   \n",
       "10353          8488481         11019813          8387521          8489630   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         12287446          8895840          8663678         10553365   \n",
       "51740          8543338         10569257          8506875          8299989   \n",
       "51741          8818510         17061913          8594974          8773231   \n",
       "51742         10705972         10870175          8382767          8381194   \n",
       "51743         10234743          8309368         37465740         10245559   \n",
       "\n",
       "       storage_read_33  storage_read_34  storage_read_35  storage_read_36  \\\n",
       "10349          5492829          5998544          5891860          7814591   \n",
       "10350          8519690          8638781         42290935          8383710   \n",
       "10351          8066287          8223229         10504103          8735648   \n",
       "10352          8538409          8632647         14245766          8354670   \n",
       "10353          8276652          9835017          8621850          8626961   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         12711808         10673067          8389756          8359183   \n",
       "51740         10316593          8503505          8939314          8508727   \n",
       "51741          9003841         11484336          8612511         12725491   \n",
       "51742          8329842          8856950         12796641          8647711   \n",
       "51743          8334776          8419498         10762647         10198151   \n",
       "\n",
       "       storage_read_37  storage_read_38  storage_read_39  storage_read_40  \\\n",
       "10349          5529272          6217429          5991803          6185449   \n",
       "10350          8366525         10543327         13446729          8562244   \n",
       "10351          8158064          8133157          8239803          8644667   \n",
       "10352          8470798         10749819         13440037          8550352   \n",
       "10353          8549592         37950625         10452323         12527143   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         10379295         12528570         10969099          8670621   \n",
       "51740          8361617          8524726         10814457          8372174   \n",
       "51741          8817009         11495521          8714473          8821176   \n",
       "51742          9266354          8940393         10474418         10545584   \n",
       "51743          8428701         10577593          9118195         10683851   \n",
       "\n",
       "       storage_read_41  storage_read_42  storage_read_43  storage_read_44  \\\n",
       "10349          6902642          5980136          7421468          5681677   \n",
       "10350         11058375          8488875         12396652         10391459   \n",
       "10351         12644237          8358060          8225970          8660389   \n",
       "10352          8609333          8438354          8402632         15373805   \n",
       "10353          8822736          9263766          8357299          8540703   \n",
       "...                ...              ...              ...              ...   \n",
       "51739          8652548         10550440         39944207          8389738   \n",
       "51740         11061362          8883278          8689928         10365815   \n",
       "51741          9265820         13714389          8666974          8627826   \n",
       "51742         12815659          8884078          8560747         10442510   \n",
       "51743        121613525        184841752         32005537          8440774   \n",
       "\n",
       "       storage_read_45  storage_read_46  storage_read_47  storage_read_48  \\\n",
       "10349          5966192          6109616          7567891          5846990   \n",
       "10350         10351811         10561641         12953847         12409115   \n",
       "10351          8518447          8504429         12533369          8689333   \n",
       "10352         10484490         10554563         10229382         13219005   \n",
       "10353          9111676         10458711          8559185          8507426   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         10560773         10561421          8061577         10291408   \n",
       "51740         15182218         10810828          8575559          8520356   \n",
       "51741          9018118          8547567         13605149         10844157   \n",
       "51742         10788619          9019874         12716753          8503933   \n",
       "51743          8488516          8515182         12773670          8404478   \n",
       "\n",
       "       storage_read_49  storage_read_50  storage_read_51  storage_read_52  \\\n",
       "10349          6112060         97310474         17336658         13796783   \n",
       "10350         10677140          8804297          8901499         11119837   \n",
       "10351          8477762         11506495          8358542          8709241   \n",
       "10352          8731257         19218173          8630721         10224253   \n",
       "10353          8579776          8746330          8138283         11175015   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         10779399          8870248         12336870          8387109   \n",
       "51740          8544042         11174954         10876883          8457505   \n",
       "51741          9387263          8749473         11568575          8723640   \n",
       "51742          8711987         10775934          8195325         44548114   \n",
       "51743          8671754          8709625         12353100          8481645   \n",
       "\n",
       "       storage_read_53  storage_read_54  storage_read_55  storage_read_56  \\\n",
       "10349         18713268         19894066         18332663         14661660   \n",
       "10350         10872655          8407654          8264675         10957710   \n",
       "10351         10614027         11632215          8550261          8873256   \n",
       "10352         10340196         10393288         10106051         12323110   \n",
       "10353          8595406          8902364          8332965          8361039   \n",
       "...                ...              ...              ...              ...   \n",
       "51739          8441533          8678733          9984154          8366145   \n",
       "51740          8673947         11468264          8820723          8567023   \n",
       "51741          8942341         10617363         13064802          8523383   \n",
       "51742         10726064          9026744          8445915          8507748   \n",
       "51743         10656037          8520645         12852726          8477719   \n",
       "\n",
       "       storage_read_57  storage_read_58  storage_read_59  storage_read_60  \\\n",
       "10349         19257501         15475056          8225753         10487868   \n",
       "10350          8384802          8519338         10820045         11123633   \n",
       "10351          8482540          8532818         15824394          8830350   \n",
       "10352          8414503          8578111         51290837          8305726   \n",
       "10353         10378713         12787657          8145043          8312744   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         10805324          8647382         10256019          8349905   \n",
       "51740         10860846         11391839          8842686         19812124   \n",
       "51741         11026674          8578178         24698248         13979201   \n",
       "51742          8452342          8772246         10350067          8427267   \n",
       "51743          8683958         10759111         12914466          8393423   \n",
       "\n",
       "       storage_read_61  storage_read_62  storage_read_63  storage_read_64  \\\n",
       "10349          8711097         13304050          8412879         10373481   \n",
       "10350          8390562          8462875         10507050         10178128   \n",
       "10351          8485058          8497595         11886693          8894422   \n",
       "10352          8478335         10768022         11733712          8332781   \n",
       "10353          8731626          9014585          8505092         10009366   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         10523607         10931970         10458515         10473312   \n",
       "51740          8946573          8791057         16361185          8533967   \n",
       "51741          8772399          8402494          8289403         11379152   \n",
       "51742          8871375          9076799          8532933          8453897   \n",
       "51743          8403572          8488533          8618440         10127356   \n",
       "\n",
       "       storage_read_65  storage_read_66  storage_read_67  storage_read_68  \\\n",
       "10349         10470535         16536448          8223530         10340000   \n",
       "10350         16382574          8761501         10717954          8531560   \n",
       "10351         10706747          8527169         11778510          8781740   \n",
       "10352          8727201         37670116          8313523         14102287   \n",
       "10353          8416168          8670220          8173819         11315161   \n",
       "...                ...              ...              ...              ...   \n",
       "51739          8897988          8904247         10592698         10284166   \n",
       "51740         10285427         10425740         14478042          8404877   \n",
       "51741          8891009         12734972          8470994         11670816   \n",
       "51742         10826378          8773135         12721326          8321676   \n",
       "51743         10800592          8739328          8859179         10626537   \n",
       "\n",
       "       storage_read_69  storage_read_70  storage_read_71  storage_read_72  \\\n",
       "10349         10688828          8955038         12202825         10595663   \n",
       "10350         10897303         10484143         12811571          8488820   \n",
       "10351          8727389          8651815         16139815          8840701   \n",
       "10352          8417725          8587518          8106971         11671120   \n",
       "10353          8706034         10193845          8395020         13228150   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         10645271          8708176          8212278         10063170   \n",
       "51740         10849198          8573393         11482042          8369284   \n",
       "51741          8811621          8407754          8323347         13188208   \n",
       "51742          8820357          9187835         10663898         12077850   \n",
       "51743          8491552          8609366         12850855         10143318   \n",
       "\n",
       "       storage_read_73  storage_read_74  storage_read_75  storage_read_76  \\\n",
       "10349          8486823          8729727         16683279          8353251   \n",
       "10350         15389367          8672187          8966090          8564948   \n",
       "10351         10429474         10289087         10259087         15087479   \n",
       "10352          8380392         10593747          9990942         13421741   \n",
       "10353          8414112          8699331         10276658         14740368   \n",
       "...                ...              ...              ...              ...   \n",
       "51739          8608993          8872729         10399184         15170931   \n",
       "51740          8366118        425288531         16584794          8028567   \n",
       "51741         37612145         10137071         10231144         10281107   \n",
       "51742         10707120          8944022         10376270         14255277   \n",
       "51743          8639329          8785810          8955660          8627274   \n",
       "\n",
       "       storage_read_77  storage_read_78  storage_read_79  storage_read_80  \\\n",
       "10349         10586755         10801437         12082993          8381621   \n",
       "10350         10642362         10904969         10565104          8309026   \n",
       "10351         12543331          8513447          8334728         49994365   \n",
       "10352          8099989          8337930          9794444         13672608   \n",
       "10353         19832494          9120454          8469223          8499963   \n",
       "...                ...              ...              ...              ...   \n",
       "51739          8495125          8894359         10181892         10564106   \n",
       "51740          8464932         11595003          8473635          8138972   \n",
       "51741         13505613         10125422          8181015          8437772   \n",
       "51742        204156921         11073784          8657728          8620637   \n",
       "51743         12390340          8597459          8685329          8541182   \n",
       "\n",
       "       storage_read_81  storage_read_82  storage_read_83  storage_read_84  \\\n",
       "10349          8410435          8652209          8350547         14692345   \n",
       "10350          8398710         11412777         11117744         10269720   \n",
       "10351          8215618          8604742         10609323         12144078   \n",
       "10352          8370689          8488835          8143470          8434725   \n",
       "10353         12941210         11575268         10465656          8591943   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         25030421          9560755         10371851         10836861   \n",
       "51740         10260020         11467672          8666207         10387038   \n",
       "51741         11977832          8704510          8287773         12731769   \n",
       "51742         11086617          9195539         10913934          9769349   \n",
       "51743         10543093          9054845         11005979          9027678   \n",
       "\n",
       "       storage_read_85  storage_read_86  storage_read_87  storage_read_88  \\\n",
       "10349          8516878          8561044         10250409         13190273   \n",
       "10350         10484975         12959735          8814519          8323007   \n",
       "10351          8253432          8037491         19018142          8976236   \n",
       "10352         11667065         10441879         10184217         10116199   \n",
       "10353         12923118          8777033          8478963          9835609   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         20334727          9053671         12760438          8553624   \n",
       "51740         10282057         10161966         15367902         10421462   \n",
       "51741         11889629          8305773          8260662          8381328   \n",
       "51742         10543973          8680376          8475656          8847838   \n",
       "51743         10336373          8583459          8733106         10385317   \n",
       "\n",
       "       storage_read_89  storage_read_90  storage_read_91  storage_read_92  \\\n",
       "10349          8769430         10986805          8454508         10891473   \n",
       "10350         12631073         10974987          8929813          8664836   \n",
       "10351         14604671          8491854          8458781          8644519   \n",
       "10352         13860272          8283912          8162210         10321826   \n",
       "10353         13224206          8787755          8390613         10190604   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         10949804          8850878          8448312         10734659   \n",
       "51740         10333816         10445888         13501332          8430543   \n",
       "51741         10625474         13328911          8362958          8665567   \n",
       "51742         10940193         11764926          8283324          8308861   \n",
       "51743         14261698          8253850          8613903          8640237   \n",
       "\n",
       "       storage_read_93  storage_read_94  storage_read_95  storage_read_96  \\\n",
       "10349          8417138          8533933         10391721         35806246   \n",
       "10350          8474154         10504975         15641122          8475338   \n",
       "10351         12173688          8200359         10443159         10640156   \n",
       "10352         12093021          8624351          8241190         10282456   \n",
       "10353         10415175         16058700          8202801          8540888   \n",
       "...                ...              ...              ...              ...   \n",
       "51739         11196281         10785306          8586234        108780991   \n",
       "51740         10671941          8216823         40377534          8543653   \n",
       "51741          8946453         11349207          8320162         12359587   \n",
       "51742         10414160         35778257         10405549          8629303   \n",
       "51743         10522594         32691958         10649389          8178480   \n",
       "\n",
       "       storage_read_97  storage_read_98  storage_read_99  storage_read_100  \\\n",
       "10349          8826651          8717912          8454972           8442490   \n",
       "10350          8388229          8444432         11467017           8686724   \n",
       "10351         12070560          8194655          8352542           8501466   \n",
       "10352         10056107         15757540          8070230           8206376   \n",
       "10353          8601314         12820082          8374002          10188733   \n",
       "...                ...              ...              ...               ...   \n",
       "51739          8453552          8562735         10457979           8459255   \n",
       "51740         10606720          8618171         13969326           8597634   \n",
       "51741          8756083         11043137          8270922           8361199   \n",
       "51742         10616899         36756805          8406101           8237047   \n",
       "51743          8178202         11877307          8553348          10298336   \n",
       "\n",
       "       storage_write_1  storage_write_2  storage_write_3  storage_write_4  \\\n",
       "10349           216608           202423           195257           187535   \n",
       "10350           230811           202367           189571           187479   \n",
       "10351           231441           206663           195774           191534   \n",
       "10352           228108           206534           191349           179127   \n",
       "10353           225126           202459           186867           187553   \n",
       "...                ...              ...              ...              ...   \n",
       "51739           226367           196811           179293           183904   \n",
       "51740           225849           199479           186868           189220   \n",
       "51741           226850           202738           191590           188387   \n",
       "51742           227443           206184           189739           189351   \n",
       "51743           233203           205202           191258           188554   \n",
       "\n",
       "       storage_write_5  storage_write_6  storage_write_7  storage_write_8  \\\n",
       "10349           188441           187998           185386           184164   \n",
       "10350           189404           188516           186590           185831   \n",
       "10351           195608           189182           193127           187053   \n",
       "10352           184793           186886           186646           181609   \n",
       "10353           188071           187904           188441           186627   \n",
       "...                ...              ...              ...              ...   \n",
       "51739           184367           181053           182886           182089   \n",
       "51740           184108           184960           193275           184554   \n",
       "51741           184239           181942           182684           184573   \n",
       "51742           183480           185628           186498           179869   \n",
       "51743           185221           184869           185518           184481   \n",
       "\n",
       "       storage_write_9  storage_write_10  storage_write_11  storage_write_12  \\\n",
       "10349           190424            184905            234738            190812   \n",
       "10350           189256            186034            181015            184330   \n",
       "10351           187553            190108            185589            185664   \n",
       "10352           181609            181146            184886            185386   \n",
       "10353           226348            181923            172571            181498   \n",
       "...                ...               ...               ...               ...   \n",
       "51739           181756            183867            180959            182978   \n",
       "51740           185479            182331            183498            182294   \n",
       "51741           198221            183869            183572            183591   \n",
       "51742           188813            180832            178850            183850   \n",
       "51743           182406            182425            187017            183054   \n",
       "\n",
       "       storage_write_13  storage_write_14  storage_write_15  storage_write_16  \\\n",
       "10349            185016            184960            182534            181294   \n",
       "10350            186312            183089            185571            184053   \n",
       "10351            187590            185793            185108            182016   \n",
       "10352            189109            184831            181775            183146   \n",
       "10353            173368            176571            171979            173923   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            184070            179515            183552            182867   \n",
       "51740            182294            176257            185701            180257   \n",
       "51741            181943            179294            180387            178887   \n",
       "51742            185832            180702            188980            179017   \n",
       "51743            188592            183592            186554            182351   \n",
       "\n",
       "       storage_write_17  storage_write_18  storage_write_19  storage_write_20  \\\n",
       "10349            187220            186405            184331            184867   \n",
       "10350            183645            186404            183793            184627   \n",
       "10351            188127            184830            185738            187923   \n",
       "10352            186219            185683            186238            184386   \n",
       "10353            174034            171775            175275            179312   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            183182            181367            182256            223459   \n",
       "51740            184665            182146            178664            178702   \n",
       "51741            181165            182573            183554            179721   \n",
       "51742            186776            179739            180202            181406   \n",
       "51743            180962            185332            182351            181554   \n",
       "\n",
       "       storage_write_21  storage_write_22  storage_write_23  storage_write_24  \\\n",
       "10349            184127            183127            184368            179942   \n",
       "10350            183035            185442            183108            184479   \n",
       "10351            183164            184572            220479            199127   \n",
       "10352            178146            182090            181775            182294   \n",
       "10353            174367            176108            173497            180961   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            189163            181423            181274            179664   \n",
       "51740            231701            186165            177090            181905   \n",
       "51741            184850            177388            179479            178202   \n",
       "51742            185999            183332            188202            180610   \n",
       "51743            182813            183702            180962            185777   \n",
       "\n",
       "       storage_write_25  storage_write_26  storage_write_27  storage_write_28  \\\n",
       "10349            185590            180812            187738            181571   \n",
       "10350            185757            184867            230330            190961   \n",
       "10351            190109            182813            188886            184682   \n",
       "10352            183127            180719            184738            185571   \n",
       "10353            178293            176868            177183            174164   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            179978            181959            180830            181867   \n",
       "51740            179849            181257            185201            176665   \n",
       "51741            182609            178424            185461            178998   \n",
       "51742            180794            179869            187239            183295   \n",
       "51743            182498            183351            181129            185332   \n",
       "\n",
       "       storage_write_29  storage_write_30  storage_write_31  storage_write_32  \\\n",
       "10349            185072            182701            185887            180683   \n",
       "10350            184498            178442            183404            184793   \n",
       "10351            187738            184868            188498            187498   \n",
       "10352            184720            185719            185108            180868   \n",
       "10353            175609            174461            176923            180831   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            180719            179941            178831            179886   \n",
       "51740            181276            176054            184850            180220   \n",
       "51741            179906            179332            181425            180646   \n",
       "51742            182055            179666            178054            179295   \n",
       "51743            185258            230091            195535            185165   \n",
       "\n",
       "       storage_write_33  storage_write_34  storage_write_35  storage_write_36  \\\n",
       "10349            183812            182349            186627            185127   \n",
       "10350            186887            185182            183479            184590   \n",
       "10351            184368            185275            181534            183738   \n",
       "10352            183868            178720            185831            180701   \n",
       "10353            179034            176386            173145            171015   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            183052            178237            180442            182812   \n",
       "51740            181701            181072            182664            182646   \n",
       "51741            181739            177869            177887            181961   \n",
       "51742            186424            177647            179425            181276   \n",
       "51743            186591            184146            186295            183962   \n",
       "\n",
       "       storage_write_37  storage_write_38  storage_write_39  storage_write_40  \\\n",
       "10349            188553            179979            182942            180090   \n",
       "10350            181682            182794            184108            183719   \n",
       "10351            193219            185571            185608            186349   \n",
       "10352            189793            180034            185868            178720   \n",
       "10353            178498            175812            173331            175627   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            179868            177978            178793            179775   \n",
       "51740            185238            178072            183350            179757   \n",
       "51741            182443            177369            180165            176276   \n",
       "51742            188091            184554            184276            175814   \n",
       "51743            186961            185999            187573            183795   \n",
       "\n",
       "       storage_write_41  storage_write_42  storage_write_43  storage_write_44  \\\n",
       "10349            186405            180739            183220            178831   \n",
       "10350            183294            185108            182034            174942   \n",
       "10351            186571            182813            185423            185701   \n",
       "10352            185682            181942            184275            177590   \n",
       "10353            177405            177904            172997            175071   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            180923            181200            179923            180719   \n",
       "51740            182479            182091            184812            181368   \n",
       "51741            180147            175295            180869            179461   \n",
       "51742            179739            176832            180776            180462   \n",
       "51743            185110            184870            184202            182147   \n",
       "\n",
       "       storage_write_45  storage_write_46  storage_write_47  storage_write_48  \\\n",
       "10349            185645            184090            184997            183960   \n",
       "10350            183405            184367            190534            185757   \n",
       "10351            185608            185349            183442            187164   \n",
       "10352            185423            186775            186905            185775   \n",
       "10353            174831            179405            174220            173164   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            178034            175793            181386            177090   \n",
       "51740            182071            176979            182331            181035   \n",
       "51741            179535            182350            180257            176924   \n",
       "51742            176369            182517            225590            187554   \n",
       "51743            184721            184924            187592            183925   \n",
       "\n",
       "       storage_write_49  storage_write_50  storage_write_51  storage_write_52  \\\n",
       "10349            181072            180219            183164            179720   \n",
       "10350            180979            182867            187016            184145   \n",
       "10351            189386            181960            188145            184367   \n",
       "10352            183849            179330            181720            181850   \n",
       "10353            176071            173127            174035            177664   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            179848            177867            181978            180478   \n",
       "51740            184276            179683            181238            180831   \n",
       "51741            180313            180443            182314            177332   \n",
       "51742            172794            177018            179128            176351   \n",
       "51743            185406            182758            186258            183813   \n",
       "\n",
       "       storage_write_53  storage_write_54  storage_write_55  storage_write_56  \\\n",
       "10349            182590            178016            185756            176349   \n",
       "10350            183961            185645            186182            184608   \n",
       "10351            191701            183090            187794            183942   \n",
       "10352            221922            189368            187683            186553   \n",
       "10353            177571            177571            174849            173664   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            185349            177793            180164            181460   \n",
       "51740            184164            178609            180183            178035   \n",
       "51741            184868            181480            183683            178739   \n",
       "51742            180443            175240            175573            179832   \n",
       "51743            186369            182758            184147            183610   \n",
       "\n",
       "       storage_write_57  storage_write_58  storage_write_59  storage_write_60  \\\n",
       "10349            186572            179294            181867            180757   \n",
       "10350            184257            183905            186294            182738   \n",
       "10351            184405            184942            185034            183590   \n",
       "10352            179349            184905            184812            181349   \n",
       "10353            175738            176053            172386            178627   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            179885            180015            178757            179923   \n",
       "51740            180942            178942            188628            181961   \n",
       "51741            185665            180072            182221            179276   \n",
       "51742            177499            179647            178795            184461   \n",
       "51743            186239            181758            184110            184036   \n",
       "\n",
       "       storage_write_61  storage_write_62  storage_write_63  storage_write_64  \\\n",
       "10349            183405            179349            190164            214423   \n",
       "10350            184794            182867            185793            183923   \n",
       "10351            185608            182904            188238            187182   \n",
       "10352            188108            180034            180812            186590   \n",
       "10353            176071            173738            176219            174219   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            178090            176016            183793            178793   \n",
       "51740            184443            179479            181220            179609   \n",
       "51741            183979            179479            207313            181147   \n",
       "51742            185332            184536            182758            181850   \n",
       "51743            185888            184091            185461            184906   \n",
       "\n",
       "       storage_write_65  storage_write_66  storage_write_67  storage_write_68  \\\n",
       "10349            182849            181349            187923            181405   \n",
       "10350            182793            184905            182367            184072   \n",
       "10351            193645            183497            189738            185460   \n",
       "10352            182015            184756            186961            178572   \n",
       "10353            210015            183109            175775            175571   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            177942            178608            182627            176885   \n",
       "51740            182905            177054            178961            181794   \n",
       "51741            173998            172814            176350            172925   \n",
       "51742            185962            185406            181554            182258   \n",
       "51743            185258            182258            184703            183202   \n",
       "\n",
       "       storage_write_69  storage_write_70  storage_write_71  storage_write_72  \\\n",
       "10349            183738            180923            185738            177868   \n",
       "10350            186182            184793            183164            182553   \n",
       "10351            187182            185775            188349            185108   \n",
       "10352            183035            182682            188534            183590   \n",
       "10353            178479            176238            181719            177145   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            180886            183515            182923            179831   \n",
       "51740            180572            178349            183405            181924   \n",
       "51741            173351            172462            173295            171091   \n",
       "51742            184591            183591            187535            183517   \n",
       "51743            188683            183165            187147            182758   \n",
       "\n",
       "       storage_write_73  storage_write_74  storage_write_75  storage_write_76  \\\n",
       "10349            184535            182442            182109            181052   \n",
       "10350            181757            184275            185516            181664   \n",
       "10351            184682            184849            184090            212312   \n",
       "10352            181850            181238            180793            182183   \n",
       "10353            175312            182886            174942            177571   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            182682            183015            208348            184868   \n",
       "51740            183498            187627            213386            188442   \n",
       "51741            171332            174813            178795            172572   \n",
       "51742            186998            184684            179350            179036   \n",
       "51743            182351            184240            187110            183018   \n",
       "\n",
       "       storage_write_77  storage_write_78  storage_write_79  storage_write_80  \\\n",
       "10349            184201            179794            184720            181312   \n",
       "10350            183868            183072            184145            183553   \n",
       "10351            185071            177219            183423            178553   \n",
       "10352            184812            182220            185219            183331   \n",
       "10353            171739            174572            177257            175886   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            179293            184089            181163            179775   \n",
       "51740            181108            181387            184331            180035   \n",
       "51741            174979            178202            176017            172998   \n",
       "51742            178221            182147            186610            180684   \n",
       "51743            187425            182739            185295            183351   \n",
       "\n",
       "       storage_write_81  storage_write_82  storage_write_83  storage_write_84  \\\n",
       "10349            184979            179997            181905            180664   \n",
       "10350            208700            188146            184849            183627   \n",
       "10351            176442            180145            183571            179071   \n",
       "10352            183294            183164            186515            177238   \n",
       "10353            171738            176164            175479            174979   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            177886            179867            181571            183348   \n",
       "51740            185145            178220            181350            178554   \n",
       "51741            174887            174091            174128            173276   \n",
       "51742            188776            178591            184646            183054   \n",
       "51743            182850            185850            212035            178314   \n",
       "\n",
       "       storage_write_85  storage_write_86  storage_write_87  storage_write_88  \\\n",
       "10349            183924            178368            186034            179776   \n",
       "10350            186109            183238            183701            184553   \n",
       "10351            180683            177312            179775            176794   \n",
       "10352            183831            179294            179683            183534   \n",
       "10353            177905            174405            178034            176145   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            178775            182385            177627            180533   \n",
       "51740            183887            184794            184424            185165   \n",
       "51741            177942            177405            171572            169221   \n",
       "51742            180887            181684            183055            177980   \n",
       "51743            177221            173666            176721            172480   \n",
       "\n",
       "       storage_write_89  storage_write_90  storage_write_91  storage_write_92  \\\n",
       "10349            184590            181035            180219            180997   \n",
       "10350            185053            184497            182794            184664   \n",
       "10351            182794            183627            182201            177793   \n",
       "10352            179979            181627            181849            183997   \n",
       "10353            171127            176830            173293            173460   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            177905            177571            182571            178700   \n",
       "51740            179405            183961            183368            182239   \n",
       "51741            172221            178554            175961            175684   \n",
       "51742            181591            178091            185350            181980   \n",
       "51743            176851            175406            180332            172424   \n",
       "\n",
       "       storage_write_93  storage_write_94  storage_write_95  storage_write_96  \\\n",
       "10349            185664            179367            184960            180924   \n",
       "10350            180312            182998            184719            182145   \n",
       "10351            186386            178183            179923            174146   \n",
       "10352            183812            185571            182571            180164   \n",
       "10353            175849            168998            176256            177016   \n",
       "...                 ...               ...               ...               ...   \n",
       "51739            178626            178442            178793            177294   \n",
       "51740            183498            178572            181701            183405   \n",
       "51741            171220            175535            177368            173573   \n",
       "51742            178869            181684            180498            183906   \n",
       "51743            175203            175851            180166            175351   \n",
       "\n",
       "       storage_write_97  storage_write_98  storage_write_99  storage_write_100  \n",
       "10349            185590            180720            183368             179145  \n",
       "10350            184886            182090            184664             185682  \n",
       "10351            176572            179812            187275             182664  \n",
       "10352            185960            183552            187053             184460  \n",
       "10353            173367            174146            178108             174423  \n",
       "...                 ...               ...               ...                ...  \n",
       "51739            185293            179145            179701             182218  \n",
       "51740            179405            180220            181109             181832  \n",
       "51741            175313            173720            176294             176165  \n",
       "51742            186480            180406            183017             177332  \n",
       "51743            172573            175035            172925             172943  \n",
       "\n",
       "[41395 rows x 215 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict_train[\"feat_gpu_dc_a6_32_14_a6_53\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f6a00bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu_sleep_1s</th>\n",
       "      <th>cpu_sleep_2s</th>\n",
       "      <th>cpu_sleep_5s</th>\n",
       "      <th>cpu_sleep_10s</th>\n",
       "      <th>cpu_sleep_120s</th>\n",
       "      <th>cpu_hash</th>\n",
       "      <th>cpu_pseudorandom</th>\n",
       "      <th>cpu_urandom</th>\n",
       "      <th>cpu_fib</th>\n",
       "      <th>gpu_matrixmul</th>\n",
       "      <th>gpu_sum</th>\n",
       "      <th>gpu_scopy</th>\n",
       "      <th>mem_list</th>\n",
       "      <th>mem_reserve</th>\n",
       "      <th>mem_csvread</th>\n",
       "      <th>storage_read_1</th>\n",
       "      <th>storage_read_2</th>\n",
       "      <th>storage_read_3</th>\n",
       "      <th>storage_read_4</th>\n",
       "      <th>storage_read_5</th>\n",
       "      <th>storage_read_6</th>\n",
       "      <th>storage_read_7</th>\n",
       "      <th>storage_read_8</th>\n",
       "      <th>storage_read_9</th>\n",
       "      <th>storage_read_10</th>\n",
       "      <th>storage_read_11</th>\n",
       "      <th>storage_read_12</th>\n",
       "      <th>storage_read_13</th>\n",
       "      <th>storage_read_14</th>\n",
       "      <th>storage_read_15</th>\n",
       "      <th>storage_read_16</th>\n",
       "      <th>storage_read_17</th>\n",
       "      <th>storage_read_18</th>\n",
       "      <th>storage_read_19</th>\n",
       "      <th>storage_read_20</th>\n",
       "      <th>storage_read_21</th>\n",
       "      <th>storage_read_22</th>\n",
       "      <th>storage_read_23</th>\n",
       "      <th>storage_read_24</th>\n",
       "      <th>storage_read_25</th>\n",
       "      <th>storage_read_26</th>\n",
       "      <th>storage_read_27</th>\n",
       "      <th>storage_read_28</th>\n",
       "      <th>storage_read_29</th>\n",
       "      <th>storage_read_30</th>\n",
       "      <th>storage_read_31</th>\n",
       "      <th>storage_read_32</th>\n",
       "      <th>storage_read_33</th>\n",
       "      <th>storage_read_34</th>\n",
       "      <th>storage_read_35</th>\n",
       "      <th>storage_read_36</th>\n",
       "      <th>storage_read_37</th>\n",
       "      <th>storage_read_38</th>\n",
       "      <th>storage_read_39</th>\n",
       "      <th>storage_read_40</th>\n",
       "      <th>storage_read_41</th>\n",
       "      <th>storage_read_42</th>\n",
       "      <th>storage_read_43</th>\n",
       "      <th>storage_read_44</th>\n",
       "      <th>storage_read_45</th>\n",
       "      <th>storage_read_46</th>\n",
       "      <th>storage_read_47</th>\n",
       "      <th>storage_read_48</th>\n",
       "      <th>storage_read_49</th>\n",
       "      <th>storage_read_50</th>\n",
       "      <th>storage_read_51</th>\n",
       "      <th>storage_read_52</th>\n",
       "      <th>storage_read_53</th>\n",
       "      <th>storage_read_54</th>\n",
       "      <th>storage_read_55</th>\n",
       "      <th>storage_read_56</th>\n",
       "      <th>storage_read_57</th>\n",
       "      <th>storage_read_58</th>\n",
       "      <th>storage_read_59</th>\n",
       "      <th>storage_read_60</th>\n",
       "      <th>storage_read_61</th>\n",
       "      <th>storage_read_62</th>\n",
       "      <th>storage_read_63</th>\n",
       "      <th>storage_read_64</th>\n",
       "      <th>storage_read_65</th>\n",
       "      <th>storage_read_66</th>\n",
       "      <th>storage_read_67</th>\n",
       "      <th>storage_read_68</th>\n",
       "      <th>storage_read_69</th>\n",
       "      <th>storage_read_70</th>\n",
       "      <th>storage_read_71</th>\n",
       "      <th>storage_read_72</th>\n",
       "      <th>storage_read_73</th>\n",
       "      <th>storage_read_74</th>\n",
       "      <th>storage_read_75</th>\n",
       "      <th>storage_read_76</th>\n",
       "      <th>storage_read_77</th>\n",
       "      <th>storage_read_78</th>\n",
       "      <th>storage_read_79</th>\n",
       "      <th>storage_read_80</th>\n",
       "      <th>storage_read_81</th>\n",
       "      <th>storage_read_82</th>\n",
       "      <th>storage_read_83</th>\n",
       "      <th>storage_read_84</th>\n",
       "      <th>storage_read_85</th>\n",
       "      <th>storage_read_86</th>\n",
       "      <th>storage_read_87</th>\n",
       "      <th>storage_read_88</th>\n",
       "      <th>storage_read_89</th>\n",
       "      <th>storage_read_90</th>\n",
       "      <th>storage_read_91</th>\n",
       "      <th>storage_read_92</th>\n",
       "      <th>storage_read_93</th>\n",
       "      <th>storage_read_94</th>\n",
       "      <th>storage_read_95</th>\n",
       "      <th>storage_read_96</th>\n",
       "      <th>storage_read_97</th>\n",
       "      <th>storage_read_98</th>\n",
       "      <th>storage_read_99</th>\n",
       "      <th>storage_read_100</th>\n",
       "      <th>storage_write_1</th>\n",
       "      <th>storage_write_2</th>\n",
       "      <th>storage_write_3</th>\n",
       "      <th>storage_write_4</th>\n",
       "      <th>storage_write_5</th>\n",
       "      <th>storage_write_6</th>\n",
       "      <th>storage_write_7</th>\n",
       "      <th>storage_write_8</th>\n",
       "      <th>storage_write_9</th>\n",
       "      <th>storage_write_10</th>\n",
       "      <th>storage_write_11</th>\n",
       "      <th>storage_write_12</th>\n",
       "      <th>storage_write_13</th>\n",
       "      <th>storage_write_14</th>\n",
       "      <th>storage_write_15</th>\n",
       "      <th>storage_write_16</th>\n",
       "      <th>storage_write_17</th>\n",
       "      <th>storage_write_18</th>\n",
       "      <th>storage_write_19</th>\n",
       "      <th>storage_write_20</th>\n",
       "      <th>storage_write_21</th>\n",
       "      <th>storage_write_22</th>\n",
       "      <th>storage_write_23</th>\n",
       "      <th>storage_write_24</th>\n",
       "      <th>storage_write_25</th>\n",
       "      <th>storage_write_26</th>\n",
       "      <th>storage_write_27</th>\n",
       "      <th>storage_write_28</th>\n",
       "      <th>storage_write_29</th>\n",
       "      <th>storage_write_30</th>\n",
       "      <th>storage_write_31</th>\n",
       "      <th>storage_write_32</th>\n",
       "      <th>storage_write_33</th>\n",
       "      <th>storage_write_34</th>\n",
       "      <th>storage_write_35</th>\n",
       "      <th>storage_write_36</th>\n",
       "      <th>storage_write_37</th>\n",
       "      <th>storage_write_38</th>\n",
       "      <th>storage_write_39</th>\n",
       "      <th>storage_write_40</th>\n",
       "      <th>storage_write_41</th>\n",
       "      <th>storage_write_42</th>\n",
       "      <th>storage_write_43</th>\n",
       "      <th>storage_write_44</th>\n",
       "      <th>storage_write_45</th>\n",
       "      <th>storage_write_46</th>\n",
       "      <th>storage_write_47</th>\n",
       "      <th>storage_write_48</th>\n",
       "      <th>storage_write_49</th>\n",
       "      <th>storage_write_50</th>\n",
       "      <th>storage_write_51</th>\n",
       "      <th>storage_write_52</th>\n",
       "      <th>storage_write_53</th>\n",
       "      <th>storage_write_54</th>\n",
       "      <th>storage_write_55</th>\n",
       "      <th>storage_write_56</th>\n",
       "      <th>storage_write_57</th>\n",
       "      <th>storage_write_58</th>\n",
       "      <th>storage_write_59</th>\n",
       "      <th>storage_write_60</th>\n",
       "      <th>storage_write_61</th>\n",
       "      <th>storage_write_62</th>\n",
       "      <th>storage_write_63</th>\n",
       "      <th>storage_write_64</th>\n",
       "      <th>storage_write_65</th>\n",
       "      <th>storage_write_66</th>\n",
       "      <th>storage_write_67</th>\n",
       "      <th>storage_write_68</th>\n",
       "      <th>storage_write_69</th>\n",
       "      <th>storage_write_70</th>\n",
       "      <th>storage_write_71</th>\n",
       "      <th>storage_write_72</th>\n",
       "      <th>storage_write_73</th>\n",
       "      <th>storage_write_74</th>\n",
       "      <th>storage_write_75</th>\n",
       "      <th>storage_write_76</th>\n",
       "      <th>storage_write_77</th>\n",
       "      <th>storage_write_78</th>\n",
       "      <th>storage_write_79</th>\n",
       "      <th>storage_write_80</th>\n",
       "      <th>storage_write_81</th>\n",
       "      <th>storage_write_82</th>\n",
       "      <th>storage_write_83</th>\n",
       "      <th>storage_write_84</th>\n",
       "      <th>storage_write_85</th>\n",
       "      <th>storage_write_86</th>\n",
       "      <th>storage_write_87</th>\n",
       "      <th>storage_write_88</th>\n",
       "      <th>storage_write_89</th>\n",
       "      <th>storage_write_90</th>\n",
       "      <th>storage_write_91</th>\n",
       "      <th>storage_write_92</th>\n",
       "      <th>storage_write_93</th>\n",
       "      <th>storage_write_94</th>\n",
       "      <th>storage_write_95</th>\n",
       "      <th>storage_write_96</th>\n",
       "      <th>storage_write_97</th>\n",
       "      <th>storage_write_98</th>\n",
       "      <th>storage_write_99</th>\n",
       "      <th>storage_write_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.064438</td>\n",
       "      <td>1000.043082</td>\n",
       "      <td>2500.043863</td>\n",
       "      <td>705.072362</td>\n",
       "      <td>4165.923007</td>\n",
       "      <td>47995</td>\n",
       "      <td>20373</td>\n",
       "      <td>2769748383</td>\n",
       "      <td>3536579</td>\n",
       "      <td>555686812</td>\n",
       "      <td>19477002</td>\n",
       "      <td>29388281</td>\n",
       "      <td>817643</td>\n",
       "      <td>287888516</td>\n",
       "      <td>58828470</td>\n",
       "      <td>8364038</td>\n",
       "      <td>7017214</td>\n",
       "      <td>9463958</td>\n",
       "      <td>5874610</td>\n",
       "      <td>5834036</td>\n",
       "      <td>6163534</td>\n",
       "      <td>8185817</td>\n",
       "      <td>65191595</td>\n",
       "      <td>10743708</td>\n",
       "      <td>8249743</td>\n",
       "      <td>8386057</td>\n",
       "      <td>13285525</td>\n",
       "      <td>8600055</td>\n",
       "      <td>10591487</td>\n",
       "      <td>8593019</td>\n",
       "      <td>10311100</td>\n",
       "      <td>8394093</td>\n",
       "      <td>10335859</td>\n",
       "      <td>12833343</td>\n",
       "      <td>12588715</td>\n",
       "      <td>14498683</td>\n",
       "      <td>8362205</td>\n",
       "      <td>8442037</td>\n",
       "      <td>8478500</td>\n",
       "      <td>16589263</td>\n",
       "      <td>10656245</td>\n",
       "      <td>8278965</td>\n",
       "      <td>10488080</td>\n",
       "      <td>17270055</td>\n",
       "      <td>11071465</td>\n",
       "      <td>8353131</td>\n",
       "      <td>10658801</td>\n",
       "      <td>16546467</td>\n",
       "      <td>8448149</td>\n",
       "      <td>8168855</td>\n",
       "      <td>8517519</td>\n",
       "      <td>8270187</td>\n",
       "      <td>20178332</td>\n",
       "      <td>8362612</td>\n",
       "      <td>8514000</td>\n",
       "      <td>12956972</td>\n",
       "      <td>15024698</td>\n",
       "      <td>8559722</td>\n",
       "      <td>10525339</td>\n",
       "      <td>8445131</td>\n",
       "      <td>15034717</td>\n",
       "      <td>8450167</td>\n",
       "      <td>8379705</td>\n",
       "      <td>8427297</td>\n",
       "      <td>12287033</td>\n",
       "      <td>8539650</td>\n",
       "      <td>8423780</td>\n",
       "      <td>8626112</td>\n",
       "      <td>8461798</td>\n",
       "      <td>10444694</td>\n",
       "      <td>10643803</td>\n",
       "      <td>8342170</td>\n",
       "      <td>8264559</td>\n",
       "      <td>11043819</td>\n",
       "      <td>8169522</td>\n",
       "      <td>10154084</td>\n",
       "      <td>12025739</td>\n",
       "      <td>8133819</td>\n",
       "      <td>10033696</td>\n",
       "      <td>10031658</td>\n",
       "      <td>9885697</td>\n",
       "      <td>7996191</td>\n",
       "      <td>10014974</td>\n",
       "      <td>8017523</td>\n",
       "      <td>8020320</td>\n",
       "      <td>8179263</td>\n",
       "      <td>8119245</td>\n",
       "      <td>10171751</td>\n",
       "      <td>48763469</td>\n",
       "      <td>8173614</td>\n",
       "      <td>8044190</td>\n",
       "      <td>10270935</td>\n",
       "      <td>12368737</td>\n",
       "      <td>8310077</td>\n",
       "      <td>10479008</td>\n",
       "      <td>8482742</td>\n",
       "      <td>10402101</td>\n",
       "      <td>10424730</td>\n",
       "      <td>10279417</td>\n",
       "      <td>10168658</td>\n",
       "      <td>13910190</td>\n",
       "      <td>8186837</td>\n",
       "      <td>8223411</td>\n",
       "      <td>10183269</td>\n",
       "      <td>13106491</td>\n",
       "      <td>10119898</td>\n",
       "      <td>10137621</td>\n",
       "      <td>8303503</td>\n",
       "      <td>8293485</td>\n",
       "      <td>12487273</td>\n",
       "      <td>8343077</td>\n",
       "      <td>8398466</td>\n",
       "      <td>10294120</td>\n",
       "      <td>10177046</td>\n",
       "      <td>8252188</td>\n",
       "      <td>235609</td>\n",
       "      <td>209703</td>\n",
       "      <td>189480</td>\n",
       "      <td>187203</td>\n",
       "      <td>184480</td>\n",
       "      <td>186555</td>\n",
       "      <td>184795</td>\n",
       "      <td>182629</td>\n",
       "      <td>181591</td>\n",
       "      <td>178259</td>\n",
       "      <td>178073</td>\n",
       "      <td>186240</td>\n",
       "      <td>182054</td>\n",
       "      <td>178999</td>\n",
       "      <td>180943</td>\n",
       "      <td>180425</td>\n",
       "      <td>177203</td>\n",
       "      <td>181722</td>\n",
       "      <td>179962</td>\n",
       "      <td>178758</td>\n",
       "      <td>180240</td>\n",
       "      <td>177925</td>\n",
       "      <td>178628</td>\n",
       "      <td>181055</td>\n",
       "      <td>176369</td>\n",
       "      <td>180425</td>\n",
       "      <td>184665</td>\n",
       "      <td>177313</td>\n",
       "      <td>181777</td>\n",
       "      <td>183110</td>\n",
       "      <td>224073</td>\n",
       "      <td>186499</td>\n",
       "      <td>185017</td>\n",
       "      <td>180221</td>\n",
       "      <td>180907</td>\n",
       "      <td>176406</td>\n",
       "      <td>179795</td>\n",
       "      <td>179925</td>\n",
       "      <td>184536</td>\n",
       "      <td>178610</td>\n",
       "      <td>180332</td>\n",
       "      <td>183276</td>\n",
       "      <td>181147</td>\n",
       "      <td>183203</td>\n",
       "      <td>180054</td>\n",
       "      <td>182796</td>\n",
       "      <td>183573</td>\n",
       "      <td>181166</td>\n",
       "      <td>176573</td>\n",
       "      <td>178536</td>\n",
       "      <td>178610</td>\n",
       "      <td>176092</td>\n",
       "      <td>179073</td>\n",
       "      <td>176332</td>\n",
       "      <td>182517</td>\n",
       "      <td>177332</td>\n",
       "      <td>178832</td>\n",
       "      <td>180832</td>\n",
       "      <td>177073</td>\n",
       "      <td>181276</td>\n",
       "      <td>179036</td>\n",
       "      <td>181444</td>\n",
       "      <td>180555</td>\n",
       "      <td>185499</td>\n",
       "      <td>177443</td>\n",
       "      <td>176647</td>\n",
       "      <td>177851</td>\n",
       "      <td>178813</td>\n",
       "      <td>178888</td>\n",
       "      <td>182055</td>\n",
       "      <td>180925</td>\n",
       "      <td>174924</td>\n",
       "      <td>181944</td>\n",
       "      <td>176629</td>\n",
       "      <td>183314</td>\n",
       "      <td>180276</td>\n",
       "      <td>176795</td>\n",
       "      <td>179129</td>\n",
       "      <td>183276</td>\n",
       "      <td>180702</td>\n",
       "      <td>180906</td>\n",
       "      <td>181091</td>\n",
       "      <td>179850</td>\n",
       "      <td>175758</td>\n",
       "      <td>176833</td>\n",
       "      <td>210203</td>\n",
       "      <td>180758</td>\n",
       "      <td>179610</td>\n",
       "      <td>179925</td>\n",
       "      <td>183110</td>\n",
       "      <td>180073</td>\n",
       "      <td>177647</td>\n",
       "      <td>178573</td>\n",
       "      <td>182925</td>\n",
       "      <td>178888</td>\n",
       "      <td>179740</td>\n",
       "      <td>180906</td>\n",
       "      <td>180906</td>\n",
       "      <td>179165</td>\n",
       "      <td>180073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.041008</td>\n",
       "      <td>1000.029479</td>\n",
       "      <td>2500.041373</td>\n",
       "      <td>705.083857</td>\n",
       "      <td>4165.598477</td>\n",
       "      <td>61767</td>\n",
       "      <td>18349</td>\n",
       "      <td>2768446772</td>\n",
       "      <td>3639596</td>\n",
       "      <td>554976039</td>\n",
       "      <td>19125025</td>\n",
       "      <td>29365156</td>\n",
       "      <td>830240</td>\n",
       "      <td>286771868</td>\n",
       "      <td>36686385</td>\n",
       "      <td>10553687</td>\n",
       "      <td>10950612</td>\n",
       "      <td>10484279</td>\n",
       "      <td>9430299</td>\n",
       "      <td>8363153</td>\n",
       "      <td>9134263</td>\n",
       "      <td>10771409</td>\n",
       "      <td>8508449</td>\n",
       "      <td>8350357</td>\n",
       "      <td>37324457</td>\n",
       "      <td>8152653</td>\n",
       "      <td>8276450</td>\n",
       "      <td>8246061</td>\n",
       "      <td>8327560</td>\n",
       "      <td>8254690</td>\n",
       "      <td>9119671</td>\n",
       "      <td>10215835</td>\n",
       "      <td>13353793</td>\n",
       "      <td>8243561</td>\n",
       "      <td>5863157</td>\n",
       "      <td>6547453</td>\n",
       "      <td>5961139</td>\n",
       "      <td>7634191</td>\n",
       "      <td>5761583</td>\n",
       "      <td>5624176</td>\n",
       "      <td>5625565</td>\n",
       "      <td>5573250</td>\n",
       "      <td>10329428</td>\n",
       "      <td>7618061</td>\n",
       "      <td>5656935</td>\n",
       "      <td>5549047</td>\n",
       "      <td>5709954</td>\n",
       "      <td>5604546</td>\n",
       "      <td>7583673</td>\n",
       "      <td>5448287</td>\n",
       "      <td>5407751</td>\n",
       "      <td>5389066</td>\n",
       "      <td>5551121</td>\n",
       "      <td>8191968</td>\n",
       "      <td>5630954</td>\n",
       "      <td>6802840</td>\n",
       "      <td>6068676</td>\n",
       "      <td>5929805</td>\n",
       "      <td>67867612</td>\n",
       "      <td>13664145</td>\n",
       "      <td>13405923</td>\n",
       "      <td>13909644</td>\n",
       "      <td>13887144</td>\n",
       "      <td>14307144</td>\n",
       "      <td>15503271</td>\n",
       "      <td>17596823</td>\n",
       "      <td>13738607</td>\n",
       "      <td>14346088</td>\n",
       "      <td>11319500</td>\n",
       "      <td>8235468</td>\n",
       "      <td>10004484</td>\n",
       "      <td>8385319</td>\n",
       "      <td>9307985</td>\n",
       "      <td>8173727</td>\n",
       "      <td>9926576</td>\n",
       "      <td>8127358</td>\n",
       "      <td>8484061</td>\n",
       "      <td>8187579</td>\n",
       "      <td>14506440</td>\n",
       "      <td>8335523</td>\n",
       "      <td>8609597</td>\n",
       "      <td>8212524</td>\n",
       "      <td>8430171</td>\n",
       "      <td>10002928</td>\n",
       "      <td>9208152</td>\n",
       "      <td>10145372</td>\n",
       "      <td>10451131</td>\n",
       "      <td>13306534</td>\n",
       "      <td>8473468</td>\n",
       "      <td>8361246</td>\n",
       "      <td>11390370</td>\n",
       "      <td>12935368</td>\n",
       "      <td>8334005</td>\n",
       "      <td>8143246</td>\n",
       "      <td>8259912</td>\n",
       "      <td>8129875</td>\n",
       "      <td>9370688</td>\n",
       "      <td>8513616</td>\n",
       "      <td>8566319</td>\n",
       "      <td>8576135</td>\n",
       "      <td>11580426</td>\n",
       "      <td>8558875</td>\n",
       "      <td>10576946</td>\n",
       "      <td>8468209</td>\n",
       "      <td>8328468</td>\n",
       "      <td>8655245</td>\n",
       "      <td>8245912</td>\n",
       "      <td>8421116</td>\n",
       "      <td>10201910</td>\n",
       "      <td>8475376</td>\n",
       "      <td>10299539</td>\n",
       "      <td>10546742</td>\n",
       "      <td>10415224</td>\n",
       "      <td>10637779</td>\n",
       "      <td>10490427</td>\n",
       "      <td>232647</td>\n",
       "      <td>237314</td>\n",
       "      <td>197351</td>\n",
       "      <td>188111</td>\n",
       "      <td>196500</td>\n",
       "      <td>199407</td>\n",
       "      <td>198370</td>\n",
       "      <td>194666</td>\n",
       "      <td>194777</td>\n",
       "      <td>187426</td>\n",
       "      <td>193722</td>\n",
       "      <td>192981</td>\n",
       "      <td>190685</td>\n",
       "      <td>193278</td>\n",
       "      <td>205685</td>\n",
       "      <td>186944</td>\n",
       "      <td>193667</td>\n",
       "      <td>194519</td>\n",
       "      <td>190407</td>\n",
       "      <td>187333</td>\n",
       "      <td>193537</td>\n",
       "      <td>188611</td>\n",
       "      <td>191685</td>\n",
       "      <td>189666</td>\n",
       "      <td>188907</td>\n",
       "      <td>194963</td>\n",
       "      <td>203758</td>\n",
       "      <td>183592</td>\n",
       "      <td>193796</td>\n",
       "      <td>186852</td>\n",
       "      <td>188074</td>\n",
       "      <td>192722</td>\n",
       "      <td>195352</td>\n",
       "      <td>184611</td>\n",
       "      <td>195555</td>\n",
       "      <td>192240</td>\n",
       "      <td>190518</td>\n",
       "      <td>192204</td>\n",
       "      <td>193759</td>\n",
       "      <td>187704</td>\n",
       "      <td>190073</td>\n",
       "      <td>190000</td>\n",
       "      <td>190111</td>\n",
       "      <td>191907</td>\n",
       "      <td>197389</td>\n",
       "      <td>187962</td>\n",
       "      <td>189963</td>\n",
       "      <td>189592</td>\n",
       "      <td>193333</td>\n",
       "      <td>191907</td>\n",
       "      <td>198241</td>\n",
       "      <td>184834</td>\n",
       "      <td>224259</td>\n",
       "      <td>197685</td>\n",
       "      <td>191704</td>\n",
       "      <td>191740</td>\n",
       "      <td>197388</td>\n",
       "      <td>183963</td>\n",
       "      <td>195185</td>\n",
       "      <td>187870</td>\n",
       "      <td>189426</td>\n",
       "      <td>189573</td>\n",
       "      <td>190833</td>\n",
       "      <td>187000</td>\n",
       "      <td>196574</td>\n",
       "      <td>192500</td>\n",
       "      <td>187833</td>\n",
       "      <td>189426</td>\n",
       "      <td>193740</td>\n",
       "      <td>186148</td>\n",
       "      <td>196110</td>\n",
       "      <td>193555</td>\n",
       "      <td>197647</td>\n",
       "      <td>192851</td>\n",
       "      <td>195000</td>\n",
       "      <td>184259</td>\n",
       "      <td>203851</td>\n",
       "      <td>189981</td>\n",
       "      <td>193741</td>\n",
       "      <td>189852</td>\n",
       "      <td>200259</td>\n",
       "      <td>186852</td>\n",
       "      <td>192907</td>\n",
       "      <td>188778</td>\n",
       "      <td>191315</td>\n",
       "      <td>189889</td>\n",
       "      <td>193129</td>\n",
       "      <td>181278</td>\n",
       "      <td>200110</td>\n",
       "      <td>191388</td>\n",
       "      <td>190055</td>\n",
       "      <td>193092</td>\n",
       "      <td>196926</td>\n",
       "      <td>187167</td>\n",
       "      <td>191296</td>\n",
       "      <td>188796</td>\n",
       "      <td>191518</td>\n",
       "      <td>190111</td>\n",
       "      <td>191685</td>\n",
       "      <td>186148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.037611</td>\n",
       "      <td>1000.024424</td>\n",
       "      <td>2500.031145</td>\n",
       "      <td>705.073316</td>\n",
       "      <td>4165.562159</td>\n",
       "      <td>43744</td>\n",
       "      <td>18894</td>\n",
       "      <td>2767824583</td>\n",
       "      <td>3674922</td>\n",
       "      <td>568956115</td>\n",
       "      <td>19147043</td>\n",
       "      <td>29372601</td>\n",
       "      <td>849961</td>\n",
       "      <td>337174835</td>\n",
       "      <td>36610868</td>\n",
       "      <td>10240594</td>\n",
       "      <td>11169278</td>\n",
       "      <td>7886692</td>\n",
       "      <td>8429394</td>\n",
       "      <td>8375524</td>\n",
       "      <td>10328280</td>\n",
       "      <td>8171228</td>\n",
       "      <td>8102914</td>\n",
       "      <td>8066598</td>\n",
       "      <td>8205395</td>\n",
       "      <td>8225264</td>\n",
       "      <td>10317188</td>\n",
       "      <td>161513133</td>\n",
       "      <td>96040033</td>\n",
       "      <td>8307302</td>\n",
       "      <td>8229079</td>\n",
       "      <td>8331209</td>\n",
       "      <td>10481725</td>\n",
       "      <td>10441132</td>\n",
       "      <td>8316190</td>\n",
       "      <td>11082556</td>\n",
       "      <td>8352357</td>\n",
       "      <td>10774539</td>\n",
       "      <td>14672347</td>\n",
       "      <td>10632465</td>\n",
       "      <td>8400449</td>\n",
       "      <td>10757890</td>\n",
       "      <td>10362261</td>\n",
       "      <td>10653706</td>\n",
       "      <td>10803871</td>\n",
       "      <td>10387742</td>\n",
       "      <td>8539875</td>\n",
       "      <td>8694801</td>\n",
       "      <td>8546098</td>\n",
       "      <td>11384278</td>\n",
       "      <td>14002237</td>\n",
       "      <td>8626542</td>\n",
       "      <td>8482357</td>\n",
       "      <td>8623264</td>\n",
       "      <td>14486792</td>\n",
       "      <td>8326968</td>\n",
       "      <td>10499168</td>\n",
       "      <td>8202450</td>\n",
       "      <td>8221913</td>\n",
       "      <td>11218408</td>\n",
       "      <td>8110969</td>\n",
       "      <td>8180135</td>\n",
       "      <td>10502891</td>\n",
       "      <td>8094598</td>\n",
       "      <td>8199376</td>\n",
       "      <td>8265802</td>\n",
       "      <td>8118839</td>\n",
       "      <td>8180635</td>\n",
       "      <td>10376243</td>\n",
       "      <td>10886316</td>\n",
       "      <td>10150687</td>\n",
       "      <td>10134484</td>\n",
       "      <td>10221003</td>\n",
       "      <td>10222336</td>\n",
       "      <td>12473295</td>\n",
       "      <td>8242913</td>\n",
       "      <td>8026783</td>\n",
       "      <td>8067061</td>\n",
       "      <td>8115358</td>\n",
       "      <td>10102262</td>\n",
       "      <td>12374202</td>\n",
       "      <td>8389005</td>\n",
       "      <td>8140672</td>\n",
       "      <td>8040006</td>\n",
       "      <td>8157598</td>\n",
       "      <td>10508799</td>\n",
       "      <td>12226740</td>\n",
       "      <td>8001488</td>\n",
       "      <td>10114076</td>\n",
       "      <td>10280520</td>\n",
       "      <td>10052298</td>\n",
       "      <td>9855651</td>\n",
       "      <td>10233021</td>\n",
       "      <td>10363095</td>\n",
       "      <td>78672579</td>\n",
       "      <td>7789654</td>\n",
       "      <td>8139931</td>\n",
       "      <td>8413061</td>\n",
       "      <td>9980318</td>\n",
       "      <td>10110503</td>\n",
       "      <td>8123968</td>\n",
       "      <td>8361598</td>\n",
       "      <td>9886670</td>\n",
       "      <td>18693785</td>\n",
       "      <td>10343928</td>\n",
       "      <td>8426820</td>\n",
       "      <td>7941154</td>\n",
       "      <td>9813522</td>\n",
       "      <td>10051854</td>\n",
       "      <td>10290373</td>\n",
       "      <td>12026833</td>\n",
       "      <td>13647867</td>\n",
       "      <td>8299746</td>\n",
       "      <td>8528116</td>\n",
       "      <td>8028506</td>\n",
       "      <td>224037</td>\n",
       "      <td>203444</td>\n",
       "      <td>190759</td>\n",
       "      <td>182999</td>\n",
       "      <td>184333</td>\n",
       "      <td>184630</td>\n",
       "      <td>183851</td>\n",
       "      <td>182333</td>\n",
       "      <td>182296</td>\n",
       "      <td>180537</td>\n",
       "      <td>182963</td>\n",
       "      <td>180574</td>\n",
       "      <td>185759</td>\n",
       "      <td>180629</td>\n",
       "      <td>186629</td>\n",
       "      <td>217092</td>\n",
       "      <td>185444</td>\n",
       "      <td>180629</td>\n",
       "      <td>180278</td>\n",
       "      <td>181463</td>\n",
       "      <td>184926</td>\n",
       "      <td>178999</td>\n",
       "      <td>181445</td>\n",
       "      <td>183222</td>\n",
       "      <td>181278</td>\n",
       "      <td>180630</td>\n",
       "      <td>182648</td>\n",
       "      <td>178592</td>\n",
       "      <td>179111</td>\n",
       "      <td>181333</td>\n",
       "      <td>183778</td>\n",
       "      <td>181036</td>\n",
       "      <td>180777</td>\n",
       "      <td>178110</td>\n",
       "      <td>183018</td>\n",
       "      <td>179851</td>\n",
       "      <td>183852</td>\n",
       "      <td>177870</td>\n",
       "      <td>185666</td>\n",
       "      <td>180148</td>\n",
       "      <td>179444</td>\n",
       "      <td>180722</td>\n",
       "      <td>178388</td>\n",
       "      <td>180815</td>\n",
       "      <td>183259</td>\n",
       "      <td>178703</td>\n",
       "      <td>182630</td>\n",
       "      <td>180536</td>\n",
       "      <td>182370</td>\n",
       "      <td>179630</td>\n",
       "      <td>181018</td>\n",
       "      <td>185796</td>\n",
       "      <td>182555</td>\n",
       "      <td>181055</td>\n",
       "      <td>180647</td>\n",
       "      <td>180074</td>\n",
       "      <td>187981</td>\n",
       "      <td>178018</td>\n",
       "      <td>182370</td>\n",
       "      <td>180426</td>\n",
       "      <td>182758</td>\n",
       "      <td>182426</td>\n",
       "      <td>180555</td>\n",
       "      <td>180556</td>\n",
       "      <td>181463</td>\n",
       "      <td>181537</td>\n",
       "      <td>182462</td>\n",
       "      <td>178740</td>\n",
       "      <td>180481</td>\n",
       "      <td>176796</td>\n",
       "      <td>212018</td>\n",
       "      <td>183684</td>\n",
       "      <td>184722</td>\n",
       "      <td>180667</td>\n",
       "      <td>177722</td>\n",
       "      <td>180296</td>\n",
       "      <td>182463</td>\n",
       "      <td>181074</td>\n",
       "      <td>180241</td>\n",
       "      <td>181574</td>\n",
       "      <td>181833</td>\n",
       "      <td>182796</td>\n",
       "      <td>184537</td>\n",
       "      <td>182851</td>\n",
       "      <td>184130</td>\n",
       "      <td>178796</td>\n",
       "      <td>182778</td>\n",
       "      <td>180240</td>\n",
       "      <td>182870</td>\n",
       "      <td>184462</td>\n",
       "      <td>179481</td>\n",
       "      <td>180685</td>\n",
       "      <td>179371</td>\n",
       "      <td>180148</td>\n",
       "      <td>180407</td>\n",
       "      <td>179555</td>\n",
       "      <td>184278</td>\n",
       "      <td>181537</td>\n",
       "      <td>179925</td>\n",
       "      <td>174852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500.038261</td>\n",
       "      <td>1000.024531</td>\n",
       "      <td>2500.031074</td>\n",
       "      <td>705.071737</td>\n",
       "      <td>4166.355214</td>\n",
       "      <td>44149</td>\n",
       "      <td>18626</td>\n",
       "      <td>2768749925</td>\n",
       "      <td>3662691</td>\n",
       "      <td>571413773</td>\n",
       "      <td>19212646</td>\n",
       "      <td>29629874</td>\n",
       "      <td>833490</td>\n",
       "      <td>287170337</td>\n",
       "      <td>36627957</td>\n",
       "      <td>17142159</td>\n",
       "      <td>37204283</td>\n",
       "      <td>10527260</td>\n",
       "      <td>10002840</td>\n",
       "      <td>19503871</td>\n",
       "      <td>8618932</td>\n",
       "      <td>8422027</td>\n",
       "      <td>8072253</td>\n",
       "      <td>21171333</td>\n",
       "      <td>9137629</td>\n",
       "      <td>10466243</td>\n",
       "      <td>10271208</td>\n",
       "      <td>9851657</td>\n",
       "      <td>10544111</td>\n",
       "      <td>11977242</td>\n",
       "      <td>8081068</td>\n",
       "      <td>10135747</td>\n",
       "      <td>15243869</td>\n",
       "      <td>10610593</td>\n",
       "      <td>8239695</td>\n",
       "      <td>10978513</td>\n",
       "      <td>12470699</td>\n",
       "      <td>8701875</td>\n",
       "      <td>8262510</td>\n",
       "      <td>8465655</td>\n",
       "      <td>8461378</td>\n",
       "      <td>14453416</td>\n",
       "      <td>68236054</td>\n",
       "      <td>8162641</td>\n",
       "      <td>8223695</td>\n",
       "      <td>8335768</td>\n",
       "      <td>8125141</td>\n",
       "      <td>9228998</td>\n",
       "      <td>8408286</td>\n",
       "      <td>10400577</td>\n",
       "      <td>8267936</td>\n",
       "      <td>8299269</td>\n",
       "      <td>8256065</td>\n",
       "      <td>9965526</td>\n",
       "      <td>8135697</td>\n",
       "      <td>8747985</td>\n",
       "      <td>8251362</td>\n",
       "      <td>8844151</td>\n",
       "      <td>10409224</td>\n",
       "      <td>11442175</td>\n",
       "      <td>8444007</td>\n",
       "      <td>10603555</td>\n",
       "      <td>8235677</td>\n",
       "      <td>8199159</td>\n",
       "      <td>8328547</td>\n",
       "      <td>9272609</td>\n",
       "      <td>10258819</td>\n",
       "      <td>10107284</td>\n",
       "      <td>10422428</td>\n",
       "      <td>10488075</td>\n",
       "      <td>10280152</td>\n",
       "      <td>11422879</td>\n",
       "      <td>8153123</td>\n",
       "      <td>8468711</td>\n",
       "      <td>41099608</td>\n",
       "      <td>7880756</td>\n",
       "      <td>8099864</td>\n",
       "      <td>11960465</td>\n",
       "      <td>8054069</td>\n",
       "      <td>9963341</td>\n",
       "      <td>10114005</td>\n",
       "      <td>10562815</td>\n",
       "      <td>10174209</td>\n",
       "      <td>11242493</td>\n",
       "      <td>8276436</td>\n",
       "      <td>8446434</td>\n",
       "      <td>8067328</td>\n",
       "      <td>7977958</td>\n",
       "      <td>9767826</td>\n",
       "      <td>34756077</td>\n",
       "      <td>8156271</td>\n",
       "      <td>8141327</td>\n",
       "      <td>12159519</td>\n",
       "      <td>8438879</td>\n",
       "      <td>8227826</td>\n",
       "      <td>9634660</td>\n",
       "      <td>10433687</td>\n",
       "      <td>8481286</td>\n",
       "      <td>8192937</td>\n",
       "      <td>8158142</td>\n",
       "      <td>8467156</td>\n",
       "      <td>11683580</td>\n",
       "      <td>8197271</td>\n",
       "      <td>8209623</td>\n",
       "      <td>8140382</td>\n",
       "      <td>10184413</td>\n",
       "      <td>8121031</td>\n",
       "      <td>9208240</td>\n",
       "      <td>8477027</td>\n",
       "      <td>10606594</td>\n",
       "      <td>8100920</td>\n",
       "      <td>8304269</td>\n",
       "      <td>8249288</td>\n",
       "      <td>12100778</td>\n",
       "      <td>7954885</td>\n",
       "      <td>224516</td>\n",
       "      <td>201423</td>\n",
       "      <td>187979</td>\n",
       "      <td>182628</td>\n",
       "      <td>183776</td>\n",
       "      <td>184869</td>\n",
       "      <td>181072</td>\n",
       "      <td>180053</td>\n",
       "      <td>182720</td>\n",
       "      <td>181295</td>\n",
       "      <td>180128</td>\n",
       "      <td>178164</td>\n",
       "      <td>180349</td>\n",
       "      <td>185201</td>\n",
       "      <td>174998</td>\n",
       "      <td>176905</td>\n",
       "      <td>179369</td>\n",
       "      <td>180961</td>\n",
       "      <td>175554</td>\n",
       "      <td>179943</td>\n",
       "      <td>179054</td>\n",
       "      <td>176979</td>\n",
       "      <td>178628</td>\n",
       "      <td>178776</td>\n",
       "      <td>176961</td>\n",
       "      <td>176369</td>\n",
       "      <td>182701</td>\n",
       "      <td>217572</td>\n",
       "      <td>184645</td>\n",
       "      <td>177906</td>\n",
       "      <td>177850</td>\n",
       "      <td>176479</td>\n",
       "      <td>177646</td>\n",
       "      <td>179443</td>\n",
       "      <td>178572</td>\n",
       "      <td>177868</td>\n",
       "      <td>178757</td>\n",
       "      <td>178053</td>\n",
       "      <td>179479</td>\n",
       "      <td>176035</td>\n",
       "      <td>179127</td>\n",
       "      <td>180831</td>\n",
       "      <td>177627</td>\n",
       "      <td>177739</td>\n",
       "      <td>179090</td>\n",
       "      <td>178572</td>\n",
       "      <td>178109</td>\n",
       "      <td>179979</td>\n",
       "      <td>178220</td>\n",
       "      <td>178238</td>\n",
       "      <td>178201</td>\n",
       "      <td>179128</td>\n",
       "      <td>178590</td>\n",
       "      <td>177980</td>\n",
       "      <td>181757</td>\n",
       "      <td>182516</td>\n",
       "      <td>179850</td>\n",
       "      <td>181035</td>\n",
       "      <td>177923</td>\n",
       "      <td>180220</td>\n",
       "      <td>179035</td>\n",
       "      <td>182572</td>\n",
       "      <td>177905</td>\n",
       "      <td>177405</td>\n",
       "      <td>177831</td>\n",
       "      <td>181979</td>\n",
       "      <td>174164</td>\n",
       "      <td>174868</td>\n",
       "      <td>178627</td>\n",
       "      <td>179794</td>\n",
       "      <td>180850</td>\n",
       "      <td>177276</td>\n",
       "      <td>175609</td>\n",
       "      <td>178442</td>\n",
       "      <td>178480</td>\n",
       "      <td>172109</td>\n",
       "      <td>179368</td>\n",
       "      <td>178850</td>\n",
       "      <td>176794</td>\n",
       "      <td>183516</td>\n",
       "      <td>175905</td>\n",
       "      <td>178646</td>\n",
       "      <td>212146</td>\n",
       "      <td>186720</td>\n",
       "      <td>175423</td>\n",
       "      <td>175794</td>\n",
       "      <td>177331</td>\n",
       "      <td>174942</td>\n",
       "      <td>183053</td>\n",
       "      <td>178905</td>\n",
       "      <td>177387</td>\n",
       "      <td>178016</td>\n",
       "      <td>180813</td>\n",
       "      <td>175627</td>\n",
       "      <td>178887</td>\n",
       "      <td>176387</td>\n",
       "      <td>178127</td>\n",
       "      <td>176961</td>\n",
       "      <td>174461</td>\n",
       "      <td>177535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500.042360</td>\n",
       "      <td>1000.043469</td>\n",
       "      <td>2500.058711</td>\n",
       "      <td>705.117631</td>\n",
       "      <td>4165.979697</td>\n",
       "      <td>43539</td>\n",
       "      <td>18949</td>\n",
       "      <td>2765913804</td>\n",
       "      <td>3589012</td>\n",
       "      <td>540192536</td>\n",
       "      <td>19112911</td>\n",
       "      <td>29337383</td>\n",
       "      <td>818865</td>\n",
       "      <td>330672592</td>\n",
       "      <td>36744595</td>\n",
       "      <td>10268563</td>\n",
       "      <td>13022823</td>\n",
       "      <td>10964596</td>\n",
       "      <td>8726981</td>\n",
       "      <td>8173873</td>\n",
       "      <td>8720722</td>\n",
       "      <td>10374933</td>\n",
       "      <td>14432666</td>\n",
       "      <td>8216354</td>\n",
       "      <td>8079466</td>\n",
       "      <td>8193539</td>\n",
       "      <td>10380118</td>\n",
       "      <td>8040355</td>\n",
       "      <td>10457914</td>\n",
       "      <td>8429168</td>\n",
       "      <td>10970966</td>\n",
       "      <td>8054984</td>\n",
       "      <td>8034707</td>\n",
       "      <td>8211780</td>\n",
       "      <td>10762449</td>\n",
       "      <td>11091039</td>\n",
       "      <td>8113188</td>\n",
       "      <td>8297854</td>\n",
       "      <td>8488593</td>\n",
       "      <td>10227563</td>\n",
       "      <td>10386173</td>\n",
       "      <td>10168952</td>\n",
       "      <td>10493895</td>\n",
       "      <td>15971822</td>\n",
       "      <td>8103132</td>\n",
       "      <td>8198187</td>\n",
       "      <td>10646894</td>\n",
       "      <td>10051472</td>\n",
       "      <td>8154669</td>\n",
       "      <td>8181984</td>\n",
       "      <td>8507408</td>\n",
       "      <td>8295613</td>\n",
       "      <td>73506876</td>\n",
       "      <td>10134916</td>\n",
       "      <td>10382637</td>\n",
       "      <td>10182323</td>\n",
       "      <td>12156014</td>\n",
       "      <td>8482648</td>\n",
       "      <td>10760059</td>\n",
       "      <td>8044541</td>\n",
       "      <td>10246785</td>\n",
       "      <td>10390192</td>\n",
       "      <td>10556246</td>\n",
       "      <td>10076787</td>\n",
       "      <td>12277957</td>\n",
       "      <td>13404691</td>\n",
       "      <td>8498334</td>\n",
       "      <td>7974170</td>\n",
       "      <td>8174670</td>\n",
       "      <td>10644339</td>\n",
       "      <td>10773356</td>\n",
       "      <td>8167096</td>\n",
       "      <td>10197193</td>\n",
       "      <td>12270513</td>\n",
       "      <td>8544741</td>\n",
       "      <td>8040819</td>\n",
       "      <td>10409210</td>\n",
       "      <td>10402803</td>\n",
       "      <td>8682240</td>\n",
       "      <td>8167207</td>\n",
       "      <td>8132744</td>\n",
       "      <td>10180490</td>\n",
       "      <td>19086303</td>\n",
       "      <td>8080355</td>\n",
       "      <td>8206984</td>\n",
       "      <td>10385118</td>\n",
       "      <td>12655122</td>\n",
       "      <td>8322336</td>\n",
       "      <td>10513024</td>\n",
       "      <td>8311576</td>\n",
       "      <td>12550345</td>\n",
       "      <td>8136818</td>\n",
       "      <td>8254669</td>\n",
       "      <td>8420279</td>\n",
       "      <td>10838967</td>\n",
       "      <td>10134286</td>\n",
       "      <td>8459723</td>\n",
       "      <td>8453612</td>\n",
       "      <td>8630741</td>\n",
       "      <td>10263063</td>\n",
       "      <td>10459192</td>\n",
       "      <td>10270433</td>\n",
       "      <td>10313711</td>\n",
       "      <td>12775306</td>\n",
       "      <td>8328168</td>\n",
       "      <td>8535927</td>\n",
       "      <td>10892670</td>\n",
       "      <td>12287180</td>\n",
       "      <td>8006189</td>\n",
       "      <td>8092984</td>\n",
       "      <td>8250984</td>\n",
       "      <td>7891635</td>\n",
       "      <td>10094064</td>\n",
       "      <td>8149521</td>\n",
       "      <td>8338835</td>\n",
       "      <td>224536</td>\n",
       "      <td>199295</td>\n",
       "      <td>184870</td>\n",
       "      <td>187332</td>\n",
       "      <td>187350</td>\n",
       "      <td>188424</td>\n",
       "      <td>183072</td>\n",
       "      <td>184313</td>\n",
       "      <td>184314</td>\n",
       "      <td>182702</td>\n",
       "      <td>176498</td>\n",
       "      <td>180628</td>\n",
       "      <td>181721</td>\n",
       "      <td>184499</td>\n",
       "      <td>179110</td>\n",
       "      <td>184832</td>\n",
       "      <td>177628</td>\n",
       "      <td>181461</td>\n",
       "      <td>182443</td>\n",
       "      <td>181369</td>\n",
       "      <td>219258</td>\n",
       "      <td>188962</td>\n",
       "      <td>178906</td>\n",
       "      <td>183573</td>\n",
       "      <td>179962</td>\n",
       "      <td>182202</td>\n",
       "      <td>184443</td>\n",
       "      <td>182314</td>\n",
       "      <td>179517</td>\n",
       "      <td>185888</td>\n",
       "      <td>179869</td>\n",
       "      <td>181202</td>\n",
       "      <td>180647</td>\n",
       "      <td>184925</td>\n",
       "      <td>179443</td>\n",
       "      <td>183647</td>\n",
       "      <td>178203</td>\n",
       "      <td>180943</td>\n",
       "      <td>183591</td>\n",
       "      <td>185665</td>\n",
       "      <td>176295</td>\n",
       "      <td>180869</td>\n",
       "      <td>180240</td>\n",
       "      <td>184628</td>\n",
       "      <td>177666</td>\n",
       "      <td>183647</td>\n",
       "      <td>180610</td>\n",
       "      <td>183740</td>\n",
       "      <td>187943</td>\n",
       "      <td>179999</td>\n",
       "      <td>180591</td>\n",
       "      <td>180129</td>\n",
       "      <td>181610</td>\n",
       "      <td>181017</td>\n",
       "      <td>180814</td>\n",
       "      <td>180832</td>\n",
       "      <td>181517</td>\n",
       "      <td>181851</td>\n",
       "      <td>185055</td>\n",
       "      <td>182462</td>\n",
       "      <td>183332</td>\n",
       "      <td>183147</td>\n",
       "      <td>181388</td>\n",
       "      <td>183388</td>\n",
       "      <td>180036</td>\n",
       "      <td>180388</td>\n",
       "      <td>185943</td>\n",
       "      <td>181517</td>\n",
       "      <td>181832</td>\n",
       "      <td>182314</td>\n",
       "      <td>181387</td>\n",
       "      <td>180184</td>\n",
       "      <td>179592</td>\n",
       "      <td>179110</td>\n",
       "      <td>210165</td>\n",
       "      <td>185276</td>\n",
       "      <td>182369</td>\n",
       "      <td>182554</td>\n",
       "      <td>181425</td>\n",
       "      <td>181203</td>\n",
       "      <td>183314</td>\n",
       "      <td>184758</td>\n",
       "      <td>181758</td>\n",
       "      <td>179444</td>\n",
       "      <td>181980</td>\n",
       "      <td>181980</td>\n",
       "      <td>181202</td>\n",
       "      <td>181443</td>\n",
       "      <td>182313</td>\n",
       "      <td>181666</td>\n",
       "      <td>179758</td>\n",
       "      <td>181610</td>\n",
       "      <td>182166</td>\n",
       "      <td>181943</td>\n",
       "      <td>176721</td>\n",
       "      <td>182795</td>\n",
       "      <td>185536</td>\n",
       "      <td>182702</td>\n",
       "      <td>183702</td>\n",
       "      <td>180887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10344</th>\n",
       "      <td>500.042652</td>\n",
       "      <td>1000.040212</td>\n",
       "      <td>2500.065565</td>\n",
       "      <td>705.136758</td>\n",
       "      <td>4166.411693</td>\n",
       "      <td>43063</td>\n",
       "      <td>18459</td>\n",
       "      <td>2740380298</td>\n",
       "      <td>3526679</td>\n",
       "      <td>569577148</td>\n",
       "      <td>19232677</td>\n",
       "      <td>29347480</td>\n",
       "      <td>817801</td>\n",
       "      <td>339656639</td>\n",
       "      <td>36588272</td>\n",
       "      <td>14433235</td>\n",
       "      <td>10009582</td>\n",
       "      <td>9216521</td>\n",
       "      <td>8741436</td>\n",
       "      <td>10552018</td>\n",
       "      <td>8931766</td>\n",
       "      <td>9884232</td>\n",
       "      <td>8464070</td>\n",
       "      <td>10761904</td>\n",
       "      <td>8687399</td>\n",
       "      <td>11119176</td>\n",
       "      <td>8511217</td>\n",
       "      <td>12999220</td>\n",
       "      <td>8445551</td>\n",
       "      <td>8930654</td>\n",
       "      <td>10666109</td>\n",
       "      <td>8652326</td>\n",
       "      <td>11023548</td>\n",
       "      <td>12625429</td>\n",
       "      <td>8622290</td>\n",
       "      <td>9734050</td>\n",
       "      <td>10969475</td>\n",
       "      <td>9132930</td>\n",
       "      <td>8634011</td>\n",
       "      <td>12062532</td>\n",
       "      <td>11000492</td>\n",
       "      <td>9057042</td>\n",
       "      <td>8366257</td>\n",
       "      <td>8511902</td>\n",
       "      <td>8683936</td>\n",
       "      <td>12530505</td>\n",
       "      <td>8528069</td>\n",
       "      <td>8527254</td>\n",
       "      <td>8652270</td>\n",
       "      <td>11511929</td>\n",
       "      <td>8363441</td>\n",
       "      <td>9530608</td>\n",
       "      <td>8735954</td>\n",
       "      <td>12636115</td>\n",
       "      <td>8185537</td>\n",
       "      <td>8400626</td>\n",
       "      <td>8541032</td>\n",
       "      <td>12219195</td>\n",
       "      <td>10313558</td>\n",
       "      <td>10300004</td>\n",
       "      <td>10234523</td>\n",
       "      <td>20340788</td>\n",
       "      <td>12987683</td>\n",
       "      <td>9360037</td>\n",
       "      <td>37126653</td>\n",
       "      <td>8796953</td>\n",
       "      <td>10531630</td>\n",
       "      <td>8321887</td>\n",
       "      <td>8239592</td>\n",
       "      <td>9573015</td>\n",
       "      <td>10964975</td>\n",
       "      <td>8537402</td>\n",
       "      <td>10649183</td>\n",
       "      <td>8824823</td>\n",
       "      <td>8247721</td>\n",
       "      <td>12513690</td>\n",
       "      <td>10300503</td>\n",
       "      <td>10574573</td>\n",
       "      <td>8616383</td>\n",
       "      <td>10614943</td>\n",
       "      <td>8548050</td>\n",
       "      <td>10372966</td>\n",
       "      <td>8208556</td>\n",
       "      <td>10707868</td>\n",
       "      <td>8304312</td>\n",
       "      <td>8690122</td>\n",
       "      <td>10611017</td>\n",
       "      <td>11990884</td>\n",
       "      <td>8568254</td>\n",
       "      <td>8852675</td>\n",
       "      <td>10436075</td>\n",
       "      <td>10375725</td>\n",
       "      <td>12465136</td>\n",
       "      <td>9604700</td>\n",
       "      <td>8496717</td>\n",
       "      <td>8467477</td>\n",
       "      <td>10947271</td>\n",
       "      <td>10556074</td>\n",
       "      <td>10594092</td>\n",
       "      <td>9514016</td>\n",
       "      <td>12742964</td>\n",
       "      <td>8457533</td>\n",
       "      <td>8287999</td>\n",
       "      <td>8094038</td>\n",
       "      <td>8314442</td>\n",
       "      <td>11916755</td>\n",
       "      <td>8460533</td>\n",
       "      <td>8389682</td>\n",
       "      <td>10402243</td>\n",
       "      <td>12856629</td>\n",
       "      <td>8309554</td>\n",
       "      <td>9761938</td>\n",
       "      <td>8386867</td>\n",
       "      <td>11771591</td>\n",
       "      <td>8557772</td>\n",
       "      <td>232997</td>\n",
       "      <td>209367</td>\n",
       "      <td>198682</td>\n",
       "      <td>194682</td>\n",
       "      <td>198016</td>\n",
       "      <td>188774</td>\n",
       "      <td>191719</td>\n",
       "      <td>194812</td>\n",
       "      <td>188590</td>\n",
       "      <td>190182</td>\n",
       "      <td>191534</td>\n",
       "      <td>187478</td>\n",
       "      <td>186386</td>\n",
       "      <td>188016</td>\n",
       "      <td>188886</td>\n",
       "      <td>186219</td>\n",
       "      <td>191534</td>\n",
       "      <td>186275</td>\n",
       "      <td>185794</td>\n",
       "      <td>186646</td>\n",
       "      <td>191775</td>\n",
       "      <td>182572</td>\n",
       "      <td>190645</td>\n",
       "      <td>185979</td>\n",
       "      <td>181942</td>\n",
       "      <td>186979</td>\n",
       "      <td>189645</td>\n",
       "      <td>189442</td>\n",
       "      <td>190367</td>\n",
       "      <td>186905</td>\n",
       "      <td>194904</td>\n",
       "      <td>186423</td>\n",
       "      <td>192627</td>\n",
       "      <td>188793</td>\n",
       "      <td>186386</td>\n",
       "      <td>188663</td>\n",
       "      <td>187479</td>\n",
       "      <td>191553</td>\n",
       "      <td>187071</td>\n",
       "      <td>195219</td>\n",
       "      <td>188423</td>\n",
       "      <td>185831</td>\n",
       "      <td>190145</td>\n",
       "      <td>186775</td>\n",
       "      <td>189015</td>\n",
       "      <td>191016</td>\n",
       "      <td>188201</td>\n",
       "      <td>191330</td>\n",
       "      <td>188127</td>\n",
       "      <td>189571</td>\n",
       "      <td>179182</td>\n",
       "      <td>217404</td>\n",
       "      <td>194496</td>\n",
       "      <td>193941</td>\n",
       "      <td>194664</td>\n",
       "      <td>189257</td>\n",
       "      <td>187405</td>\n",
       "      <td>188201</td>\n",
       "      <td>191997</td>\n",
       "      <td>188923</td>\n",
       "      <td>191534</td>\n",
       "      <td>187127</td>\n",
       "      <td>191052</td>\n",
       "      <td>190905</td>\n",
       "      <td>190775</td>\n",
       "      <td>189663</td>\n",
       "      <td>191108</td>\n",
       "      <td>193145</td>\n",
       "      <td>187460</td>\n",
       "      <td>191257</td>\n",
       "      <td>192034</td>\n",
       "      <td>189516</td>\n",
       "      <td>193163</td>\n",
       "      <td>189775</td>\n",
       "      <td>189145</td>\n",
       "      <td>187737</td>\n",
       "      <td>189312</td>\n",
       "      <td>184405</td>\n",
       "      <td>186293</td>\n",
       "      <td>188960</td>\n",
       "      <td>190294</td>\n",
       "      <td>190349</td>\n",
       "      <td>187960</td>\n",
       "      <td>189478</td>\n",
       "      <td>193312</td>\n",
       "      <td>189312</td>\n",
       "      <td>189442</td>\n",
       "      <td>187256</td>\n",
       "      <td>191775</td>\n",
       "      <td>191386</td>\n",
       "      <td>188312</td>\n",
       "      <td>186997</td>\n",
       "      <td>190849</td>\n",
       "      <td>187553</td>\n",
       "      <td>188552</td>\n",
       "      <td>187942</td>\n",
       "      <td>189793</td>\n",
       "      <td>187293</td>\n",
       "      <td>190830</td>\n",
       "      <td>189256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10345</th>\n",
       "      <td>500.040205</td>\n",
       "      <td>1000.049537</td>\n",
       "      <td>2500.068000</td>\n",
       "      <td>705.135873</td>\n",
       "      <td>4166.416356</td>\n",
       "      <td>44004</td>\n",
       "      <td>18331</td>\n",
       "      <td>2755378146</td>\n",
       "      <td>3616329</td>\n",
       "      <td>546020451</td>\n",
       "      <td>19186393</td>\n",
       "      <td>29331371</td>\n",
       "      <td>810620</td>\n",
       "      <td>334051760</td>\n",
       "      <td>36451475</td>\n",
       "      <td>10766896</td>\n",
       "      <td>9261784</td>\n",
       "      <td>12653097</td>\n",
       "      <td>8176259</td>\n",
       "      <td>10908506</td>\n",
       "      <td>9196470</td>\n",
       "      <td>10396327</td>\n",
       "      <td>8391627</td>\n",
       "      <td>10341549</td>\n",
       "      <td>10339994</td>\n",
       "      <td>12752633</td>\n",
       "      <td>10378030</td>\n",
       "      <td>8624198</td>\n",
       "      <td>8669586</td>\n",
       "      <td>8906881</td>\n",
       "      <td>10327290</td>\n",
       "      <td>12760559</td>\n",
       "      <td>8353294</td>\n",
       "      <td>8625198</td>\n",
       "      <td>12309823</td>\n",
       "      <td>8989935</td>\n",
       "      <td>8476700</td>\n",
       "      <td>13080758</td>\n",
       "      <td>14029285</td>\n",
       "      <td>8241443</td>\n",
       "      <td>8490589</td>\n",
       "      <td>8670216</td>\n",
       "      <td>35873721</td>\n",
       "      <td>12199584</td>\n",
       "      <td>8460811</td>\n",
       "      <td>10615250</td>\n",
       "      <td>8236092</td>\n",
       "      <td>10165311</td>\n",
       "      <td>8770956</td>\n",
       "      <td>10962079</td>\n",
       "      <td>8448774</td>\n",
       "      <td>10279735</td>\n",
       "      <td>8468829</td>\n",
       "      <td>8811029</td>\n",
       "      <td>8279980</td>\n",
       "      <td>10638157</td>\n",
       "      <td>10198976</td>\n",
       "      <td>10889839</td>\n",
       "      <td>8424311</td>\n",
       "      <td>8554292</td>\n",
       "      <td>10329623</td>\n",
       "      <td>10851487</td>\n",
       "      <td>8205055</td>\n",
       "      <td>8328794</td>\n",
       "      <td>9923868</td>\n",
       "      <td>8607847</td>\n",
       "      <td>10503195</td>\n",
       "      <td>12551542</td>\n",
       "      <td>10427363</td>\n",
       "      <td>8754123</td>\n",
       "      <td>8351830</td>\n",
       "      <td>10251661</td>\n",
       "      <td>10292401</td>\n",
       "      <td>14539854</td>\n",
       "      <td>8475922</td>\n",
       "      <td>8548885</td>\n",
       "      <td>8526644</td>\n",
       "      <td>13238239</td>\n",
       "      <td>8292999</td>\n",
       "      <td>10594713</td>\n",
       "      <td>8286109</td>\n",
       "      <td>10224050</td>\n",
       "      <td>8674531</td>\n",
       "      <td>8597291</td>\n",
       "      <td>8578551</td>\n",
       "      <td>11088300</td>\n",
       "      <td>10243050</td>\n",
       "      <td>8391367</td>\n",
       "      <td>88405068</td>\n",
       "      <td>126904593</td>\n",
       "      <td>183228285</td>\n",
       "      <td>196640707</td>\n",
       "      <td>580739428</td>\n",
       "      <td>188881423</td>\n",
       "      <td>51053492</td>\n",
       "      <td>10391770</td>\n",
       "      <td>10697637</td>\n",
       "      <td>10840784</td>\n",
       "      <td>10381233</td>\n",
       "      <td>8190407</td>\n",
       "      <td>10407086</td>\n",
       "      <td>10834618</td>\n",
       "      <td>10185607</td>\n",
       "      <td>10750748</td>\n",
       "      <td>8514143</td>\n",
       "      <td>8530866</td>\n",
       "      <td>10707359</td>\n",
       "      <td>10609824</td>\n",
       "      <td>8423330</td>\n",
       "      <td>10723582</td>\n",
       "      <td>12699541</td>\n",
       "      <td>8722790</td>\n",
       "      <td>8367978</td>\n",
       "      <td>14089617</td>\n",
       "      <td>8303998</td>\n",
       "      <td>229386</td>\n",
       "      <td>196387</td>\n",
       "      <td>188646</td>\n",
       "      <td>190313</td>\n",
       "      <td>184016</td>\n",
       "      <td>179350</td>\n",
       "      <td>186035</td>\n",
       "      <td>183664</td>\n",
       "      <td>184091</td>\n",
       "      <td>181609</td>\n",
       "      <td>186202</td>\n",
       "      <td>178665</td>\n",
       "      <td>179072</td>\n",
       "      <td>177942</td>\n",
       "      <td>182720</td>\n",
       "      <td>183721</td>\n",
       "      <td>181980</td>\n",
       "      <td>180368</td>\n",
       "      <td>184349</td>\n",
       "      <td>178405</td>\n",
       "      <td>187442</td>\n",
       "      <td>180498</td>\n",
       "      <td>178980</td>\n",
       "      <td>184905</td>\n",
       "      <td>185590</td>\n",
       "      <td>183517</td>\n",
       "      <td>183979</td>\n",
       "      <td>184313</td>\n",
       "      <td>184461</td>\n",
       "      <td>182257</td>\n",
       "      <td>181647</td>\n",
       "      <td>177424</td>\n",
       "      <td>178257</td>\n",
       "      <td>176572</td>\n",
       "      <td>179998</td>\n",
       "      <td>182572</td>\n",
       "      <td>182886</td>\n",
       "      <td>183016</td>\n",
       "      <td>185201</td>\n",
       "      <td>234664</td>\n",
       "      <td>187350</td>\n",
       "      <td>180721</td>\n",
       "      <td>179350</td>\n",
       "      <td>177998</td>\n",
       "      <td>187294</td>\n",
       "      <td>185831</td>\n",
       "      <td>182572</td>\n",
       "      <td>184183</td>\n",
       "      <td>187146</td>\n",
       "      <td>184906</td>\n",
       "      <td>180479</td>\n",
       "      <td>181535</td>\n",
       "      <td>178906</td>\n",
       "      <td>180812</td>\n",
       "      <td>189127</td>\n",
       "      <td>182609</td>\n",
       "      <td>185257</td>\n",
       "      <td>183665</td>\n",
       "      <td>186072</td>\n",
       "      <td>184628</td>\n",
       "      <td>186572</td>\n",
       "      <td>178794</td>\n",
       "      <td>177943</td>\n",
       "      <td>183905</td>\n",
       "      <td>183442</td>\n",
       "      <td>178924</td>\n",
       "      <td>179183</td>\n",
       "      <td>182090</td>\n",
       "      <td>179998</td>\n",
       "      <td>180424</td>\n",
       "      <td>174257</td>\n",
       "      <td>180035</td>\n",
       "      <td>185646</td>\n",
       "      <td>179146</td>\n",
       "      <td>187628</td>\n",
       "      <td>181942</td>\n",
       "      <td>184831</td>\n",
       "      <td>175498</td>\n",
       "      <td>188072</td>\n",
       "      <td>178683</td>\n",
       "      <td>185979</td>\n",
       "      <td>182091</td>\n",
       "      <td>181164</td>\n",
       "      <td>177905</td>\n",
       "      <td>185646</td>\n",
       "      <td>184109</td>\n",
       "      <td>181664</td>\n",
       "      <td>178720</td>\n",
       "      <td>181257</td>\n",
       "      <td>180202</td>\n",
       "      <td>186405</td>\n",
       "      <td>179387</td>\n",
       "      <td>184813</td>\n",
       "      <td>209183</td>\n",
       "      <td>184887</td>\n",
       "      <td>179702</td>\n",
       "      <td>176275</td>\n",
       "      <td>181294</td>\n",
       "      <td>186424</td>\n",
       "      <td>183609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10346</th>\n",
       "      <td>500.043270</td>\n",
       "      <td>1000.034373</td>\n",
       "      <td>2500.053717</td>\n",
       "      <td>705.117217</td>\n",
       "      <td>4166.182475</td>\n",
       "      <td>43303</td>\n",
       "      <td>17950</td>\n",
       "      <td>2752920936</td>\n",
       "      <td>3529923</td>\n",
       "      <td>570518014</td>\n",
       "      <td>19128836</td>\n",
       "      <td>29334449</td>\n",
       "      <td>802916</td>\n",
       "      <td>287805705</td>\n",
       "      <td>36582654</td>\n",
       "      <td>10700014</td>\n",
       "      <td>41615332</td>\n",
       "      <td>10493758</td>\n",
       "      <td>11654651</td>\n",
       "      <td>8312526</td>\n",
       "      <td>8801909</td>\n",
       "      <td>11185804</td>\n",
       "      <td>12873783</td>\n",
       "      <td>10470147</td>\n",
       "      <td>10691182</td>\n",
       "      <td>8632762</td>\n",
       "      <td>11436635</td>\n",
       "      <td>10824901</td>\n",
       "      <td>10862698</td>\n",
       "      <td>8549190</td>\n",
       "      <td>11428376</td>\n",
       "      <td>10498091</td>\n",
       "      <td>8526949</td>\n",
       "      <td>8261212</td>\n",
       "      <td>14817037</td>\n",
       "      <td>11499208</td>\n",
       "      <td>8239601</td>\n",
       "      <td>8665744</td>\n",
       "      <td>8344377</td>\n",
       "      <td>8617485</td>\n",
       "      <td>14489005</td>\n",
       "      <td>8745483</td>\n",
       "      <td>8407691</td>\n",
       "      <td>8419469</td>\n",
       "      <td>13146262</td>\n",
       "      <td>8422506</td>\n",
       "      <td>13586386</td>\n",
       "      <td>10289853</td>\n",
       "      <td>10239742</td>\n",
       "      <td>10300483</td>\n",
       "      <td>10163354</td>\n",
       "      <td>10353982</td>\n",
       "      <td>12447715</td>\n",
       "      <td>8622874</td>\n",
       "      <td>8371932</td>\n",
       "      <td>8583578</td>\n",
       "      <td>8424395</td>\n",
       "      <td>8210897</td>\n",
       "      <td>10401481</td>\n",
       "      <td>10065023</td>\n",
       "      <td>10441647</td>\n",
       "      <td>10205280</td>\n",
       "      <td>13378944</td>\n",
       "      <td>8233527</td>\n",
       "      <td>10669552</td>\n",
       "      <td>8376692</td>\n",
       "      <td>8521986</td>\n",
       "      <td>8379544</td>\n",
       "      <td>8281804</td>\n",
       "      <td>8249453</td>\n",
       "      <td>10553387</td>\n",
       "      <td>10230742</td>\n",
       "      <td>10374796</td>\n",
       "      <td>10378149</td>\n",
       "      <td>10618238</td>\n",
       "      <td>8423821</td>\n",
       "      <td>10603090</td>\n",
       "      <td>8230286</td>\n",
       "      <td>8321803</td>\n",
       "      <td>8207157</td>\n",
       "      <td>8356784</td>\n",
       "      <td>8341803</td>\n",
       "      <td>10762458</td>\n",
       "      <td>11372784</td>\n",
       "      <td>5571597</td>\n",
       "      <td>34136667</td>\n",
       "      <td>5602208</td>\n",
       "      <td>5648781</td>\n",
       "      <td>5637226</td>\n",
       "      <td>5660781</td>\n",
       "      <td>5791224</td>\n",
       "      <td>5712299</td>\n",
       "      <td>6615565</td>\n",
       "      <td>5781594</td>\n",
       "      <td>7685163</td>\n",
       "      <td>5643244</td>\n",
       "      <td>6252830</td>\n",
       "      <td>5964648</td>\n",
       "      <td>5949426</td>\n",
       "      <td>6087590</td>\n",
       "      <td>5775742</td>\n",
       "      <td>5940463</td>\n",
       "      <td>5790724</td>\n",
       "      <td>8064417</td>\n",
       "      <td>5993221</td>\n",
       "      <td>9065072</td>\n",
       "      <td>5895038</td>\n",
       "      <td>6084313</td>\n",
       "      <td>7946549</td>\n",
       "      <td>5851649</td>\n",
       "      <td>5760669</td>\n",
       "      <td>5885316</td>\n",
       "      <td>5691058</td>\n",
       "      <td>5848853</td>\n",
       "      <td>5767780</td>\n",
       "      <td>238034</td>\n",
       "      <td>207479</td>\n",
       "      <td>199220</td>\n",
       "      <td>189997</td>\n",
       "      <td>190034</td>\n",
       "      <td>188165</td>\n",
       "      <td>188664</td>\n",
       "      <td>188886</td>\n",
       "      <td>187868</td>\n",
       "      <td>182683</td>\n",
       "      <td>185553</td>\n",
       "      <td>188665</td>\n",
       "      <td>189535</td>\n",
       "      <td>184349</td>\n",
       "      <td>189146</td>\n",
       "      <td>180276</td>\n",
       "      <td>186479</td>\n",
       "      <td>181757</td>\n",
       "      <td>184942</td>\n",
       "      <td>186627</td>\n",
       "      <td>188665</td>\n",
       "      <td>185461</td>\n",
       "      <td>184275</td>\n",
       "      <td>185016</td>\n",
       "      <td>186182</td>\n",
       "      <td>184054</td>\n",
       "      <td>192887</td>\n",
       "      <td>186905</td>\n",
       "      <td>186720</td>\n",
       "      <td>227849</td>\n",
       "      <td>185349</td>\n",
       "      <td>180405</td>\n",
       "      <td>176609</td>\n",
       "      <td>177905</td>\n",
       "      <td>184053</td>\n",
       "      <td>177294</td>\n",
       "      <td>179479</td>\n",
       "      <td>181554</td>\n",
       "      <td>175849</td>\n",
       "      <td>176164</td>\n",
       "      <td>182091</td>\n",
       "      <td>182257</td>\n",
       "      <td>184794</td>\n",
       "      <td>177775</td>\n",
       "      <td>183535</td>\n",
       "      <td>176942</td>\n",
       "      <td>178942</td>\n",
       "      <td>178609</td>\n",
       "      <td>179794</td>\n",
       "      <td>179868</td>\n",
       "      <td>180942</td>\n",
       "      <td>184424</td>\n",
       "      <td>175997</td>\n",
       "      <td>176738</td>\n",
       "      <td>183349</td>\n",
       "      <td>177980</td>\n",
       "      <td>181016</td>\n",
       "      <td>182090</td>\n",
       "      <td>181313</td>\n",
       "      <td>182868</td>\n",
       "      <td>180201</td>\n",
       "      <td>177035</td>\n",
       "      <td>181757</td>\n",
       "      <td>181960</td>\n",
       "      <td>181257</td>\n",
       "      <td>181442</td>\n",
       "      <td>182257</td>\n",
       "      <td>179924</td>\n",
       "      <td>179609</td>\n",
       "      <td>179053</td>\n",
       "      <td>180146</td>\n",
       "      <td>179387</td>\n",
       "      <td>176016</td>\n",
       "      <td>180387</td>\n",
       "      <td>181831</td>\n",
       "      <td>179146</td>\n",
       "      <td>176757</td>\n",
       "      <td>179312</td>\n",
       "      <td>177646</td>\n",
       "      <td>183275</td>\n",
       "      <td>179220</td>\n",
       "      <td>178905</td>\n",
       "      <td>178442</td>\n",
       "      <td>176294</td>\n",
       "      <td>209812</td>\n",
       "      <td>176387</td>\n",
       "      <td>187609</td>\n",
       "      <td>177183</td>\n",
       "      <td>179683</td>\n",
       "      <td>181054</td>\n",
       "      <td>184479</td>\n",
       "      <td>174961</td>\n",
       "      <td>177406</td>\n",
       "      <td>182164</td>\n",
       "      <td>182276</td>\n",
       "      <td>174868</td>\n",
       "      <td>174202</td>\n",
       "      <td>178775</td>\n",
       "      <td>184665</td>\n",
       "      <td>181701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10347</th>\n",
       "      <td>500.040546</td>\n",
       "      <td>1000.036786</td>\n",
       "      <td>2500.058650</td>\n",
       "      <td>705.119620</td>\n",
       "      <td>4166.240330</td>\n",
       "      <td>43318</td>\n",
       "      <td>18653</td>\n",
       "      <td>2757718048</td>\n",
       "      <td>3587949</td>\n",
       "      <td>572492850</td>\n",
       "      <td>19139505</td>\n",
       "      <td>29346128</td>\n",
       "      <td>857489</td>\n",
       "      <td>287146293</td>\n",
       "      <td>36531070</td>\n",
       "      <td>7746027</td>\n",
       "      <td>6965056</td>\n",
       "      <td>9066824</td>\n",
       "      <td>6071568</td>\n",
       "      <td>7789823</td>\n",
       "      <td>6499692</td>\n",
       "      <td>6179585</td>\n",
       "      <td>5935736</td>\n",
       "      <td>6255602</td>\n",
       "      <td>5934606</td>\n",
       "      <td>9081546</td>\n",
       "      <td>6027290</td>\n",
       "      <td>6244657</td>\n",
       "      <td>6062141</td>\n",
       "      <td>6259157</td>\n",
       "      <td>6015364</td>\n",
       "      <td>6217621</td>\n",
       "      <td>6095641</td>\n",
       "      <td>6226288</td>\n",
       "      <td>5996513</td>\n",
       "      <td>7203275</td>\n",
       "      <td>6350638</td>\n",
       "      <td>5584222</td>\n",
       "      <td>5720720</td>\n",
       "      <td>7638379</td>\n",
       "      <td>5787701</td>\n",
       "      <td>5607574</td>\n",
       "      <td>5784219</td>\n",
       "      <td>7620991</td>\n",
       "      <td>8522850</td>\n",
       "      <td>5655351</td>\n",
       "      <td>5590574</td>\n",
       "      <td>5508538</td>\n",
       "      <td>5673776</td>\n",
       "      <td>5583629</td>\n",
       "      <td>5662406</td>\n",
       "      <td>5520205</td>\n",
       "      <td>5757090</td>\n",
       "      <td>5552129</td>\n",
       "      <td>81639414</td>\n",
       "      <td>17272234</td>\n",
       "      <td>13489339</td>\n",
       "      <td>14355420</td>\n",
       "      <td>16265876</td>\n",
       "      <td>14593176</td>\n",
       "      <td>14240941</td>\n",
       "      <td>16800277</td>\n",
       "      <td>95419935</td>\n",
       "      <td>15664995</td>\n",
       "      <td>13811594</td>\n",
       "      <td>14234792</td>\n",
       "      <td>13965629</td>\n",
       "      <td>15944381</td>\n",
       "      <td>15625866</td>\n",
       "      <td>14367272</td>\n",
       "      <td>16059564</td>\n",
       "      <td>16711556</td>\n",
       "      <td>16399874</td>\n",
       "      <td>18146333</td>\n",
       "      <td>15963862</td>\n",
       "      <td>16386300</td>\n",
       "      <td>15787901</td>\n",
       "      <td>14289681</td>\n",
       "      <td>16336968</td>\n",
       "      <td>19176949</td>\n",
       "      <td>13638392</td>\n",
       "      <td>14143942</td>\n",
       "      <td>13644392</td>\n",
       "      <td>13841205</td>\n",
       "      <td>12021655</td>\n",
       "      <td>10069773</td>\n",
       "      <td>8457258</td>\n",
       "      <td>10332825</td>\n",
       "      <td>10412009</td>\n",
       "      <td>10309122</td>\n",
       "      <td>10432213</td>\n",
       "      <td>12140153</td>\n",
       "      <td>8370500</td>\n",
       "      <td>8240113</td>\n",
       "      <td>8567090</td>\n",
       "      <td>8321574</td>\n",
       "      <td>8582701</td>\n",
       "      <td>9984941</td>\n",
       "      <td>10855837</td>\n",
       "      <td>9019546</td>\n",
       "      <td>10675710</td>\n",
       "      <td>9031824</td>\n",
       "      <td>8775975</td>\n",
       "      <td>9857684</td>\n",
       "      <td>12174727</td>\n",
       "      <td>8710292</td>\n",
       "      <td>8470887</td>\n",
       "      <td>8859901</td>\n",
       "      <td>8691310</td>\n",
       "      <td>10102921</td>\n",
       "      <td>8681088</td>\n",
       "      <td>10930299</td>\n",
       "      <td>8426239</td>\n",
       "      <td>8544831</td>\n",
       "      <td>8428277</td>\n",
       "      <td>229256</td>\n",
       "      <td>204182</td>\n",
       "      <td>195757</td>\n",
       "      <td>185812</td>\n",
       "      <td>192053</td>\n",
       "      <td>183146</td>\n",
       "      <td>188479</td>\n",
       "      <td>180497</td>\n",
       "      <td>182646</td>\n",
       "      <td>183979</td>\n",
       "      <td>180719</td>\n",
       "      <td>178887</td>\n",
       "      <td>182201</td>\n",
       "      <td>182775</td>\n",
       "      <td>186034</td>\n",
       "      <td>181553</td>\n",
       "      <td>185590</td>\n",
       "      <td>183183</td>\n",
       "      <td>178331</td>\n",
       "      <td>181553</td>\n",
       "      <td>182405</td>\n",
       "      <td>184497</td>\n",
       "      <td>182368</td>\n",
       "      <td>181165</td>\n",
       "      <td>180812</td>\n",
       "      <td>181534</td>\n",
       "      <td>187349</td>\n",
       "      <td>183016</td>\n",
       "      <td>186887</td>\n",
       "      <td>181275</td>\n",
       "      <td>186498</td>\n",
       "      <td>182257</td>\n",
       "      <td>188386</td>\n",
       "      <td>229460</td>\n",
       "      <td>189905</td>\n",
       "      <td>185275</td>\n",
       "      <td>185146</td>\n",
       "      <td>182257</td>\n",
       "      <td>185239</td>\n",
       "      <td>182590</td>\n",
       "      <td>182072</td>\n",
       "      <td>181423</td>\n",
       "      <td>181609</td>\n",
       "      <td>179646</td>\n",
       "      <td>188442</td>\n",
       "      <td>180460</td>\n",
       "      <td>185535</td>\n",
       "      <td>182072</td>\n",
       "      <td>187090</td>\n",
       "      <td>184424</td>\n",
       "      <td>181960</td>\n",
       "      <td>182423</td>\n",
       "      <td>182905</td>\n",
       "      <td>182220</td>\n",
       "      <td>181794</td>\n",
       "      <td>181238</td>\n",
       "      <td>182572</td>\n",
       "      <td>180164</td>\n",
       "      <td>182849</td>\n",
       "      <td>184627</td>\n",
       "      <td>183942</td>\n",
       "      <td>185127</td>\n",
       "      <td>186423</td>\n",
       "      <td>182646</td>\n",
       "      <td>181498</td>\n",
       "      <td>183405</td>\n",
       "      <td>183182</td>\n",
       "      <td>183701</td>\n",
       "      <td>183034</td>\n",
       "      <td>185571</td>\n",
       "      <td>181591</td>\n",
       "      <td>179794</td>\n",
       "      <td>184664</td>\n",
       "      <td>184461</td>\n",
       "      <td>182497</td>\n",
       "      <td>180719</td>\n",
       "      <td>183164</td>\n",
       "      <td>183387</td>\n",
       "      <td>180535</td>\n",
       "      <td>184646</td>\n",
       "      <td>182424</td>\n",
       "      <td>180257</td>\n",
       "      <td>186090</td>\n",
       "      <td>182497</td>\n",
       "      <td>182405</td>\n",
       "      <td>186127</td>\n",
       "      <td>213386</td>\n",
       "      <td>180238</td>\n",
       "      <td>179887</td>\n",
       "      <td>178979</td>\n",
       "      <td>176794</td>\n",
       "      <td>174460</td>\n",
       "      <td>175424</td>\n",
       "      <td>174109</td>\n",
       "      <td>174831</td>\n",
       "      <td>174813</td>\n",
       "      <td>172109</td>\n",
       "      <td>175979</td>\n",
       "      <td>177294</td>\n",
       "      <td>172461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10348</th>\n",
       "      <td>500.042124</td>\n",
       "      <td>1000.034972</td>\n",
       "      <td>2500.060365</td>\n",
       "      <td>705.135626</td>\n",
       "      <td>4166.281850</td>\n",
       "      <td>43061</td>\n",
       "      <td>18618</td>\n",
       "      <td>2754970102</td>\n",
       "      <td>3579423</td>\n",
       "      <td>566216901</td>\n",
       "      <td>19252474</td>\n",
       "      <td>29356167</td>\n",
       "      <td>848396</td>\n",
       "      <td>337989969</td>\n",
       "      <td>36649639</td>\n",
       "      <td>10595427</td>\n",
       "      <td>10941403</td>\n",
       "      <td>8897117</td>\n",
       "      <td>12554585</td>\n",
       "      <td>5915140</td>\n",
       "      <td>7002570</td>\n",
       "      <td>8170664</td>\n",
       "      <td>6298949</td>\n",
       "      <td>120559917</td>\n",
       "      <td>22046508</td>\n",
       "      <td>9814067</td>\n",
       "      <td>11924056</td>\n",
       "      <td>13318945</td>\n",
       "      <td>8633843</td>\n",
       "      <td>9340852</td>\n",
       "      <td>11002903</td>\n",
       "      <td>11705708</td>\n",
       "      <td>8963339</td>\n",
       "      <td>9091578</td>\n",
       "      <td>8865859</td>\n",
       "      <td>11550913</td>\n",
       "      <td>14050805</td>\n",
       "      <td>8625121</td>\n",
       "      <td>10306079</td>\n",
       "      <td>10317171</td>\n",
       "      <td>16339106</td>\n",
       "      <td>8255830</td>\n",
       "      <td>10491077</td>\n",
       "      <td>10418059</td>\n",
       "      <td>13816864</td>\n",
       "      <td>8439605</td>\n",
       "      <td>8534807</td>\n",
       "      <td>8450197</td>\n",
       "      <td>10557113</td>\n",
       "      <td>10189840</td>\n",
       "      <td>10061638</td>\n",
       "      <td>10128193</td>\n",
       "      <td>10037527</td>\n",
       "      <td>10053341</td>\n",
       "      <td>12144998</td>\n",
       "      <td>13021467</td>\n",
       "      <td>10882849</td>\n",
       "      <td>8602658</td>\n",
       "      <td>8366717</td>\n",
       "      <td>8767378</td>\n",
       "      <td>10708759</td>\n",
       "      <td>8748527</td>\n",
       "      <td>8619713</td>\n",
       "      <td>10663445</td>\n",
       "      <td>8445438</td>\n",
       "      <td>8844488</td>\n",
       "      <td>10643408</td>\n",
       "      <td>8723897</td>\n",
       "      <td>8757952</td>\n",
       "      <td>9159354</td>\n",
       "      <td>8804192</td>\n",
       "      <td>9138114</td>\n",
       "      <td>10766795</td>\n",
       "      <td>8711601</td>\n",
       "      <td>8330847</td>\n",
       "      <td>8724546</td>\n",
       "      <td>10361523</td>\n",
       "      <td>13714661</td>\n",
       "      <td>10638092</td>\n",
       "      <td>8830025</td>\n",
       "      <td>8518307</td>\n",
       "      <td>8880284</td>\n",
       "      <td>8312792</td>\n",
       "      <td>8513104</td>\n",
       "      <td>10505502</td>\n",
       "      <td>8528418</td>\n",
       "      <td>8370014</td>\n",
       "      <td>10565816</td>\n",
       "      <td>8432809</td>\n",
       "      <td>8654973</td>\n",
       "      <td>84861339</td>\n",
       "      <td>9245779</td>\n",
       "      <td>8520141</td>\n",
       "      <td>8815211</td>\n",
       "      <td>15644597</td>\n",
       "      <td>11345194</td>\n",
       "      <td>11087087</td>\n",
       "      <td>8536455</td>\n",
       "      <td>15163030</td>\n",
       "      <td>8653564</td>\n",
       "      <td>10635871</td>\n",
       "      <td>59397766</td>\n",
       "      <td>16672879</td>\n",
       "      <td>8379106</td>\n",
       "      <td>10297894</td>\n",
       "      <td>10140192</td>\n",
       "      <td>10383171</td>\n",
       "      <td>10144841</td>\n",
       "      <td>12698750</td>\n",
       "      <td>8234182</td>\n",
       "      <td>8551585</td>\n",
       "      <td>8427883</td>\n",
       "      <td>8543770</td>\n",
       "      <td>11294676</td>\n",
       "      <td>10568649</td>\n",
       "      <td>232812</td>\n",
       "      <td>199960</td>\n",
       "      <td>197960</td>\n",
       "      <td>190331</td>\n",
       "      <td>190793</td>\n",
       "      <td>188016</td>\n",
       "      <td>188145</td>\n",
       "      <td>187146</td>\n",
       "      <td>191960</td>\n",
       "      <td>187905</td>\n",
       "      <td>187553</td>\n",
       "      <td>186627</td>\n",
       "      <td>187979</td>\n",
       "      <td>182590</td>\n",
       "      <td>187276</td>\n",
       "      <td>184794</td>\n",
       "      <td>186090</td>\n",
       "      <td>183460</td>\n",
       "      <td>189201</td>\n",
       "      <td>183590</td>\n",
       "      <td>189368</td>\n",
       "      <td>185960</td>\n",
       "      <td>183016</td>\n",
       "      <td>182998</td>\n",
       "      <td>186887</td>\n",
       "      <td>182960</td>\n",
       "      <td>186498</td>\n",
       "      <td>184108</td>\n",
       "      <td>184035</td>\n",
       "      <td>179850</td>\n",
       "      <td>183108</td>\n",
       "      <td>186275</td>\n",
       "      <td>187534</td>\n",
       "      <td>184442</td>\n",
       "      <td>189645</td>\n",
       "      <td>180238</td>\n",
       "      <td>189738</td>\n",
       "      <td>183109</td>\n",
       "      <td>185646</td>\n",
       "      <td>186202</td>\n",
       "      <td>187664</td>\n",
       "      <td>182164</td>\n",
       "      <td>182424</td>\n",
       "      <td>184479</td>\n",
       "      <td>187201</td>\n",
       "      <td>235033</td>\n",
       "      <td>196682</td>\n",
       "      <td>184367</td>\n",
       "      <td>179553</td>\n",
       "      <td>185071</td>\n",
       "      <td>183590</td>\n",
       "      <td>184831</td>\n",
       "      <td>190146</td>\n",
       "      <td>183034</td>\n",
       "      <td>188720</td>\n",
       "      <td>185442</td>\n",
       "      <td>183090</td>\n",
       "      <td>181349</td>\n",
       "      <td>186461</td>\n",
       "      <td>185590</td>\n",
       "      <td>187219</td>\n",
       "      <td>186238</td>\n",
       "      <td>186627</td>\n",
       "      <td>186886</td>\n",
       "      <td>188793</td>\n",
       "      <td>185146</td>\n",
       "      <td>190293</td>\n",
       "      <td>185460</td>\n",
       "      <td>188497</td>\n",
       "      <td>184683</td>\n",
       "      <td>185646</td>\n",
       "      <td>186572</td>\n",
       "      <td>192145</td>\n",
       "      <td>187979</td>\n",
       "      <td>186090</td>\n",
       "      <td>180350</td>\n",
       "      <td>189776</td>\n",
       "      <td>182812</td>\n",
       "      <td>181831</td>\n",
       "      <td>184886</td>\n",
       "      <td>187719</td>\n",
       "      <td>179627</td>\n",
       "      <td>184961</td>\n",
       "      <td>182424</td>\n",
       "      <td>186016</td>\n",
       "      <td>183053</td>\n",
       "      <td>188590</td>\n",
       "      <td>182572</td>\n",
       "      <td>187960</td>\n",
       "      <td>185904</td>\n",
       "      <td>186924</td>\n",
       "      <td>183887</td>\n",
       "      <td>189590</td>\n",
       "      <td>182978</td>\n",
       "      <td>189090</td>\n",
       "      <td>186683</td>\n",
       "      <td>181405</td>\n",
       "      <td>184035</td>\n",
       "      <td>213830</td>\n",
       "      <td>188571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10349 rows × 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cpu_sleep_1s  cpu_sleep_2s  cpu_sleep_5s  cpu_sleep_10s  \\\n",
       "0        500.064438   1000.043082   2500.043863     705.072362   \n",
       "1        500.041008   1000.029479   2500.041373     705.083857   \n",
       "2        500.037611   1000.024424   2500.031145     705.073316   \n",
       "3        500.038261   1000.024531   2500.031074     705.071737   \n",
       "4        500.042360   1000.043469   2500.058711     705.117631   \n",
       "...             ...           ...           ...            ...   \n",
       "10344    500.042652   1000.040212   2500.065565     705.136758   \n",
       "10345    500.040205   1000.049537   2500.068000     705.135873   \n",
       "10346    500.043270   1000.034373   2500.053717     705.117217   \n",
       "10347    500.040546   1000.036786   2500.058650     705.119620   \n",
       "10348    500.042124   1000.034972   2500.060365     705.135626   \n",
       "\n",
       "       cpu_sleep_120s  cpu_hash  cpu_pseudorandom  cpu_urandom  cpu_fib  \\\n",
       "0         4165.923007     47995             20373   2769748383  3536579   \n",
       "1         4165.598477     61767             18349   2768446772  3639596   \n",
       "2         4165.562159     43744             18894   2767824583  3674922   \n",
       "3         4166.355214     44149             18626   2768749925  3662691   \n",
       "4         4165.979697     43539             18949   2765913804  3589012   \n",
       "...               ...       ...               ...          ...      ...   \n",
       "10344     4166.411693     43063             18459   2740380298  3526679   \n",
       "10345     4166.416356     44004             18331   2755378146  3616329   \n",
       "10346     4166.182475     43303             17950   2752920936  3529923   \n",
       "10347     4166.240330     43318             18653   2757718048  3587949   \n",
       "10348     4166.281850     43061             18618   2754970102  3579423   \n",
       "\n",
       "       gpu_matrixmul   gpu_sum  gpu_scopy  mem_list  mem_reserve  mem_csvread  \\\n",
       "0          555686812  19477002   29388281    817643    287888516     58828470   \n",
       "1          554976039  19125025   29365156    830240    286771868     36686385   \n",
       "2          568956115  19147043   29372601    849961    337174835     36610868   \n",
       "3          571413773  19212646   29629874    833490    287170337     36627957   \n",
       "4          540192536  19112911   29337383    818865    330672592     36744595   \n",
       "...              ...       ...        ...       ...          ...          ...   \n",
       "10344      569577148  19232677   29347480    817801    339656639     36588272   \n",
       "10345      546020451  19186393   29331371    810620    334051760     36451475   \n",
       "10346      570518014  19128836   29334449    802916    287805705     36582654   \n",
       "10347      572492850  19139505   29346128    857489    287146293     36531070   \n",
       "10348      566216901  19252474   29356167    848396    337989969     36649639   \n",
       "\n",
       "       storage_read_1  storage_read_2  storage_read_3  storage_read_4  \\\n",
       "0             8364038         7017214         9463958         5874610   \n",
       "1            10553687        10950612        10484279         9430299   \n",
       "2            10240594        11169278         7886692         8429394   \n",
       "3            17142159        37204283        10527260        10002840   \n",
       "4            10268563        13022823        10964596         8726981   \n",
       "...               ...             ...             ...             ...   \n",
       "10344        14433235        10009582         9216521         8741436   \n",
       "10345        10766896         9261784        12653097         8176259   \n",
       "10346        10700014        41615332        10493758        11654651   \n",
       "10347         7746027         6965056         9066824         6071568   \n",
       "10348        10595427        10941403         8897117        12554585   \n",
       "\n",
       "       storage_read_5  storage_read_6  storage_read_7  storage_read_8  \\\n",
       "0             5834036         6163534         8185817        65191595   \n",
       "1             8363153         9134263        10771409         8508449   \n",
       "2             8375524        10328280         8171228         8102914   \n",
       "3            19503871         8618932         8422027         8072253   \n",
       "4             8173873         8720722        10374933        14432666   \n",
       "...               ...             ...             ...             ...   \n",
       "10344        10552018         8931766         9884232         8464070   \n",
       "10345        10908506         9196470        10396327         8391627   \n",
       "10346         8312526         8801909        11185804        12873783   \n",
       "10347         7789823         6499692         6179585         5935736   \n",
       "10348         5915140         7002570         8170664         6298949   \n",
       "\n",
       "       storage_read_9  storage_read_10  storage_read_11  storage_read_12  \\\n",
       "0            10743708          8249743          8386057         13285525   \n",
       "1             8350357         37324457          8152653          8276450   \n",
       "2             8066598          8205395          8225264         10317188   \n",
       "3            21171333          9137629         10466243         10271208   \n",
       "4             8216354          8079466          8193539         10380118   \n",
       "...               ...              ...              ...              ...   \n",
       "10344        10761904          8687399         11119176          8511217   \n",
       "10345        10341549         10339994         12752633         10378030   \n",
       "10346        10470147         10691182          8632762         11436635   \n",
       "10347         6255602          5934606          9081546          6027290   \n",
       "10348       120559917         22046508          9814067         11924056   \n",
       "\n",
       "       storage_read_13  storage_read_14  storage_read_15  storage_read_16  \\\n",
       "0              8600055         10591487          8593019         10311100   \n",
       "1              8246061          8327560          8254690          9119671   \n",
       "2            161513133         96040033          8307302          8229079   \n",
       "3              9851657         10544111         11977242          8081068   \n",
       "4              8040355         10457914          8429168         10970966   \n",
       "...                ...              ...              ...              ...   \n",
       "10344         12999220          8445551          8930654         10666109   \n",
       "10345          8624198          8669586          8906881         10327290   \n",
       "10346         10824901         10862698          8549190         11428376   \n",
       "10347          6244657          6062141          6259157          6015364   \n",
       "10348         13318945          8633843          9340852         11002903   \n",
       "\n",
       "       storage_read_17  storage_read_18  storage_read_19  storage_read_20  \\\n",
       "0              8394093         10335859         12833343         12588715   \n",
       "1             10215835         13353793          8243561          5863157   \n",
       "2              8331209         10481725         10441132          8316190   \n",
       "3             10135747         15243869         10610593          8239695   \n",
       "4              8054984          8034707          8211780         10762449   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          8652326         11023548         12625429          8622290   \n",
       "10345         12760559          8353294          8625198         12309823   \n",
       "10346         10498091          8526949          8261212         14817037   \n",
       "10347          6217621          6095641          6226288          5996513   \n",
       "10348         11705708          8963339          9091578          8865859   \n",
       "\n",
       "       storage_read_21  storage_read_22  storage_read_23  storage_read_24  \\\n",
       "0             14498683          8362205          8442037          8478500   \n",
       "1              6547453          5961139          7634191          5761583   \n",
       "2             11082556          8352357         10774539         14672347   \n",
       "3             10978513         12470699          8701875          8262510   \n",
       "4             11091039          8113188          8297854          8488593   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          9734050         10969475          9132930          8634011   \n",
       "10345          8989935          8476700         13080758         14029285   \n",
       "10346         11499208          8239601          8665744          8344377   \n",
       "10347          7203275          6350638          5584222          5720720   \n",
       "10348         11550913         14050805          8625121         10306079   \n",
       "\n",
       "       storage_read_25  storage_read_26  storage_read_27  storage_read_28  \\\n",
       "0             16589263         10656245          8278965         10488080   \n",
       "1              5624176          5625565          5573250         10329428   \n",
       "2             10632465          8400449         10757890         10362261   \n",
       "3              8465655          8461378         14453416         68236054   \n",
       "4             10227563         10386173         10168952         10493895   \n",
       "...                ...              ...              ...              ...   \n",
       "10344         12062532         11000492          9057042          8366257   \n",
       "10345          8241443          8490589          8670216         35873721   \n",
       "10346          8617485         14489005          8745483          8407691   \n",
       "10347          7638379          5787701          5607574          5784219   \n",
       "10348         10317171         16339106          8255830         10491077   \n",
       "\n",
       "       storage_read_29  storage_read_30  storage_read_31  storage_read_32  \\\n",
       "0             17270055         11071465          8353131         10658801   \n",
       "1              7618061          5656935          5549047          5709954   \n",
       "2             10653706         10803871         10387742          8539875   \n",
       "3              8162641          8223695          8335768          8125141   \n",
       "4             15971822          8103132          8198187         10646894   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          8511902          8683936         12530505          8528069   \n",
       "10345         12199584          8460811         10615250          8236092   \n",
       "10346          8419469         13146262          8422506         13586386   \n",
       "10347          7620991          8522850          5655351          5590574   \n",
       "10348         10418059         13816864          8439605          8534807   \n",
       "\n",
       "       storage_read_33  storage_read_34  storage_read_35  storage_read_36  \\\n",
       "0             16546467          8448149          8168855          8517519   \n",
       "1              5604546          7583673          5448287          5407751   \n",
       "2              8694801          8546098         11384278         14002237   \n",
       "3              9228998          8408286         10400577          8267936   \n",
       "4             10051472          8154669          8181984          8507408   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          8527254          8652270         11511929          8363441   \n",
       "10345         10165311          8770956         10962079          8448774   \n",
       "10346         10289853         10239742         10300483         10163354   \n",
       "10347          5508538          5673776          5583629          5662406   \n",
       "10348          8450197         10557113         10189840         10061638   \n",
       "\n",
       "       storage_read_37  storage_read_38  storage_read_39  storage_read_40  \\\n",
       "0              8270187         20178332          8362612          8514000   \n",
       "1              5389066          5551121          8191968          5630954   \n",
       "2              8626542          8482357          8623264         14486792   \n",
       "3              8299269          8256065          9965526          8135697   \n",
       "4              8295613         73506876         10134916         10382637   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          9530608          8735954         12636115          8185537   \n",
       "10345         10279735          8468829          8811029          8279980   \n",
       "10346         10353982         12447715          8622874          8371932   \n",
       "10347          5520205          5757090          5552129         81639414   \n",
       "10348         10128193         10037527         10053341         12144998   \n",
       "\n",
       "       storage_read_41  storage_read_42  storage_read_43  storage_read_44  \\\n",
       "0             12956972         15024698          8559722         10525339   \n",
       "1              6802840          6068676          5929805         67867612   \n",
       "2              8326968         10499168          8202450          8221913   \n",
       "3              8747985          8251362          8844151         10409224   \n",
       "4             10182323         12156014          8482648         10760059   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          8400626          8541032         12219195         10313558   \n",
       "10345         10638157         10198976         10889839          8424311   \n",
       "10346          8583578          8424395          8210897         10401481   \n",
       "10347         17272234         13489339         14355420         16265876   \n",
       "10348         13021467         10882849          8602658          8366717   \n",
       "\n",
       "       storage_read_45  storage_read_46  storage_read_47  storage_read_48  \\\n",
       "0              8445131         15034717          8450167          8379705   \n",
       "1             13664145         13405923         13909644         13887144   \n",
       "2             11218408          8110969          8180135         10502891   \n",
       "3             11442175          8444007         10603555          8235677   \n",
       "4              8044541         10246785         10390192         10556246   \n",
       "...                ...              ...              ...              ...   \n",
       "10344         10300004         10234523         20340788         12987683   \n",
       "10345          8554292         10329623         10851487          8205055   \n",
       "10346         10065023         10441647         10205280         13378944   \n",
       "10347         14593176         14240941         16800277         95419935   \n",
       "10348          8767378         10708759          8748527          8619713   \n",
       "\n",
       "       storage_read_49  storage_read_50  storage_read_51  storage_read_52  \\\n",
       "0              8427297         12287033          8539650          8423780   \n",
       "1             14307144         15503271         17596823         13738607   \n",
       "2              8094598          8199376          8265802          8118839   \n",
       "3              8199159          8328547          9272609         10258819   \n",
       "4             10076787         12277957         13404691          8498334   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          9360037         37126653          8796953         10531630   \n",
       "10345          8328794          9923868          8607847         10503195   \n",
       "10346          8233527         10669552          8376692          8521986   \n",
       "10347         15664995         13811594         14234792         13965629   \n",
       "10348         10663445          8445438          8844488         10643408   \n",
       "\n",
       "       storage_read_53  storage_read_54  storage_read_55  storage_read_56  \\\n",
       "0              8626112          8461798         10444694         10643803   \n",
       "1             14346088         11319500          8235468         10004484   \n",
       "2              8180635         10376243         10886316         10150687   \n",
       "3             10107284         10422428         10488075         10280152   \n",
       "4              7974170          8174670         10644339         10773356   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          8321887          8239592          9573015         10964975   \n",
       "10345         12551542         10427363          8754123          8351830   \n",
       "10346          8379544          8281804          8249453         10553387   \n",
       "10347         15944381         15625866         14367272         16059564   \n",
       "10348          8723897          8757952          9159354          8804192   \n",
       "\n",
       "       storage_read_57  storage_read_58  storage_read_59  storage_read_60  \\\n",
       "0              8342170          8264559         11043819          8169522   \n",
       "1              8385319          9307985          8173727          9926576   \n",
       "2             10134484         10221003         10222336         12473295   \n",
       "3             11422879          8153123          8468711         41099608   \n",
       "4              8167096         10197193         12270513          8544741   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          8537402         10649183          8824823          8247721   \n",
       "10345         10251661         10292401         14539854          8475922   \n",
       "10346         10230742         10374796         10378149         10618238   \n",
       "10347         16711556         16399874         18146333         15963862   \n",
       "10348          9138114         10766795          8711601          8330847   \n",
       "\n",
       "       storage_read_61  storage_read_62  storage_read_63  storage_read_64  \\\n",
       "0             10154084         12025739          8133819         10033696   \n",
       "1              8127358          8484061          8187579         14506440   \n",
       "2              8242913          8026783          8067061          8115358   \n",
       "3              7880756          8099864         11960465          8054069   \n",
       "4              8040819         10409210         10402803          8682240   \n",
       "...                ...              ...              ...              ...   \n",
       "10344         12513690         10300503         10574573          8616383   \n",
       "10345          8548885          8526644         13238239          8292999   \n",
       "10346          8423821         10603090          8230286          8321803   \n",
       "10347         16386300         15787901         14289681         16336968   \n",
       "10348          8724546         10361523         13714661         10638092   \n",
       "\n",
       "       storage_read_65  storage_read_66  storage_read_67  storage_read_68  \\\n",
       "0             10031658          9885697          7996191         10014974   \n",
       "1              8335523          8609597          8212524          8430171   \n",
       "2             10102262         12374202          8389005          8140672   \n",
       "3              9963341         10114005         10562815         10174209   \n",
       "4              8167207          8132744         10180490         19086303   \n",
       "...                ...              ...              ...              ...   \n",
       "10344         10614943          8548050         10372966          8208556   \n",
       "10345         10594713          8286109         10224050          8674531   \n",
       "10346          8207157          8356784          8341803         10762458   \n",
       "10347         19176949         13638392         14143942         13644392   \n",
       "10348          8830025          8518307          8880284          8312792   \n",
       "\n",
       "       storage_read_69  storage_read_70  storage_read_71  storage_read_72  \\\n",
       "0              8017523          8020320          8179263          8119245   \n",
       "1             10002928          9208152         10145372         10451131   \n",
       "2              8040006          8157598         10508799         12226740   \n",
       "3             11242493          8276436          8446434          8067328   \n",
       "4              8080355          8206984         10385118         12655122   \n",
       "...                ...              ...              ...              ...   \n",
       "10344         10707868          8304312          8690122         10611017   \n",
       "10345          8597291          8578551         11088300         10243050   \n",
       "10346         11372784          5571597         34136667          5602208   \n",
       "10347         13841205         12021655         10069773          8457258   \n",
       "10348          8513104         10505502          8528418          8370014   \n",
       "\n",
       "       storage_read_73  storage_read_74  storage_read_75  storage_read_76  \\\n",
       "0             10171751         48763469          8173614          8044190   \n",
       "1             13306534          8473468          8361246         11390370   \n",
       "2              8001488         10114076         10280520         10052298   \n",
       "3              7977958          9767826         34756077          8156271   \n",
       "4              8322336         10513024          8311576         12550345   \n",
       "...                ...              ...              ...              ...   \n",
       "10344         11990884          8568254          8852675         10436075   \n",
       "10345          8391367         88405068        126904593        183228285   \n",
       "10346          5648781          5637226          5660781          5791224   \n",
       "10347         10332825         10412009         10309122         10432213   \n",
       "10348         10565816          8432809          8654973         84861339   \n",
       "\n",
       "       storage_read_77  storage_read_78  storage_read_79  storage_read_80  \\\n",
       "0             10270935         12368737          8310077         10479008   \n",
       "1             12935368          8334005          8143246          8259912   \n",
       "2              9855651         10233021         10363095         78672579   \n",
       "3              8141327         12159519          8438879          8227826   \n",
       "4              8136818          8254669          8420279         10838967   \n",
       "...                ...              ...              ...              ...   \n",
       "10344         10375725         12465136          9604700          8496717   \n",
       "10345        196640707        580739428        188881423         51053492   \n",
       "10346          5712299          6615565          5781594          7685163   \n",
       "10347         12140153          8370500          8240113          8567090   \n",
       "10348          9245779          8520141          8815211         15644597   \n",
       "\n",
       "       storage_read_81  storage_read_82  storage_read_83  storage_read_84  \\\n",
       "0              8482742         10402101         10424730         10279417   \n",
       "1              8129875          9370688          8513616          8566319   \n",
       "2              7789654          8139931          8413061          9980318   \n",
       "3              9634660         10433687          8481286          8192937   \n",
       "4             10134286          8459723          8453612          8630741   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          8467477         10947271         10556074         10594092   \n",
       "10345         10391770         10697637         10840784         10381233   \n",
       "10346          5643244          6252830          5964648          5949426   \n",
       "10347          8321574          8582701          9984941         10855837   \n",
       "10348         11345194         11087087          8536455         15163030   \n",
       "\n",
       "       storage_read_85  storage_read_86  storage_read_87  storage_read_88  \\\n",
       "0             10168658         13910190          8186837          8223411   \n",
       "1              8576135         11580426          8558875         10576946   \n",
       "2             10110503          8123968          8361598          9886670   \n",
       "3              8158142          8467156         11683580          8197271   \n",
       "4             10263063         10459192         10270433         10313711   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          9514016         12742964          8457533          8287999   \n",
       "10345          8190407         10407086         10834618         10185607   \n",
       "10346          6087590          5775742          5940463          5790724   \n",
       "10347          9019546         10675710          9031824          8775975   \n",
       "10348          8653564         10635871         59397766         16672879   \n",
       "\n",
       "       storage_read_89  storage_read_90  storage_read_91  storage_read_92  \\\n",
       "0             10183269         13106491         10119898         10137621   \n",
       "1              8468209          8328468          8655245          8245912   \n",
       "2             18693785         10343928          8426820          7941154   \n",
       "3              8209623          8140382         10184413          8121031   \n",
       "4             12775306          8328168          8535927         10892670   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          8094038          8314442         11916755          8460533   \n",
       "10345         10750748          8514143          8530866         10707359   \n",
       "10346          8064417          5993221          9065072          5895038   \n",
       "10347          9857684         12174727          8710292          8470887   \n",
       "10348          8379106         10297894         10140192         10383171   \n",
       "\n",
       "       storage_read_93  storage_read_94  storage_read_95  storage_read_96  \\\n",
       "0              8303503          8293485         12487273          8343077   \n",
       "1              8421116         10201910          8475376         10299539   \n",
       "2              9813522         10051854         10290373         12026833   \n",
       "3              9208240          8477027         10606594          8100920   \n",
       "4             12287180          8006189          8092984          8250984   \n",
       "...                ...              ...              ...              ...   \n",
       "10344          8389682         10402243         12856629          8309554   \n",
       "10345         10609824          8423330         10723582         12699541   \n",
       "10346          6084313          7946549          5851649          5760669   \n",
       "10347          8859901          8691310         10102921          8681088   \n",
       "10348         10144841         12698750          8234182          8551585   \n",
       "\n",
       "       storage_read_97  storage_read_98  storage_read_99  storage_read_100  \\\n",
       "0              8398466         10294120         10177046           8252188   \n",
       "1             10546742         10415224         10637779          10490427   \n",
       "2             13647867          8299746          8528116           8028506   \n",
       "3              8304269          8249288         12100778           7954885   \n",
       "4              7891635         10094064          8149521           8338835   \n",
       "...                ...              ...              ...               ...   \n",
       "10344          9761938          8386867         11771591           8557772   \n",
       "10345          8722790          8367978         14089617           8303998   \n",
       "10346          5885316          5691058          5848853           5767780   \n",
       "10347         10930299          8426239          8544831           8428277   \n",
       "10348          8427883          8543770         11294676          10568649   \n",
       "\n",
       "       storage_write_1  storage_write_2  storage_write_3  storage_write_4  \\\n",
       "0               235609           209703           189480           187203   \n",
       "1               232647           237314           197351           188111   \n",
       "2               224037           203444           190759           182999   \n",
       "3               224516           201423           187979           182628   \n",
       "4               224536           199295           184870           187332   \n",
       "...                ...              ...              ...              ...   \n",
       "10344           232997           209367           198682           194682   \n",
       "10345           229386           196387           188646           190313   \n",
       "10346           238034           207479           199220           189997   \n",
       "10347           229256           204182           195757           185812   \n",
       "10348           232812           199960           197960           190331   \n",
       "\n",
       "       storage_write_5  storage_write_6  storage_write_7  storage_write_8  \\\n",
       "0               184480           186555           184795           182629   \n",
       "1               196500           199407           198370           194666   \n",
       "2               184333           184630           183851           182333   \n",
       "3               183776           184869           181072           180053   \n",
       "4               187350           188424           183072           184313   \n",
       "...                ...              ...              ...              ...   \n",
       "10344           198016           188774           191719           194812   \n",
       "10345           184016           179350           186035           183664   \n",
       "10346           190034           188165           188664           188886   \n",
       "10347           192053           183146           188479           180497   \n",
       "10348           190793           188016           188145           187146   \n",
       "\n",
       "       storage_write_9  storage_write_10  storage_write_11  storage_write_12  \\\n",
       "0               181591            178259            178073            186240   \n",
       "1               194777            187426            193722            192981   \n",
       "2               182296            180537            182963            180574   \n",
       "3               182720            181295            180128            178164   \n",
       "4               184314            182702            176498            180628   \n",
       "...                ...               ...               ...               ...   \n",
       "10344           188590            190182            191534            187478   \n",
       "10345           184091            181609            186202            178665   \n",
       "10346           187868            182683            185553            188665   \n",
       "10347           182646            183979            180719            178887   \n",
       "10348           191960            187905            187553            186627   \n",
       "\n",
       "       storage_write_13  storage_write_14  storage_write_15  storage_write_16  \\\n",
       "0                182054            178999            180943            180425   \n",
       "1                190685            193278            205685            186944   \n",
       "2                185759            180629            186629            217092   \n",
       "3                180349            185201            174998            176905   \n",
       "4                181721            184499            179110            184832   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            186386            188016            188886            186219   \n",
       "10345            179072            177942            182720            183721   \n",
       "10346            189535            184349            189146            180276   \n",
       "10347            182201            182775            186034            181553   \n",
       "10348            187979            182590            187276            184794   \n",
       "\n",
       "       storage_write_17  storage_write_18  storage_write_19  storage_write_20  \\\n",
       "0                177203            181722            179962            178758   \n",
       "1                193667            194519            190407            187333   \n",
       "2                185444            180629            180278            181463   \n",
       "3                179369            180961            175554            179943   \n",
       "4                177628            181461            182443            181369   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            191534            186275            185794            186646   \n",
       "10345            181980            180368            184349            178405   \n",
       "10346            186479            181757            184942            186627   \n",
       "10347            185590            183183            178331            181553   \n",
       "10348            186090            183460            189201            183590   \n",
       "\n",
       "       storage_write_21  storage_write_22  storage_write_23  storage_write_24  \\\n",
       "0                180240            177925            178628            181055   \n",
       "1                193537            188611            191685            189666   \n",
       "2                184926            178999            181445            183222   \n",
       "3                179054            176979            178628            178776   \n",
       "4                219258            188962            178906            183573   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            191775            182572            190645            185979   \n",
       "10345            187442            180498            178980            184905   \n",
       "10346            188665            185461            184275            185016   \n",
       "10347            182405            184497            182368            181165   \n",
       "10348            189368            185960            183016            182998   \n",
       "\n",
       "       storage_write_25  storage_write_26  storage_write_27  storage_write_28  \\\n",
       "0                176369            180425            184665            177313   \n",
       "1                188907            194963            203758            183592   \n",
       "2                181278            180630            182648            178592   \n",
       "3                176961            176369            182701            217572   \n",
       "4                179962            182202            184443            182314   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            181942            186979            189645            189442   \n",
       "10345            185590            183517            183979            184313   \n",
       "10346            186182            184054            192887            186905   \n",
       "10347            180812            181534            187349            183016   \n",
       "10348            186887            182960            186498            184108   \n",
       "\n",
       "       storage_write_29  storage_write_30  storage_write_31  storage_write_32  \\\n",
       "0                181777            183110            224073            186499   \n",
       "1                193796            186852            188074            192722   \n",
       "2                179111            181333            183778            181036   \n",
       "3                184645            177906            177850            176479   \n",
       "4                179517            185888            179869            181202   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            190367            186905            194904            186423   \n",
       "10345            184461            182257            181647            177424   \n",
       "10346            186720            227849            185349            180405   \n",
       "10347            186887            181275            186498            182257   \n",
       "10348            184035            179850            183108            186275   \n",
       "\n",
       "       storage_write_33  storage_write_34  storage_write_35  storage_write_36  \\\n",
       "0                185017            180221            180907            176406   \n",
       "1                195352            184611            195555            192240   \n",
       "2                180777            178110            183018            179851   \n",
       "3                177646            179443            178572            177868   \n",
       "4                180647            184925            179443            183647   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            192627            188793            186386            188663   \n",
       "10345            178257            176572            179998            182572   \n",
       "10346            176609            177905            184053            177294   \n",
       "10347            188386            229460            189905            185275   \n",
       "10348            187534            184442            189645            180238   \n",
       "\n",
       "       storage_write_37  storage_write_38  storage_write_39  storage_write_40  \\\n",
       "0                179795            179925            184536            178610   \n",
       "1                190518            192204            193759            187704   \n",
       "2                183852            177870            185666            180148   \n",
       "3                178757            178053            179479            176035   \n",
       "4                178203            180943            183591            185665   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            187479            191553            187071            195219   \n",
       "10345            182886            183016            185201            234664   \n",
       "10346            179479            181554            175849            176164   \n",
       "10347            185146            182257            185239            182590   \n",
       "10348            189738            183109            185646            186202   \n",
       "\n",
       "       storage_write_41  storage_write_42  storage_write_43  storage_write_44  \\\n",
       "0                180332            183276            181147            183203   \n",
       "1                190073            190000            190111            191907   \n",
       "2                179444            180722            178388            180815   \n",
       "3                179127            180831            177627            177739   \n",
       "4                176295            180869            180240            184628   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            188423            185831            190145            186775   \n",
       "10345            187350            180721            179350            177998   \n",
       "10346            182091            182257            184794            177775   \n",
       "10347            182072            181423            181609            179646   \n",
       "10348            187664            182164            182424            184479   \n",
       "\n",
       "       storage_write_45  storage_write_46  storage_write_47  storage_write_48  \\\n",
       "0                180054            182796            183573            181166   \n",
       "1                197389            187962            189963            189592   \n",
       "2                183259            178703            182630            180536   \n",
       "3                179090            178572            178109            179979   \n",
       "4                177666            183647            180610            183740   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            189015            191016            188201            191330   \n",
       "10345            187294            185831            182572            184183   \n",
       "10346            183535            176942            178942            178609   \n",
       "10347            188442            180460            185535            182072   \n",
       "10348            187201            235033            196682            184367   \n",
       "\n",
       "       storage_write_49  storage_write_50  storage_write_51  storage_write_52  \\\n",
       "0                176573            178536            178610            176092   \n",
       "1                193333            191907            198241            184834   \n",
       "2                182370            179630            181018            185796   \n",
       "3                178220            178238            178201            179128   \n",
       "4                187943            179999            180591            180129   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            188127            189571            179182            217404   \n",
       "10345            187146            184906            180479            181535   \n",
       "10346            179794            179868            180942            184424   \n",
       "10347            187090            184424            181960            182423   \n",
       "10348            179553            185071            183590            184831   \n",
       "\n",
       "       storage_write_53  storage_write_54  storage_write_55  storage_write_56  \\\n",
       "0                179073            176332            182517            177332   \n",
       "1                224259            197685            191704            191740   \n",
       "2                182555            181055            180647            180074   \n",
       "3                178590            177980            181757            182516   \n",
       "4                181610            181017            180814            180832   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            194496            193941            194664            189257   \n",
       "10345            178906            180812            189127            182609   \n",
       "10346            175997            176738            183349            177980   \n",
       "10347            182905            182220            181794            181238   \n",
       "10348            190146            183034            188720            185442   \n",
       "\n",
       "       storage_write_57  storage_write_58  storage_write_59  storage_write_60  \\\n",
       "0                178832            180832            177073            181276   \n",
       "1                197388            183963            195185            187870   \n",
       "2                187981            178018            182370            180426   \n",
       "3                179850            181035            177923            180220   \n",
       "4                181517            181851            185055            182462   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            187405            188201            191997            188923   \n",
       "10345            185257            183665            186072            184628   \n",
       "10346            181016            182090            181313            182868   \n",
       "10347            182572            180164            182849            184627   \n",
       "10348            183090            181349            186461            185590   \n",
       "\n",
       "       storage_write_61  storage_write_62  storage_write_63  storage_write_64  \\\n",
       "0                179036            181444            180555            185499   \n",
       "1                189426            189573            190833            187000   \n",
       "2                182758            182426            180555            180556   \n",
       "3                179035            182572            177905            177405   \n",
       "4                183332            183147            181388            183388   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            191534            187127            191052            190905   \n",
       "10345            186572            178794            177943            183905   \n",
       "10346            180201            177035            181757            181960   \n",
       "10347            183942            185127            186423            182646   \n",
       "10348            187219            186238            186627            186886   \n",
       "\n",
       "       storage_write_65  storage_write_66  storage_write_67  storage_write_68  \\\n",
       "0                177443            176647            177851            178813   \n",
       "1                196574            192500            187833            189426   \n",
       "2                181463            181537            182462            178740   \n",
       "3                177831            181979            174164            174868   \n",
       "4                180036            180388            185943            181517   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            190775            189663            191108            193145   \n",
       "10345            183442            178924            179183            182090   \n",
       "10346            181257            181442            182257            179924   \n",
       "10347            181498            183405            183182            183701   \n",
       "10348            188793            185146            190293            185460   \n",
       "\n",
       "       storage_write_69  storage_write_70  storage_write_71  storage_write_72  \\\n",
       "0                178888            182055            180925            174924   \n",
       "1                193740            186148            196110            193555   \n",
       "2                180481            176796            212018            183684   \n",
       "3                178627            179794            180850            177276   \n",
       "4                181832            182314            181387            180184   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            187460            191257            192034            189516   \n",
       "10345            179998            180424            174257            180035   \n",
       "10346            179609            179053            180146            179387   \n",
       "10347            183034            185571            181591            179794   \n",
       "10348            188497            184683            185646            186572   \n",
       "\n",
       "       storage_write_73  storage_write_74  storage_write_75  storage_write_76  \\\n",
       "0                181944            176629            183314            180276   \n",
       "1                197647            192851            195000            184259   \n",
       "2                184722            180667            177722            180296   \n",
       "3                175609            178442            178480            172109   \n",
       "4                179592            179110            210165            185276   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            193163            189775            189145            187737   \n",
       "10345            185646            179146            187628            181942   \n",
       "10346            176016            180387            181831            179146   \n",
       "10347            184664            184461            182497            180719   \n",
       "10348            192145            187979            186090            180350   \n",
       "\n",
       "       storage_write_77  storage_write_78  storage_write_79  storage_write_80  \\\n",
       "0                176795            179129            183276            180702   \n",
       "1                203851            189981            193741            189852   \n",
       "2                182463            181074            180241            181574   \n",
       "3                179368            178850            176794            183516   \n",
       "4                182369            182554            181425            181203   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            189312            184405            186293            188960   \n",
       "10345            184831            175498            188072            178683   \n",
       "10346            176757            179312            177646            183275   \n",
       "10347            183164            183387            180535            184646   \n",
       "10348            189776            182812            181831            184886   \n",
       "\n",
       "       storage_write_81  storage_write_82  storage_write_83  storage_write_84  \\\n",
       "0                180906            181091            179850            175758   \n",
       "1                200259            186852            192907            188778   \n",
       "2                181833            182796            184537            182851   \n",
       "3                175905            178646            212146            186720   \n",
       "4                183314            184758            181758            179444   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            190294            190349            187960            189478   \n",
       "10345            185979            182091            181164            177905   \n",
       "10346            179220            178905            178442            176294   \n",
       "10347            182424            180257            186090            182497   \n",
       "10348            187719            179627            184961            182424   \n",
       "\n",
       "       storage_write_85  storage_write_86  storage_write_87  storage_write_88  \\\n",
       "0                176833            210203            180758            179610   \n",
       "1                191315            189889            193129            181278   \n",
       "2                184130            178796            182778            180240   \n",
       "3                175423            175794            177331            174942   \n",
       "4                181980            181980            181202            181443   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            193312            189312            189442            187256   \n",
       "10345            185646            184109            181664            178720   \n",
       "10346            209812            176387            187609            177183   \n",
       "10347            182405            186127            213386            180238   \n",
       "10348            186016            183053            188590            182572   \n",
       "\n",
       "       storage_write_89  storage_write_90  storage_write_91  storage_write_92  \\\n",
       "0                179925            183110            180073            177647   \n",
       "1                200110            191388            190055            193092   \n",
       "2                182870            184462            179481            180685   \n",
       "3                183053            178905            177387            178016   \n",
       "4                182313            181666            179758            181610   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            191775            191386            188312            186997   \n",
       "10345            181257            180202            186405            179387   \n",
       "10346            179683            181054            184479            174961   \n",
       "10347            179887            178979            176794            174460   \n",
       "10348            187960            185904            186924            183887   \n",
       "\n",
       "       storage_write_93  storage_write_94  storage_write_95  storage_write_96  \\\n",
       "0                178573            182925            178888            179740   \n",
       "1                196926            187167            191296            188796   \n",
       "2                179371            180148            180407            179555   \n",
       "3                180813            175627            178887            176387   \n",
       "4                182166            181943            176721            182795   \n",
       "...                 ...               ...               ...               ...   \n",
       "10344            190849            187553            188552            187942   \n",
       "10345            184813            209183            184887            179702   \n",
       "10346            177406            182164            182276            174868   \n",
       "10347            175424            174109            174831            174813   \n",
       "10348            189590            182978            189090            186683   \n",
       "\n",
       "       storage_write_97  storage_write_98  storage_write_99  storage_write_100  \n",
       "0                180906            180906            179165             180073  \n",
       "1                191518            190111            191685             186148  \n",
       "2                184278            181537            179925             174852  \n",
       "3                178127            176961            174461             177535  \n",
       "4                185536            182702            183702             180887  \n",
       "...                 ...               ...               ...                ...  \n",
       "10344            189793            187293            190830             189256  \n",
       "10345            176275            181294            186424             183609  \n",
       "10346            174202            178775            184665             181701  \n",
       "10347            172109            175979            177294             172461  \n",
       "10348            181405            184035            213830             188571  \n",
       "\n",
       "[10349 rows x 215 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict_test[\"feat_gpu_dc_a6_32_14_a6_53\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80099d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_test_df={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd5bbcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in file_names:\n",
    "    #df_dict_train[f]=df_dict_train[f][(np.abs(stats.zscore(df_dict_train[f])) < 15).all(axis=1)]\n",
    "    scc = QuantileTransformer(n_quantiles=1000)#QuantileTransformer() #StandardScaler()\n",
    "    scc.fit(df_dict_train[f])\n",
    "    df_dict_train[f] = scc.transform(df_dict_train[f])\n",
    "    \n",
    "    df_dict_test_df[f]={}\n",
    "    for f2 in file_names: \n",
    "        df_dict_test_df[f][f2] = scc.transform(df_dict_test[f2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e701438a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70160ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps=10 #100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2808879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41386, 10, 215)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_nd(df_dict_train[\"feat_gpu_dc_a6_32_14_a6_53\"],n_timesteps,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4c1d64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in file_names:\n",
    "    #df_dict_train[f] = df_dict_train[f][:(df_dict_train[f].shape[0]//n_timesteps)*n_timesteps]\n",
    "    #df_dict_train[f]=df_dict_train[f].reshape((int(df_dict_train[f].shape[0]/n_timesteps),n_timesteps, df_dict_train[f].shape[1]))\n",
    "    df_dict_train[f]=window_nd(df_dict_train[f],n_timesteps,axis=0)\n",
    "    \n",
    "    for f2 in file_names:\n",
    "        #df_dict_test_df[f][f2] = df_dict_test_df[f][f2][:(df_dict_test_df[f][f2].shape[0]//n_timesteps)*n_timesteps]    \n",
    "        #df_dict_test_df[f][f2] = df_dict_test_df[f][f2].reshape((int(df_dict_test_df[f][f2].shape[0]/n_timesteps),n_timesteps, df_dict_test_df[f][f2].shape[1]))\n",
    "        df_dict_test_df[f][f2]=window_nd(df_dict_test_df[f][f2],n_timesteps,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a9d766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unidentified_devices=['feat_gpu_80_1f_02_f1_e3_b0','feat_gpu_80_1f_02_f1_e3_c0', 'feat_gpu_80_1f_02_f1_e3_dd', 'feat_gpu_b8_27_eb_27_1f_a3', 'feat_gpu_b8_27_eb_2d_d7_6b', 'feat_gpu_b8_27_eb_4c_53_a8', 'feat_gpu_b8_27_eb_91_48_fe', 'feat_gpu_dc_a6_32_14_a8_d8', 'feat_gpu_dc_a6_32_14_ab_0a', 'feat_gpu_dc_a6_32_e4_48_9e']\n",
    "unidentified_devices=['feat_gpu_dc_a6_32_14_ab_0a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2b5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c4cf5f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41386, 10, 215)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict_train[\"feat_gpu_dc_a6_32_14_a6_53\"].shape\n",
    "#8279*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "87673e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(100, activation='relu', input_shape=(215,)))\n",
    "    \n",
    "    model.add(LSTM(64,return_sequences=False, activation='relu', input_shape=(n_timesteps,215)))\n",
    "    #model.add(LSTM(64,return_sequences=False, activation='relu'))\n",
    "\n",
    "    #model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))#True = many to many\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(MaxPooling1D(pool_size=2))\n",
    "    #model.add(Flatten())\n",
    "    mid_layer=50\n",
    "    model.add(Dense(mid_layer, activation='relu'))\n",
    "    model.add(Reshape((n_timesteps,mid_layer//n_timesteps)))\n",
    "    \n",
    "    #model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    #model.add(UpSampling1D(2))\n",
    "    #model.add(LSTM(64,return_sequences=True, activation='relu'))\n",
    "    \n",
    "    #model.add(Conv1DTranspose(filters=64, kernel_size=3, activation='relu'))\n",
    "    #model.add(UpSampling1D(2))\n",
    "    \n",
    "    model.add(LSTM(64,return_sequences=True, activation='relu'))\n",
    "    model.add(TimeDistributed(Dense(215)))\n",
    "    \n",
    "    #model.add(Dense(215, activation='relu'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39dd9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8aaa6f64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Training model for feat_gpu_80_1f_02_ef_e7_b2\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 10, 215)          13975     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "1372/1372 [==============================] - 38s 23ms/step - loss: 0.0622 - accuracy: 0.0100\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0500 - accuracy: 0.0124\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0482 - accuracy: 0.0132\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0474 - accuracy: 0.0139\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0469 - accuracy: 0.0142\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0465 - accuracy: 0.0144\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0459 - accuracy: 0.0146\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0454 - accuracy: 0.0145\n",
      "Epoch 9/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0450 - accuracy: 0.0142\n",
      "Epoch 10/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0448 - accuracy: 0.0141\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.048551272615167014]\n",
      "[False  True]      [0.10002051 0.89997949]\n",
      "[False  True]      [0.09294053 0.90705947]      [1019 9945]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [5428 5542]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [4529 6438]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [8965 2000]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [3512 7440]\n",
      "feat_gpu_80_1f_02_f1_e3_db [7078 3890]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [4783 6179]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [5587 5377]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [2002 8965]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [2946 8019]\n",
      "0.8174523570712137\n",
      "\n",
      "\n",
      "Training model for feat_gpu_80_1f_02_f1_e3_b0\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 10, 215)          13975     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "1372/1372 [==============================] - 37s 23ms/step - loss: 0.0589 - accuracy: 0.0108\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0478 - accuracy: 0.0136\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0466 - accuracy: 0.0148\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0458 - accuracy: 0.0154\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0452 - accuracy: 0.0157\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0448 - accuracy: 0.0153\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0444 - accuracy: 0.0153\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0441 - accuracy: 0.0147\n",
      "Epoch 9/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0437 - accuracy: 0.0154\n",
      "Epoch 10/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0433 - accuracy: 0.0151\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.04703285625042347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]      [0.10001594 0.89998406]\n",
      "[False  True]      [0.15916135 0.84083865]      [1746 9224]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [3373 7591]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [3758 7209]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [5765 5200]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [4723 6229]\n",
      "feat_gpu_80_1f_02_f1_e3_db [6823 4145]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [6155 4807]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [6439 4525]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [5360 5607]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [5652 5313]\n",
      "0.6923568040861\n",
      "\n",
      "\n",
      "Training model for feat_gpu_80_1f_02_f1_e3_b7\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 10, 215)          13975     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "1372/1372 [==============================] - 38s 23ms/step - loss: 0.0583 - accuracy: 0.0101\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0467 - accuracy: 0.0131\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0454 - accuracy: 0.0139\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0446 - accuracy: 0.0145\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0441 - accuracy: 0.0147\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0435 - accuracy: 0.0149\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0432 - accuracy: 0.0154\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0430 - accuracy: 0.0155\n",
      "Epoch 9/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0427 - accuracy: 0.0153\n",
      "Epoch 10/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0425 - accuracy: 0.0147\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.04603809165067578]\n",
      "[False  True]      [0.10001139 0.89998861]\n",
      "[False  True]      [0.11625786 0.88374214]      [1275 9692]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [2124 8840]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [3642 7328]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [5836 5129]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [2092 8860]\n",
      "feat_gpu_80_1f_02_f1_e3_db [4497 6471]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [3613 7349]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [4941 6023]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [1489 9478]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [3240 7725]\n",
      "0.8642290507887298\n",
      "\n",
      "\n",
      "Training model for feat_gpu_80_1f_02_f1_e3_c0\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 10, 215)          13975     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "1372/1372 [==============================] - 38s 23ms/step - loss: 0.0612 - accuracy: 0.0109\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0478 - accuracy: 0.0139\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0462 - accuracy: 0.0153\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0453 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0448 - accuracy: 0.0155\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0445 - accuracy: 0.0157\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0441 - accuracy: 0.0161\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0438 - accuracy: 0.0161\n",
      "Epoch 9/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0434 - accuracy: 0.0155\n",
      "Epoch 10/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0431 - accuracy: 0.0148\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.04680817168142396]\n",
      "[False  True]      [0.10001139 0.89998861]\n",
      "[False  True]      [0.10442316 0.89557684]      [1145 9820]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [  778 10186]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [  743 10227]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [  599 10368]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [  710 10242]\n",
      "feat_gpu_80_1f_02_f1_e3_db [1099 9869]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [1803 9159]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [1876 9088]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [  922 10045]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [1305 9660]\n",
      "0.945381599343485\n",
      "\n",
      "\n",
      "Training model for feat_gpu_80_1f_02_f1_e3_c7\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 64)                71680     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_11 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 10, 215)          13975     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "1370/1370 [==============================] - 38s 23ms/step - loss: 0.0601 - accuracy: 0.0111\n",
      "Epoch 2/10\n",
      "1370/1370 [==============================] - 32s 23ms/step - loss: 0.0480 - accuracy: 0.0137\n",
      "Epoch 3/10\n",
      "1370/1370 [==============================] - 32s 23ms/step - loss: 0.0469 - accuracy: 0.0143\n",
      "Epoch 4/10\n",
      "1370/1370 [==============================] - 32s 23ms/step - loss: 0.0463 - accuracy: 0.0146\n",
      "Epoch 5/10\n",
      "1370/1370 [==============================] - 32s 23ms/step - loss: 0.0459 - accuracy: 0.0151\n",
      "Epoch 6/10\n",
      "1370/1370 [==============================] - 32s 23ms/step - loss: 0.0456 - accuracy: 0.0155\n",
      "Epoch 7/10\n",
      "1370/1370 [==============================] - 32s 23ms/step - loss: 0.0453 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "1370/1370 [==============================] - 32s 23ms/step - loss: 0.0451 - accuracy: 0.0159\n",
      "Epoch 9/10\n",
      "1370/1370 [==============================] - 32s 23ms/step - loss: 0.0448 - accuracy: 0.0155\n",
      "Epoch 10/10\n",
      "1370/1370 [==============================] - 32s 23ms/step - loss: 0.0443 - accuracy: 0.0141\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.0482632609490159]\n",
      "[False  True]      [0.10002053 0.89997947]\n",
      "[False  True]      [0.06574142 0.93425858]      [  720 10232]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [1344 9620]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [2161 8809]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [1181 9786]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [4196 6769]\n",
      "feat_gpu_80_1f_02_f1_e3_db [3597 7371]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [3679 7283]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [3693 7271]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [1227 9740]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [2077 8888]\n",
      "0.8923133035470047\n",
      "\n",
      "\n",
      "Training model for feat_gpu_80_1f_02_f1_e3_db\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_7 (Reshape)         (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 10, 215)          13975     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1372/1372 [==============================] - 38s 23ms/step - loss: 0.0605 - accuracy: 0.0105\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0475 - accuracy: 0.0142\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0462 - accuracy: 0.0153\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0455 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0451 - accuracy: 0.0166\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0448 - accuracy: 0.0166\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0445 - accuracy: 0.0168\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0442 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0439 - accuracy: 0.0169\n",
      "Epoch 10/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0436 - accuracy: 0.0180\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.04718714930692968]\n",
      "[False  True]      [0.10000911 0.89999089]\n",
      "[False  True]      [0.12718818 0.87281182]      [1395 9573]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [1053 9911]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [1261 9709]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [  869 10098]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [2419 8546]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [ 957 9995]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [1681 9281]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [1761 9203]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [  932 10035]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [1568 9397]\n",
      "0.9207622868605817\n",
      "\n",
      "\n",
      "Training model for feat_gpu_80_1f_02_f1_e3_dd\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_8 (Reshape)         (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 10, 215)          13975     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1372/1372 [==============================] - 37s 23ms/step - loss: 0.0599 - accuracy: 0.0104\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0483 - accuracy: 0.0134\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0468 - accuracy: 0.0146\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0459 - accuracy: 0.0148\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0453 - accuracy: 0.0152\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0446 - accuracy: 0.0144\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0438 - accuracy: 0.0124\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0428 - accuracy: 0.0095\n",
      "Epoch 9/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0424 - accuracy: 0.0095\n",
      "Epoch 10/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0421 - accuracy: 0.0096\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.04632526563306936]\n",
      "[False  True]      [0.10001596 0.89998404]\n",
      "[False  True]      [0.10399562 0.89600438]      [1140 9822]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [2272 8692]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [6387 4583]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [5979 4988]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9364 1601]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [4577 6375]\n",
      "feat_gpu_80_1f_02_f1_e3_db [6327 4641]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [5898 5066]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [2992 7975]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [1507 9458]\n",
      "0.862562699498404\n",
      "\n",
      "\n",
      "Training model for feat_gpu_80_1f_02_f1_e3_e0\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_9 (Reshape)         (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 10, 215)          13975     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1372/1372 [==============================] - 38s 23ms/step - loss: 0.0601 - accuracy: 0.0112\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0486 - accuracy: 0.0141\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0467 - accuracy: 0.0148\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0460 - accuracy: 0.0153\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0455 - accuracy: 0.0160\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0452 - accuracy: 0.0164\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0448 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0446 - accuracy: 0.0166\n",
      "Epoch 9/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0443 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0439 - accuracy: 0.0166\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.0477567244147634]\n",
      "[False  True]      [0.10001595 0.89998405]\n",
      "[False  True]      [0.10835462 0.89164538]      [1188 9776]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [  559 10405]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [  947 10023]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [  944 10023]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [2517 8448]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [  627 10325]\n",
      "feat_gpu_80_1f_02_f1_e3_db [1480 9488]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [1214 9748]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [  680 10287]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [1105 9860]\n",
      "0.9490149580445093\n",
      "\n",
      "\n",
      "Training model for feat_gpu_80_1f_02_f1_e4_04\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_10 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 10, 215)          13975     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1372/1372 [==============================] - 38s 23ms/step - loss: 0.0582 - accuracy: 0.0103\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0469 - accuracy: 0.0133\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0460 - accuracy: 0.0142\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0455 - accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0450 - accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0447 - accuracy: 0.0153\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0444 - accuracy: 0.0153\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0439 - accuracy: 0.0154\n",
      "Epoch 9/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0432 - accuracy: 0.0140\n",
      "Epoch 10/10\n",
      "1372/1372 [==============================] - 31s 23ms/step - loss: 0.0426 - accuracy: 0.0129\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.04618190574320993]\n",
      "[False  True]      [0.10001595 0.89998405]\n",
      "[False  True]      [0.0945564 0.9054436]      [1037 9930]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [3918 7046]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [9183 1787]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [7080 3887]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10235   730]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [5684 5268]\n",
      "feat_gpu_80_1f_02_f1_e3_db [8169 2799]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [7541 3421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_80_1f_02_f1_e3_e0 [7756 3208]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [6238 4727]\n",
      "0.6426486683692083\n",
      "\n",
      "\n",
      "Training model for feat_gpu_80_1f_02_f1_e4_0c\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_11 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1372/1372 [==============================] - 39s 23ms/step - loss: 0.0591 - accuracy: 0.0107\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0474 - accuracy: 0.0138\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 33s 24ms/step - loss: 0.0461 - accuracy: 0.0146\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0453 - accuracy: 0.0152\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0445 - accuracy: 0.0155\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0437 - accuracy: 0.0139\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0431 - accuracy: 0.0134\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0424 - accuracy: 0.0124\n",
      "Epoch 9/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0418 - accuracy: 0.0118\n",
      "Epoch 10/10\n",
      "1372/1372 [==============================] - 32s 23ms/step - loss: 0.0415 - accuracy: 0.0119\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.04534623206881042]\n",
      "[False  True]      [0.10001595 0.89998405]\n",
      "[False  True]      [0.09922481 0.90077519]      [1088 9877]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [1551 9413]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [4467 6503]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [3984 6983]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [7900 3065]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [3004 7948]\n",
      "feat_gpu_80_1f_02_f1_e3_db [6177 4791]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [1436 9526]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [5148 5816]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [2457 8510]\n",
      "0.8690020069330414\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_0e_9d_fb\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_12 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1065/1065 [==============================] - 31s 23ms/step - loss: 0.0841 - accuracy: 0.0032\n",
      "Epoch 2/10\n",
      "1065/1065 [==============================] - 25s 23ms/step - loss: 0.0764 - accuracy: 0.0039\n",
      "Epoch 3/10\n",
      "1065/1065 [==============================] - 25s 23ms/step - loss: 0.0742 - accuracy: 0.0037\n",
      "Epoch 4/10\n",
      "1065/1065 [==============================] - 25s 23ms/step - loss: 0.0670 - accuracy: 0.0031\n",
      "Epoch 5/10\n",
      "1065/1065 [==============================] - 25s 23ms/step - loss: 0.0633 - accuracy: 0.0029\n",
      "Epoch 6/10\n",
      "1065/1065 [==============================] - 25s 23ms/step - loss: 0.0627 - accuracy: 0.0028\n",
      "Epoch 7/10\n",
      "1065/1065 [==============================] - 25s 23ms/step - loss: 0.0624 - accuracy: 0.0030\n",
      "Epoch 8/10\n",
      "1065/1065 [==============================] - 25s 23ms/step - loss: 0.0621 - accuracy: 0.0032\n",
      "Epoch 9/10\n",
      "1065/1065 [==============================] - 25s 23ms/step - loss: 0.0619 - accuracy: 0.0034\n",
      "Epoch 10/10\n",
      "1065/1065 [==============================] - 25s 23ms/step - loss: 0.0617 - accuracy: 0.0033\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06846933694963643]\n",
      "[False  True]      [0.10002349 0.89997651]\n",
      "[False  True]      [0.07932777 0.92067223]      [ 675 7834]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [    1 10508]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10790  1113]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [10636  1271]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10423  1480]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [   1 6429]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10781  1122]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [    1 10509]\n",
      "feat_gpu_b8_27_eb_91_48_fe [    1 10509]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [10752  1156]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4655 1113]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10762  1134]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [ 1385 10518]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [4583 7291]\n",
      "0.9999048525214081\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_1d_3b_13\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_26 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_27 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1315/1315 [==============================] - 38s 23ms/step - loss: 0.0795 - accuracy: 0.0035\n",
      "Epoch 2/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0738 - accuracy: 0.0040\n",
      "Epoch 3/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0714 - accuracy: 0.0050\n",
      "Epoch 4/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0682 - accuracy: 0.0045\n",
      "Epoch 5/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0670 - accuracy: 0.0042\n",
      "Epoch 6/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0664 - accuracy: 0.0045\n",
      "Epoch 7/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0660 - accuracy: 0.0047\n",
      "Epoch 8/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0655 - accuracy: 0.0045\n",
      "Epoch 9/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0651 - accuracy: 0.0044\n",
      "Epoch 10/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0649 - accuracy: 0.0046\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.07192448603272894]\n",
      "[False  True]      [0.10000238 0.89999762]\n",
      "[False  True]      [0.1886954 0.8113046]      [1983 8526]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8261  248]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10500    15]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10512     1]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10502     8]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11473   430]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11698   209]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10507     4]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11596   307]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6317  113]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11191   712]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10447    63]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11612   296]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5615  153]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11607   289]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11154   749]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11394   480]\n",
      "0.06292531294631605\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_27_1f_a3\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_28 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_14 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_13 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1315/1315 [==============================] - 37s 23ms/step - loss: 0.0827 - accuracy: 0.0040\n",
      "Epoch 2/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0711 - accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0700 - accuracy: 0.0036\n",
      "Epoch 4/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0692 - accuracy: 0.0036\n",
      "Epoch 5/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0680 - accuracy: 0.0034\n",
      "Epoch 6/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0675 - accuracy: 0.0035\n",
      "Epoch 7/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0669 - accuracy: 0.0036\n",
      "Epoch 8/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0663 - accuracy: 0.0036\n",
      "Epoch 9/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0660 - accuracy: 0.0037\n",
      "Epoch 10/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0658 - accuracy: 0.0037\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.0721223635742896]\n",
      "[False  True]      [0.10000238 0.89999762]\n",
      "[False  True]      [0.21653506 0.78346494]      [2276 8235]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8509]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11903]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11907]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [2183 8328]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11903]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6381   49]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11903]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10505     5]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11908]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5768]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11896]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11903]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11874]\n",
      "0.7923128151460375\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_2d_18_19\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_15 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_14 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1316/1316 [==============================] - 39s 24ms/step - loss: 0.0825 - accuracy: 0.0035\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1316/1316 [==============================] - 31s 23ms/step - loss: 0.0764 - accuracy: 0.0031\n",
      "Epoch 3/10\n",
      "1316/1316 [==============================] - 31s 23ms/step - loss: 0.0750 - accuracy: 0.0033\n",
      "Epoch 4/10\n",
      "1316/1316 [==============================] - 30s 23ms/step - loss: 0.0727 - accuracy: 0.0034\n",
      "Epoch 5/10\n",
      "1316/1316 [==============================] - 30s 23ms/step - loss: 0.0707 - accuracy: 0.0033\n",
      "Epoch 6/10\n",
      "1316/1316 [==============================] - 30s 23ms/step - loss: 0.0702 - accuracy: 0.0035\n",
      "Epoch 7/10\n",
      "1316/1316 [==============================] - 31s 23ms/step - loss: 0.0699 - accuracy: 0.0035\n",
      "Epoch 8/10\n",
      "1316/1316 [==============================] - 30s 23ms/step - loss: 0.0696 - accuracy: 0.0034\n",
      "Epoch 9/10\n",
      "1316/1316 [==============================] - 30s 23ms/step - loss: 0.0693 - accuracy: 0.0034\n",
      "Epoch 10/10\n",
      "1316/1316 [==============================] - 30s 23ms/step - loss: 0.0690 - accuracy: 0.0035\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.07368925745049204]\n",
      "[False  True]      [0.1000095 0.8999905]\n",
      "[False  True]      [0.19353305 0.80646695]      [2035 8480]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8427   82]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [8328 2181]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10488    22]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10507     4]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11749   154]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11867    40]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10488    23]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11824    79]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [4360 2070]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11574   329]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [8159 2351]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10509     1]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11850    58]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5732   36]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11823    73]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11573   330]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11704   170]\n",
      "0.32192846034214617\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_2d_d7_6b\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_32 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_16 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_15 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1315/1315 [==============================] - 36s 23ms/step - loss: 0.0830 - accuracy: 0.0041\n",
      "Epoch 2/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0716 - accuracy: 0.0032\n",
      "Epoch 3/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0704 - accuracy: 0.0034\n",
      "Epoch 4/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0700 - accuracy: 0.0037\n",
      "Epoch 5/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0697 - accuracy: 0.0041\n",
      "Epoch 6/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0693 - accuracy: 0.0044\n",
      "Epoch 7/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0684 - accuracy: 0.0042\n",
      "Epoch 8/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0672 - accuracy: 0.0042\n",
      "Epoch 9/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0665 - accuracy: 0.0042\n",
      "Epoch 10/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0662 - accuracy: 0.0044\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.07225381525377358]\n",
      "[False  True]      [0.10000713 0.89999287]\n",
      "[False  True]      [0.16998002 0.83001998]      [1787 8726]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8509]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10209   300]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10489    22]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10500    15]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10247   263]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [ 948 9563]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11903]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11907]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10254   257]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11903]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5296 1134]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11903]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [8596 1914]\n",
      "feat_gpu_b8_27_eb_91_48_fe [1608 8902]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11908]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5768]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11896]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11903]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11874]\n",
      "0.9098087717629151\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_31_6d_f3\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_34 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_17 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_16 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1315/1315 [==============================] - 38s 23ms/step - loss: 0.0854 - accuracy: 0.0040\n",
      "Epoch 2/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0761 - accuracy: 0.0032\n",
      "Epoch 3/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0734 - accuracy: 0.0033\n",
      "Epoch 4/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0695 - accuracy: 0.0035\n",
      "Epoch 5/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0689 - accuracy: 0.0039\n",
      "Epoch 6/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0684 - accuracy: 0.0040\n",
      "Epoch 7/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0676 - accuracy: 0.0037\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0671 - accuracy: 0.0039\n",
      "Epoch 9/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0667 - accuracy: 0.0040\n",
      "Epoch 10/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0663 - accuracy: 0.0040\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.0724133164396129]\n",
      "[False  True]      [0.10001189 0.89998811]\n",
      "[False  True]      [0.14405328 0.85594672]      [1514 8996]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8509]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10508     1]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11903]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11907]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11903]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6430]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11903]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10509     1]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11908]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5768]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11896]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11903]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11874]\n",
      "9.515653249595585e-05\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_4c_33_1b\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_36 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_18 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_17 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1315/1315 [==============================] - 37s 23ms/step - loss: 0.0815 - accuracy: 0.0037\n",
      "Epoch 2/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0699 - accuracy: 0.0032\n",
      "Epoch 3/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0691 - accuracy: 0.0033\n",
      "Epoch 4/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0688 - accuracy: 0.0034\n",
      "Epoch 5/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0682 - accuracy: 0.0039\n",
      "Epoch 6/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0672 - accuracy: 0.0044\n",
      "Epoch 7/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0668 - accuracy: 0.0047\n",
      "Epoch 8/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0663 - accuracy: 0.0046\n",
      "Epoch 9/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0655 - accuracy: 0.0045\n",
      "Epoch 10/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0652 - accuracy: 0.0045\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.0718582749148882]\n",
      "[False  True]      [0.10000238 0.89999762]\n",
      "[False  True]      [0.28665208 0.71334792]      [3013 7498]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8509]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10508     1]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [5229 5284]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10502     8]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11903]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11907]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11903]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6384   46]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11903]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10477    33]\n",
      "feat_gpu_b8_27_eb_91_48_fe [4961 5549]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11908]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5768]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11896]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11903]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11874]\n",
      "0.5279733587059943\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_4c_53_a8\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_38 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_19 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_18 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1489/1489 [==============================] - 43s 24ms/step - loss: 0.0828 - accuracy: 0.0055\n",
      "Epoch 2/10\n",
      "1489/1489 [==============================] - 35s 24ms/step - loss: 0.0702 - accuracy: 0.0033\n",
      "Epoch 3/10\n",
      "1489/1489 [==============================] - 35s 24ms/step - loss: 0.0669 - accuracy: 0.0030\n",
      "Epoch 4/10\n",
      "1489/1489 [==============================] - 35s 24ms/step - loss: 0.0624 - accuracy: 0.0029\n",
      "Epoch 5/10\n",
      "1489/1489 [==============================] - 35s 23ms/step - loss: 0.0612 - accuracy: 0.0029\n",
      "Epoch 6/10\n",
      "1489/1489 [==============================] - 35s 23ms/step - loss: 0.0604 - accuracy: 0.0029\n",
      "Epoch 7/10\n",
      "1489/1489 [==============================] - 35s 23ms/step - loss: 0.0597 - accuracy: 0.0028\n",
      "Epoch 8/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0594 - accuracy: 0.0028\n",
      "Epoch 9/10\n",
      "1489/1489 [==============================] - 35s 23ms/step - loss: 0.0591 - accuracy: 0.0029\n",
      "Epoch 10/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0589 - accuracy: 0.0029\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06576490217418257]\n",
      "[False  True]      [0.1000063 0.8999937]\n",
      "[False  True]      [0.0939259 0.9060741]      [ 1118 10785]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7398 1111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [10790  1117]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10737  1166]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6430]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [ 1434 10469]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10510]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [10798  1110]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4656 1112]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [3334 8562]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [10732  1171]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [4609 7265]\n",
      "0.8795261698731413\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_50_d7_8b\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_40 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_20 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_19 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1490/1490 [==============================] - 41s 23ms/step - loss: 0.0797 - accuracy: 0.0043\n",
      "Epoch 2/10\n",
      "1490/1490 [==============================] - 35s 23ms/step - loss: 0.0707 - accuracy: 0.0047\n",
      "Epoch 3/10\n",
      "1490/1490 [==============================] - 35s 23ms/step - loss: 0.0697 - accuracy: 0.0049\n",
      "Epoch 4/10\n",
      "1490/1490 [==============================] - 34s 23ms/step - loss: 0.0691 - accuracy: 0.0054\n",
      "Epoch 5/10\n",
      "1490/1490 [==============================] - 35s 23ms/step - loss: 0.0688 - accuracy: 0.0056\n",
      "Epoch 6/10\n",
      "1490/1490 [==============================] - 35s 23ms/step - loss: 0.0685 - accuracy: 0.0057\n",
      "Epoch 7/10\n",
      "1490/1490 [==============================] - 35s 23ms/step - loss: 0.0682 - accuracy: 0.0059\n",
      "Epoch 8/10\n",
      "1490/1490 [==============================] - 35s 23ms/step - loss: 0.0679 - accuracy: 0.0059\n",
      "Epoch 9/10\n",
      "1490/1490 [==============================] - 34s 23ms/step - loss: 0.0676 - accuracy: 0.0060\n",
      "Epoch 10/10\n",
      "1490/1490 [==============================] - 35s 23ms/step - loss: 0.0672 - accuracy: 0.0061\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.07169300943486534]\n",
      "[False  True]      [0.10001259 0.89998741]\n",
      "[False  True]      [0.07793735 0.92206265]      [  928 10979]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7393 1116]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10778  1125]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10330  1573]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6430]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10779  1124]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10510]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [2770 9138]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4655 1113]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10702  1194]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [8369 3534]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [4569 7305]\n",
      "0.767383271750084\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_6d_af_a9\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_42 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_21 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_20 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1315/1315 [==============================] - 39s 23ms/step - loss: 0.0828 - accuracy: 0.0040\n",
      "Epoch 2/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0709 - accuracy: 0.0030\n",
      "Epoch 3/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0699 - accuracy: 0.0032\n",
      "Epoch 4/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0693 - accuracy: 0.0034\n",
      "Epoch 5/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0685 - accuracy: 0.0036\n",
      "Epoch 6/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0677 - accuracy: 0.0036\n",
      "Epoch 7/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0673 - accuracy: 0.0038\n",
      "Epoch 8/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0668 - accuracy: 0.0043\n",
      "Epoch 9/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0663 - accuracy: 0.0046\n",
      "Epoch 10/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0658 - accuracy: 0.0049\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.0721314544690255]\n",
      "[False  True]      [0.10002139 0.89997861]\n",
      "[False  True]      [0.16392351 0.83607649]      [1723 8788]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8509]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [2685 7826]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11903]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11907]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11903]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6357   73]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11903]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10417    93]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11908]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5768]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11896]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11903]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11874]\n",
      "0.7445533250880031\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_7f_ec_53\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_44 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_22 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_21 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1489/1489 [==============================] - 40s 23ms/step - loss: 0.0837 - accuracy: 0.0051\n",
      "Epoch 2/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0691 - accuracy: 0.0032\n",
      "Epoch 3/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0661 - accuracy: 0.0031\n",
      "Epoch 4/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0620 - accuracy: 0.0030\n",
      "Epoch 5/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0612 - accuracy: 0.0030\n",
      "Epoch 6/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0604 - accuracy: 0.0031\n",
      "Epoch 7/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0599 - accuracy: 0.0032\n",
      "Epoch 8/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0596 - accuracy: 0.0031\n",
      "Epoch 9/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0594 - accuracy: 0.0032\n",
      "Epoch 10/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0592 - accuracy: 0.0032\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06576879679871667]\n",
      "[False  True]      [0.1000105 0.8999895]\n",
      "[False  True]      [0.07787953 0.92212047]      [  927 10976]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7400 1109]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10803  1100]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [10796  1111]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6430]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10791  1112]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10510]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [10798  1110]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4610 1158]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10782  1114]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [10789  1114]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [4536 7338]\n",
      "0.617988883274381\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_87_a7_ce\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_46 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_23 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_47 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_22 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "805/805 [==============================] - 27s 24ms/step - loss: 0.0866 - accuracy: 0.0047\n",
      "Epoch 2/10\n",
      "805/805 [==============================] - 19s 24ms/step - loss: 0.0808 - accuracy: 0.0051\n",
      "Epoch 3/10\n",
      "805/805 [==============================] - 19s 24ms/step - loss: 0.0755 - accuracy: 0.0040\n",
      "Epoch 4/10\n",
      "805/805 [==============================] - 19s 23ms/step - loss: 0.0736 - accuracy: 0.0049\n",
      "Epoch 5/10\n",
      "805/805 [==============================] - 19s 23ms/step - loss: 0.0713 - accuracy: 0.0049\n",
      "Epoch 6/10\n",
      "805/805 [==============================] - 19s 23ms/step - loss: 0.0695 - accuracy: 0.0049\n",
      "Epoch 7/10\n",
      "805/805 [==============================] - 19s 23ms/step - loss: 0.0691 - accuracy: 0.0050\n",
      "Epoch 8/10\n",
      "805/805 [==============================] - 19s 23ms/step - loss: 0.0687 - accuracy: 0.0051\n",
      "Epoch 9/10\n",
      "805/805 [==============================] - 19s 23ms/step - loss: 0.0684 - accuracy: 0.0049\n",
      "Epoch 10/10\n",
      "805/805 [==============================] - 19s 23ms/step - loss: 0.0681 - accuracy: 0.0047\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.07502594590704667]\n",
      "[False  True]      [0.10001554 0.89998446]\n",
      "[False  True]      [0.14136858 0.85863142]      [ 909 5521]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [6604 1905]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10507     2]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10507     4]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10403   110]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [9983  528]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [8712 3191]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [7718 4189]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10495    16]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [8993 2910]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [8124 3779]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [1613 8897]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10318   192]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [7720 4188]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4200 1568]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [9257 2639]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [7592 4311]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [8032 3842]\n",
      "0.8465271170313987\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_8c_24_61\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_48 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_24 (Reshape)        (None, 10, 5)             0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " lstm_49 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_23 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1489/1489 [==============================] - 40s 23ms/step - loss: 0.0838 - accuracy: 0.0053\n",
      "Epoch 2/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0706 - accuracy: 0.0037\n",
      "Epoch 3/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0676 - accuracy: 0.0036\n",
      "Epoch 4/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0646 - accuracy: 0.0034\n",
      "Epoch 5/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0617 - accuracy: 0.0031\n",
      "Epoch 6/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0612 - accuracy: 0.0033\n",
      "Epoch 7/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0606 - accuracy: 0.0032\n",
      "Epoch 8/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0601 - accuracy: 0.0033\n",
      "Epoch 9/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0599 - accuracy: 0.0032\n",
      "Epoch 10/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0597 - accuracy: 0.0033\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06640048508133403]\n",
      "[False  True]      [0.1000084 0.8999916]\n",
      "[False  True]      [0.08938923 0.91061077]      [ 1064 10839]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7396 1113]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [ 1134 10769]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [10786  1121]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10702  1201]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6430]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10510]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [10796  1112]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4657 1111]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [2664 9232]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [10410  1493]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [4605 7269]\n",
      "0.9047299000252037\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_8e_97_06\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_50 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_25 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_51 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_24 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1315/1315 [==============================] - 37s 23ms/step - loss: 0.0850 - accuracy: 0.0047\n",
      "Epoch 2/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0779 - accuracy: 0.0040\n",
      "Epoch 3/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0735 - accuracy: 0.0038\n",
      "Epoch 4/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0700 - accuracy: 0.0035\n",
      "Epoch 5/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0694 - accuracy: 0.0040\n",
      "Epoch 6/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0688 - accuracy: 0.0040\n",
      "Epoch 7/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0679 - accuracy: 0.0039\n",
      "Epoch 8/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0669 - accuracy: 0.0040\n",
      "Epoch 9/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0664 - accuracy: 0.0041\n",
      "Epoch 10/10\n",
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0662 - accuracy: 0.0042\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.07339647573026899]\n",
      "[False  True]      [0.10000713 0.89999287]\n",
      "[False  True]      [0.10285442 0.89714558]      [1081 9429]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8509]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10512     1]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10476    35]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11903]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11907]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11903]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [1240 5190]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11903]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10492    18]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11908]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5768]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11896]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11903]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11874]\n",
      "0.807153965785381\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_91_48_fe\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_52 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_26 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_53 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_25 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1315/1315 [==============================] - 37s 23ms/step - loss: 0.0844 - accuracy: 0.0042\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1315/1315 [==============================] - 30s 23ms/step - loss: 0.0720 - accuracy: 0.0034\n",
      "Epoch 3/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0706 - accuracy: 0.0035\n",
      "Epoch 4/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0698 - accuracy: 0.0033\n",
      "Epoch 5/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0690 - accuracy: 0.0032\n",
      "Epoch 6/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0684 - accuracy: 0.0032\n",
      "Epoch 7/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0679 - accuracy: 0.0033\n",
      "Epoch 8/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0675 - accuracy: 0.0035\n",
      "Epoch 9/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0672 - accuracy: 0.0035\n",
      "Epoch 10/10\n",
      "1315/1315 [==============================] - 31s 23ms/step - loss: 0.0668 - accuracy: 0.0039\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.07260588115944848]\n",
      "[False  True]      [0.10001189 0.89998811]\n",
      "[False  True]      [0.1376784 0.8623216]      [1447 9063]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8509]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10433    76]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10503     8]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [2116 8397]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10363   147]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [ 997 9514]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11903]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11907]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10395   116]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11903]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5941  489]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11903]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10187   323]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11908]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5768]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11896]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11903]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11874]\n",
      "0.9051469888688041\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_c2_b6_e9\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_54 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_27 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_55 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_26 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1490/1490 [==============================] - 41s 23ms/step - loss: 0.0797 - accuracy: 0.0036\n",
      "Epoch 2/10\n",
      "1490/1490 [==============================] - 35s 23ms/step - loss: 0.0709 - accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "1490/1490 [==============================] - 35s 23ms/step - loss: 0.0698 - accuracy: 0.0035\n",
      "Epoch 4/10\n",
      "1490/1490 [==============================] - 35s 23ms/step - loss: 0.0671 - accuracy: 0.0033\n",
      "Epoch 5/10\n",
      "1490/1490 [==============================] - 34s 23ms/step - loss: 0.0633 - accuracy: 0.0033\n",
      "Epoch 6/10\n",
      "1490/1490 [==============================] - 34s 23ms/step - loss: 0.0616 - accuracy: 0.0033\n",
      "Epoch 7/10\n",
      "1490/1490 [==============================] - 34s 23ms/step - loss: 0.0608 - accuracy: 0.0034\n",
      "Epoch 8/10\n",
      "1490/1490 [==============================] - 34s 23ms/step - loss: 0.0604 - accuracy: 0.0035\n",
      "Epoch 9/10\n",
      "1490/1490 [==============================] - 34s 23ms/step - loss: 0.0597 - accuracy: 0.0036\n",
      "Epoch 10/10\n",
      "1490/1490 [==============================] - 34s 23ms/step - loss: 0.0590 - accuracy: 0.0036\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06462894690964817]\n",
      "[False  True]      [0.10000839 0.89999161]\n",
      "[False  True]      [0.09833725 0.90166275]      [ 1171 10737]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7404 1105]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10804  1099]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [9260 2647]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10786  1117]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6430]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10790  1113]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10510]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4663 1105]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10780  1116]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [10767  1136]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [4645 7229]\n",
      "0.6088091628768738\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_d5_e5_0b\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_56 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_28 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_57 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_27 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "722/722 [==============================] - 23s 23ms/step - loss: 0.0872 - accuracy: 0.0049\n",
      "Epoch 2/10\n",
      "722/722 [==============================] - 17s 23ms/step - loss: 0.0788 - accuracy: 0.0050\n",
      "Epoch 3/10\n",
      "722/722 [==============================] - 16s 23ms/step - loss: 0.0694 - accuracy: 0.0033\n",
      "Epoch 4/10\n",
      "722/722 [==============================] - 17s 23ms/step - loss: 0.0642 - accuracy: 0.0029\n",
      "Epoch 5/10\n",
      "722/722 [==============================] - 17s 23ms/step - loss: 0.0631 - accuracy: 0.0028\n",
      "Epoch 6/10\n",
      "722/722 [==============================] - 16s 23ms/step - loss: 0.0627 - accuracy: 0.0028\n",
      "Epoch 7/10\n",
      "722/722 [==============================] - 17s 23ms/step - loss: 0.0624 - accuracy: 0.0028\n",
      "Epoch 8/10\n",
      "722/722 [==============================] - 17s 23ms/step - loss: 0.0621 - accuracy: 0.0028\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722/722 [==============================] - 17s 23ms/step - loss: 0.0619 - accuracy: 0.0028\n",
      "Epoch 10/10\n",
      "722/722 [==============================] - 17s 23ms/step - loss: 0.0617 - accuracy: 0.0028\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06786904225553425]\n",
      "[False  True]      [0.10000433 0.89999567]\n",
      "[False  True]      [0.06397365 0.93602635]      [ 369 5399]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7397 1112]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10796  1107]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [10767  1140]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [3853 8050]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6430]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10788  1115]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10510]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [10797  1111]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10775  1121]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [10666  1237]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [4492 7382]\n",
      "0.6763000924136773\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_dc_61_2f\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_58 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_29 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_59 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_28 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1488/1488 [==============================] - 42s 23ms/step - loss: 0.0839 - accuracy: 0.0044\n",
      "Epoch 2/10\n",
      "1488/1488 [==============================] - 35s 24ms/step - loss: 0.0776 - accuracy: 0.0045\n",
      "Epoch 3/10\n",
      "1488/1488 [==============================] - 35s 23ms/step - loss: 0.0750 - accuracy: 0.0042\n",
      "Epoch 4/10\n",
      "1488/1488 [==============================] - 35s 23ms/step - loss: 0.0684 - accuracy: 0.0032\n",
      "Epoch 5/10\n",
      "1488/1488 [==============================] - 35s 23ms/step - loss: 0.0674 - accuracy: 0.0032\n",
      "Epoch 6/10\n",
      "1488/1488 [==============================] - 35s 23ms/step - loss: 0.0635 - accuracy: 0.0027\n",
      "Epoch 7/10\n",
      "1488/1488 [==============================] - 35s 23ms/step - loss: 0.0624 - accuracy: 0.0028\n",
      "Epoch 8/10\n",
      "1488/1488 [==============================] - 35s 23ms/step - loss: 0.0620 - accuracy: 0.0028\n",
      "Epoch 9/10\n",
      "1488/1488 [==============================] - 35s 23ms/step - loss: 0.0617 - accuracy: 0.0029\n",
      "Epoch 10/10\n",
      "1488/1488 [==============================] - 35s 23ms/step - loss: 0.0614 - accuracy: 0.0029\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06865163936969676]\n",
      "[False  True]      [0.1 0.9]\n",
      "[False  True]      [0.09709146 0.90290854]      [ 1155 10741]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7395 1114]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [2509 9394]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [10674  1233]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10407  1496]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6430]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [ 1685 10218]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10510]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [10754  1154]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4651 1117]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [8902 3001]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [4562 7312]\n",
      "0.8584390489792489\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_e1_66_63\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_60 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_30 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_61 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_29 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1489/1489 [==============================] - 41s 23ms/step - loss: 0.0808 - accuracy: 0.0040\n",
      "Epoch 2/10\n",
      "1489/1489 [==============================] - 35s 23ms/step - loss: 0.0738 - accuracy: 0.0052\n",
      "Epoch 3/10\n",
      "1489/1489 [==============================] - 35s 23ms/step - loss: 0.0646 - accuracy: 0.0038\n",
      "Epoch 4/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0613 - accuracy: 0.0039\n",
      "Epoch 5/10\n",
      "1489/1489 [==============================] - 35s 23ms/step - loss: 0.0605 - accuracy: 0.0038\n",
      "Epoch 6/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0601 - accuracy: 0.0039\n",
      "Epoch 7/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0599 - accuracy: 0.0039\n",
      "Epoch 8/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0594 - accuracy: 0.0038\n",
      "Epoch 9/10\n",
      "1489/1489 [==============================] - 35s 23ms/step - loss: 0.0586 - accuracy: 0.0037\n",
      "Epoch 10/10\n",
      "1489/1489 [==============================] - 34s 23ms/step - loss: 0.0581 - accuracy: 0.0037\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06539191317364033]\n",
      "[False  True]      [0.1000084 0.8999916]\n",
      "[False  True]      [0.0635134 0.9364866]      [  756 11147]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7397 1112]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10801  1102]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [10796  1111]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10777  1126]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6430]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10791  1112]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10510]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [10798  1110]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4667 1101]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10778  1118]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [4623 7251]\n",
      "0.6106619504800405\n",
      "\n",
      "\n",
      "Training model for feat_gpu_b8_27_eb_ea_38_52\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_62 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_31 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_63 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_30 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1486/1486 [==============================] - 41s 23ms/step - loss: 0.0630 - accuracy: 0.0050\n",
      "Epoch 2/10\n",
      "1486/1486 [==============================] - 34s 23ms/step - loss: 0.0503 - accuracy: 0.0051\n",
      "Epoch 3/10\n",
      "1486/1486 [==============================] - 34s 23ms/step - loss: 0.0433 - accuracy: 0.0047\n",
      "Epoch 4/10\n",
      "1486/1486 [==============================] - 34s 23ms/step - loss: 0.0421 - accuracy: 0.0047\n",
      "Epoch 5/10\n",
      "1486/1486 [==============================] - 34s 23ms/step - loss: 0.0416 - accuracy: 0.0049\n",
      "Epoch 6/10\n",
      "1486/1486 [==============================] - 34s 23ms/step - loss: 0.0413 - accuracy: 0.0049\n",
      "Epoch 7/10\n",
      "1486/1486 [==============================] - 34s 23ms/step - loss: 0.0411 - accuracy: 0.0048\n",
      "Epoch 8/10\n",
      "1486/1486 [==============================] - 34s 23ms/step - loss: 0.0409 - accuracy: 0.0049\n",
      "Epoch 9/10\n",
      "1486/1486 [==============================] - 34s 23ms/step - loss: 0.0407 - accuracy: 0.0051\n",
      "Epoch 10/10\n",
      "1486/1486 [==============================] - 34s 23ms/step - loss: 0.0405 - accuracy: 0.0051\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.05109187263935346]\n",
      "[False  True]      [0.10001894 0.89998106]\n",
      "[False  True]      [0.06038403 0.93961597]      [  717 11157]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7408 1101]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10509]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10511]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10515]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10513]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10510]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10511]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10806  1097]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [10799  1108]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10511]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10802  1101]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6430]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10795  1108]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10510]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10510]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [10805  1103]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4666 1102]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10790  1106]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [10799  1104]\n",
      "0.19105409153952843\n",
      "\n",
      "\n",
      "Training model for feat_gpu_dc_a6_32_14_a6_53\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_64 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_32 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_65 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_31 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1294/1294 [==============================] - 36s 23ms/step - loss: 0.0721 - accuracy: 0.0075\n",
      "Epoch 2/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0616 - accuracy: 0.0080\n",
      "Epoch 3/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0595 - accuracy: 0.0075\n",
      "Epoch 4/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0585 - accuracy: 0.0075\n",
      "Epoch 5/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0580 - accuracy: 0.0073\n",
      "Epoch 6/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0578 - accuracy: 0.0073\n",
      "Epoch 7/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0575 - accuracy: 0.0074\n",
      "Epoch 8/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0572 - accuracy: 0.0073\n",
      "Epoch 9/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0569 - accuracy: 0.0072\n",
      "Epoch 10/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0566 - accuracy: 0.0073\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06573969560033008]\n",
      "[False  True]      [0.10000967 0.89999033]\n",
      "[False  True]      [0.14893617 0.85106383]      [1540 8800]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [6290 4048]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [3987 6353]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [3191 8018]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [2414 7716]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [2545 5250]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [4617 6586]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [3868 4765]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [8395 1971]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [1431 8924]\n",
      "0.861805890873974\n",
      "\n",
      "\n",
      "Training model for feat_gpu_dc_a6_32_14_a8_d8\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_66 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_33 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_67 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_32 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1293/1293 [==============================] - 36s 23ms/step - loss: 0.0720 - accuracy: 0.0075\n",
      "Epoch 2/10\n",
      "1293/1293 [==============================] - 30s 23ms/step - loss: 0.0605 - accuracy: 0.0076\n",
      "Epoch 3/10\n",
      "1293/1293 [==============================] - 29s 23ms/step - loss: 0.0595 - accuracy: 0.0077\n",
      "Epoch 4/10\n",
      "1293/1293 [==============================] - 30s 23ms/step - loss: 0.0589 - accuracy: 0.0073\n",
      "Epoch 5/10\n",
      "1293/1293 [==============================] - 30s 23ms/step - loss: 0.0587 - accuracy: 0.0077\n",
      "Epoch 6/10\n",
      "1293/1293 [==============================] - 30s 23ms/step - loss: 0.0585 - accuracy: 0.0075\n",
      "Epoch 7/10\n",
      "1293/1293 [==============================] - 30s 23ms/step - loss: 0.0583 - accuracy: 0.0076\n",
      "Epoch 8/10\n",
      "1293/1293 [==============================] - 30s 23ms/step - loss: 0.0580 - accuracy: 0.0076\n",
      "Epoch 9/10\n",
      "1293/1293 [==============================] - 30s 23ms/step - loss: 0.0578 - accuracy: 0.0077\n",
      "Epoch 10/10\n",
      "1293/1293 [==============================] - 30s 23ms/step - loss: 0.0577 - accuracy: 0.0076\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06879878451608963]\n",
      "[False  True]      [0.10001208 0.89998792]\n",
      "[False  True]      [0.21532211 0.78467789]      [2226 8112]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [1090 9250]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [2259 8081]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [  853 10356]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [ 553 9577]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [ 541 7254]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [ 1051 10152]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [1002 7631]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [8376 1990]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [   90 10265]\n",
      "0.9913085465958474\n",
      "\n",
      "\n",
      "Training model for feat_gpu_dc_a6_32_14_ab_0a\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_68 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_34 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_69 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_33 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1294/1294 [==============================] - 36s 23ms/step - loss: 0.0718 - accuracy: 0.0078\n",
      "Epoch 2/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0610 - accuracy: 0.0081\n",
      "Epoch 3/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0584 - accuracy: 0.0079\n",
      "Epoch 4/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0576 - accuracy: 0.0081\n",
      "Epoch 5/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0566 - accuracy: 0.0081\n",
      "Epoch 6/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0561 - accuracy: 0.0081\n",
      "Epoch 7/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0556 - accuracy: 0.0081\n",
      "Epoch 8/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0550 - accuracy: 0.0079\n",
      "Epoch 9/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0547 - accuracy: 0.0080\n",
      "Epoch 10/10\n",
      "1294/1294 [==============================] - 30s 23ms/step - loss: 0.0543 - accuracy: 0.0077\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.062093691978377615]\n",
      "[False  True]      [0.1000145 0.8999855]\n",
      "[False  True]      [0.29883946 0.70116054]      [3090 7250]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [1628 8712]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [5793 4545]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [9639 1570]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [8735 1395]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [6821  974]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [9893 1310]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [7843  790]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [8929 1437]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [2334 8021]\n",
      "0.8425531914893617\n",
      "\n",
      "\n",
      "Training model for feat_gpu_dc_a6_32_4c_8e_0a\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_70 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_35 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_71 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_34 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1402/1402 [==============================] - 39s 23ms/step - loss: 0.0743 - accuracy: 0.0075\n",
      "Epoch 2/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0665 - accuracy: 0.0071\n",
      "Epoch 3/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0646 - accuracy: 0.0066\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 33s 23ms/step - loss: 0.0611 - accuracy: 0.0053\n",
      "Epoch 5/10\n",
      "1402/1402 [==============================] - 33s 23ms/step - loss: 0.0600 - accuracy: 0.0052\n",
      "Epoch 6/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0591 - accuracy: 0.0052\n",
      "Epoch 7/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0586 - accuracy: 0.0052\n",
      "Epoch 8/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0583 - accuracy: 0.0050\n",
      "Epoch 9/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0580 - accuracy: 0.0048\n",
      "Epoch 10/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0579 - accuracy: 0.0049\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06374490967770716]\n",
      "[False  True]      [0.1000156 0.8999844]\n",
      "[False  True]      [0.06887323 0.93112677]      [  772 10437]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10340]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10338]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10340]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [9851  279]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7303  492]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [10504   699]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8559   74]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [9895  471]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10355]\n",
      "0.06311738293778063\n",
      "\n",
      "\n",
      "Training model for feat_gpu_dc_a6_32_4c_90_fb\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_72 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_36 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_73 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_35 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1267/1267 [==============================] - 21s 12ms/step - loss: 0.0739 - accuracy: 0.0068\n",
      "Epoch 2/10\n",
      "1267/1267 [==============================] - 16s 12ms/step - loss: 0.0638 - accuracy: 0.0068\n",
      "Epoch 3/10\n",
      "1267/1267 [==============================] - 16s 12ms/step - loss: 0.0629 - accuracy: 0.0063\n",
      "Epoch 4/10\n",
      "1267/1267 [==============================] - 16s 12ms/step - loss: 0.0624 - accuracy: 0.0063\n",
      "Epoch 5/10\n",
      "1267/1267 [==============================] - 16s 12ms/step - loss: 0.0621 - accuracy: 0.0065\n",
      "Epoch 6/10\n",
      "1267/1267 [==============================] - 16s 12ms/step - loss: 0.0616 - accuracy: 0.0063\n",
      "Epoch 7/10\n",
      "1267/1267 [==============================] - 16s 12ms/step - loss: 0.0602 - accuracy: 0.0057\n",
      "Epoch 8/10\n",
      "1267/1267 [==============================] - 16s 12ms/step - loss: 0.0589 - accuracy: 0.0052\n",
      "Epoch 9/10\n",
      "1267/1267 [==============================] - 16s 12ms/step - loss: 0.0579 - accuracy: 0.0047\n",
      "Epoch 10/10\n",
      "1267/1267 [==============================] - 16s 12ms/step - loss: 0.0573 - accuracy: 0.0046\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06268538121982711]\n",
      "[False  True]      [0.1000148 0.8999852]\n",
      "[False  True]      [0.09062192 0.90937808]      [ 918 9212]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10340]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10338]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10340]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [9859 1350]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [6561 1234]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [10295   908]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8375  258]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10366]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10355]\n",
      "0.15830660679923028\n",
      "\n",
      "\n",
      "Training model for feat_gpu_dc_a6_32_4c_98_93\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_74 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_37 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_75 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_36 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "976/976 [==============================] - 29s 23ms/step - loss: 0.0784 - accuracy: 0.0077\n",
      "Epoch 2/10\n",
      "976/976 [==============================] - 23s 23ms/step - loss: 0.0662 - accuracy: 0.0084\n",
      "Epoch 3/10\n",
      "976/976 [==============================] - 23s 23ms/step - loss: 0.0640 - accuracy: 0.0076\n",
      "Epoch 4/10\n",
      "976/976 [==============================] - 23s 23ms/step - loss: 0.0630 - accuracy: 0.0072\n",
      "Epoch 5/10\n",
      "976/976 [==============================] - 23s 23ms/step - loss: 0.0627 - accuracy: 0.0073\n",
      "Epoch 6/10\n",
      "976/976 [==============================] - 23s 23ms/step - loss: 0.0621 - accuracy: 0.0076\n",
      "Epoch 7/10\n",
      "976/976 [==============================] - 23s 23ms/step - loss: 0.0620 - accuracy: 0.0076\n",
      "Epoch 8/10\n",
      "976/976 [==============================] - 23s 23ms/step - loss: 0.0618 - accuracy: 0.0078\n",
      "Epoch 9/10\n",
      "976/976 [==============================] - 23s 23ms/step - loss: 0.0617 - accuracy: 0.0077\n",
      "Epoch 10/10\n",
      "976/976 [==============================] - 23s 23ms/step - loss: 0.0616 - accuracy: 0.0080\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06685348039090672]\n",
      "[False  True]      [0.10001923 0.89998077]\n",
      "[False  True]      [0.09890956 0.90109044]      [ 771 7024]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10340]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10338]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10340]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [1945 9264]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [3631 6499]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [5026 6177]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [4564 4069]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10307    59]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10355]\n",
      "0.82647872245517\n",
      "\n",
      "\n",
      "Training model for feat_gpu_dc_a6_32_4c_99_bf\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_76 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_38 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_77 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_37 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1402/1402 [==============================] - 40s 23ms/step - loss: 0.0742 - accuracy: 0.0080\n",
      "Epoch 2/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0667 - accuracy: 0.0081\n",
      "Epoch 3/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0615 - accuracy: 0.0057\n",
      "Epoch 4/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0576 - accuracy: 0.0048\n",
      "Epoch 5/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0571 - accuracy: 0.0049\n",
      "Epoch 6/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0568 - accuracy: 0.0049\n",
      "Epoch 7/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0566 - accuracy: 0.0049\n",
      "Epoch 8/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0564 - accuracy: 0.0048\n",
      "Epoch 9/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0563 - accuracy: 0.0047\n",
      "Epoch 10/10\n",
      "1402/1402 [==============================] - 32s 23ms/step - loss: 0.0561 - accuracy: 0.0046\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06177725370489626]\n",
      "[False  True]      [0.10000223 0.89999777]\n",
      "[False  True]      [0.08176381 0.91823619]      [  916 10287]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10339     1]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10334     4]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10325    15]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [7472 3737]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [9750  380]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7072  723]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8334  299]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [7931 2435]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10355]\n",
      "0.3333928093496298\n",
      "\n",
      "\n",
      "Training model for feat_gpu_dc_a6_32_4c_9a_79\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_78 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_39 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_79 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_38 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1080/1080 [==============================] - 31s 23ms/step - loss: 0.0763 - accuracy: 0.0082\n",
      "Epoch 2/10\n",
      "1080/1080 [==============================] - 25s 23ms/step - loss: 0.0671 - accuracy: 0.0092\n",
      "Epoch 3/10\n",
      "1080/1080 [==============================] - 25s 23ms/step - loss: 0.0651 - accuracy: 0.0074\n",
      "Epoch 4/10\n",
      "1080/1080 [==============================] - 25s 23ms/step - loss: 0.0602 - accuracy: 0.0051\n",
      "Epoch 5/10\n",
      "1080/1080 [==============================] - 25s 23ms/step - loss: 0.0579 - accuracy: 0.0047\n",
      "Epoch 6/10\n",
      "1080/1080 [==============================] - 25s 23ms/step - loss: 0.0573 - accuracy: 0.0049\n",
      "Epoch 7/10\n",
      "1080/1080 [==============================] - 25s 23ms/step - loss: 0.0569 - accuracy: 0.0049\n",
      "Epoch 8/10\n",
      "1080/1080 [==============================] - 25s 23ms/step - loss: 0.0567 - accuracy: 0.0047\n",
      "Epoch 9/10\n",
      "1080/1080 [==============================] - 25s 23ms/step - loss: 0.0565 - accuracy: 0.0050\n",
      "Epoch 10/10\n",
      "1080/1080 [==============================] - 25s 23ms/step - loss: 0.0564 - accuracy: 0.0048\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06217073493174435]\n",
      "[False  True]      [0.10000289 0.89999711]\n",
      "[False  True]      [0.0981119 0.9018881]      [ 847 7786]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10127   213]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10295    43]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9763  577]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [6242 4967]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [9588  542]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [6239 1556]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [8351 2852]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [2122 8244]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10351     4]\n",
      "0.79529230175574\n",
      "\n",
      "\n",
      "Training model for feat_gpu_dc_a6_32_e4_48_9e\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_80 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_40 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_81 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_39 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1297/1297 [==============================] - 38s 23ms/step - loss: 0.0724 - accuracy: 0.0057\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1297/1297 [==============================] - 30s 23ms/step - loss: 0.0624 - accuracy: 0.0054\n",
      "Epoch 3/10\n",
      "1297/1297 [==============================] - 31s 24ms/step - loss: 0.0605 - accuracy: 0.0056\n",
      "Epoch 4/10\n",
      "1297/1297 [==============================] - 30s 23ms/step - loss: 0.0593 - accuracy: 0.0062\n",
      "Epoch 5/10\n",
      "1297/1297 [==============================] - 30s 23ms/step - loss: 0.0577 - accuracy: 0.0063\n",
      "Epoch 6/10\n",
      "1297/1297 [==============================] - 30s 23ms/step - loss: 0.0565 - accuracy: 0.0055\n",
      "Epoch 7/10\n",
      "1297/1297 [==============================] - 30s 23ms/step - loss: 0.0556 - accuracy: 0.0051\n",
      "Epoch 8/10\n",
      "1297/1297 [==============================] - 30s 23ms/step - loss: 0.0552 - accuracy: 0.0049\n",
      "Epoch 9/10\n",
      "1297/1297 [==============================] - 30s 23ms/step - loss: 0.0548 - accuracy: 0.0047\n",
      "Epoch 10/10\n",
      "1297/1297 [==============================] - 30s 23ms/step - loss: 0.0545 - accuracy: 0.0045\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.060922046793196086]\n",
      "[False  True]      [0.10000482 0.89999518]\n",
      "[False  True]      [0.19428902 0.80571098]      [2014 8352]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [   66 10274]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [ 667 9671]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [ 506 9834]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11209]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10129     1]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7795]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11203]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8633]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10355]\n",
      "0.9936170212765958\n",
      "\n",
      "\n",
      "Training model for feat_gpu_dc_a6_32_e4_48_b3\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_82 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_41 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_83 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_40 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1296/1296 [==============================] - 36s 23ms/step - loss: 0.0728 - accuracy: 0.0077\n",
      "Epoch 2/10\n",
      "1296/1296 [==============================] - 30s 23ms/step - loss: 0.0649 - accuracy: 0.0079\n",
      "Epoch 3/10\n",
      "1296/1296 [==============================] - 29s 23ms/step - loss: 0.0643 - accuracy: 0.0082\n",
      "Epoch 4/10\n",
      "1296/1296 [==============================] - 30s 23ms/step - loss: 0.0640 - accuracy: 0.0083\n",
      "Epoch 5/10\n",
      "1296/1296 [==============================] - 30s 23ms/step - loss: 0.0637 - accuracy: 0.0084\n",
      "Epoch 6/10\n",
      "1296/1296 [==============================] - 30s 23ms/step - loss: 0.0632 - accuracy: 0.0083\n",
      "Epoch 7/10\n",
      "1296/1296 [==============================] - 30s 23ms/step - loss: 0.0625 - accuracy: 0.0083\n",
      "Epoch 8/10\n",
      "1296/1296 [==============================] - 30s 23ms/step - loss: 0.0623 - accuracy: 0.0082\n",
      "Epoch 9/10\n",
      "1296/1296 [==============================] - 30s 23ms/step - loss: 0.0622 - accuracy: 0.0083\n",
      "Epoch 10/10\n",
      "1296/1296 [==============================] - 30s 23ms/step - loss: 0.0621 - accuracy: 0.0085\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06675488715331963]\n",
      "[False  True]      [0.10001689 0.89998311]\n",
      "[False  True]      [0.10902945 0.89097055]      [1129 9226]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [3760 6580]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [7020 3318]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [7085 3255]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11209]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10130]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7795]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11203]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8633]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10357     9]\n",
      "0.6363636363636364\n",
      "\n",
      "\n",
      "Training model for feat_gpu_e4_5f_01_53_3d_49\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_84 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_42 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_85 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_41 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1401/1401 [==============================] - 40s 23ms/step - loss: 0.0715 - accuracy: 0.0054\n",
      "Epoch 2/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0608 - accuracy: 0.0054\n",
      "Epoch 3/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0601 - accuracy: 0.0056\n",
      "Epoch 4/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0594 - accuracy: 0.0060\n",
      "Epoch 5/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0590 - accuracy: 0.0059\n",
      "Epoch 6/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0585 - accuracy: 0.0060\n",
      "Epoch 7/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0574 - accuracy: 0.0059\n",
      "Epoch 8/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0550 - accuracy: 0.0047\n",
      "Epoch 9/10\n",
      "1401/1401 [==============================] - 33s 23ms/step - loss: 0.0542 - accuracy: 0.0044\n",
      "Epoch 10/10\n",
      "1401/1401 [==============================] - 33s 23ms/step - loss: 0.0535 - accuracy: 0.0043\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.05885927068706324]\n",
      "[False  True]      [0.1 0.9]\n",
      "[False  True]      [0.06348781 0.93651219]      [  711 10488]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11172    27]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [4322 6877]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11008   185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_e4_5f_01_53_3f_03 [11190]\n",
      "0.6140726850611662\n",
      "\n",
      "\n",
      "Training model for feat_gpu_e4_5f_01_53_3d_85\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_86 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_43 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_87 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_42 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1401/1401 [==============================] - 38s 23ms/step - loss: 0.0751 - accuracy: 0.0065\n",
      "Epoch 2/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0673 - accuracy: 0.0071\n",
      "Epoch 3/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0667 - accuracy: 0.0071\n",
      "Epoch 4/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0639 - accuracy: 0.0068\n",
      "Epoch 5/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0600 - accuracy: 0.0054\n",
      "Epoch 6/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0590 - accuracy: 0.0055\n",
      "Epoch 7/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0588 - accuracy: 0.0056\n",
      "Epoch 8/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0587 - accuracy: 0.0055\n",
      "Epoch 9/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0586 - accuracy: 0.0055\n",
      "Epoch 10/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0586 - accuracy: 0.0055\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.06480008344320963]\n",
      "[False  True]      [0.10001562 0.89998438]\n",
      "[False  True]      [0.16858648 0.83141352]      [1888 9311]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11199]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11199]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11193]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [9881 1309]\n",
      "0.11697944593386952\n",
      "\n",
      "\n",
      "Training model for feat_gpu_e4_5f_01_53_3d_c5\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_88 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_44 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_89 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_43 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1401/1401 [==============================] - 40s 23ms/step - loss: 0.0711 - accuracy: 0.0050\n",
      "Epoch 2/10\n",
      "1401/1401 [==============================] - 33s 23ms/step - loss: 0.0610 - accuracy: 0.0057\n",
      "Epoch 3/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0602 - accuracy: 0.0060\n",
      "Epoch 4/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0588 - accuracy: 0.0059\n",
      "Epoch 5/10\n",
      "1401/1401 [==============================] - 33s 23ms/step - loss: 0.0549 - accuracy: 0.0047\n",
      "Epoch 6/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0524 - accuracy: 0.0042\n",
      "Epoch 7/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0516 - accuracy: 0.0042\n",
      "Epoch 8/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0511 - accuracy: 0.0041\n",
      "Epoch 9/10\n",
      "1401/1401 [==============================] - 32s 23ms/step - loss: 0.0514 - accuracy: 0.0042\n",
      "Epoch 10/10\n",
      "1401/1401 [==============================] - 33s 23ms/step - loss: 0.0509 - accuracy: 0.0039\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.05707967420618789]\n",
      "[False  True]      [0.10001785 0.89998215]\n",
      "[False  True]      [0.09215108 0.90784892]      [ 1032 10167]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [7277 3922]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11198     1]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11049   144]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11190]\n",
      "0.3502098401643004\n",
      "\n",
      "\n",
      "Training model for feat_gpu_e4_5f_01_53_3e_39\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_90 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_45 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_91 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_44 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 39s 23ms/step - loss: 0.0679 - accuracy: 0.0043\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0561 - accuracy: 0.0041\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0554 - accuracy: 0.0044\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0549 - accuracy: 0.0044\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0545 - accuracy: 0.0044\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0541 - accuracy: 0.0045\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0538 - accuracy: 0.0045\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0536 - accuracy: 0.0044\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0535 - accuracy: 0.0044\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0533 - accuracy: 0.0046\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.05956425464387522]\n",
      "[False  True]      [0.10000223 0.89999777]\n",
      "[False  True]      [0.07540427 0.92459573]      [  844 10349]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [10967   232]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [7217 3982]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [10602   597]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11066   124]\n",
      "0.3555674613804804\n",
      "\n",
      "\n",
      "Training model for feat_gpu_e4_5f_01_53_3f_03\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_92 (LSTM)              (None, 64)                71680     \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " reshape_46 (Reshape)        (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm_93 (LSTM)              (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " time_distributed_45 (TimeDi  (None, 10, 215)          13975     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,825\n",
      "Trainable params: 106,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 38s 23ms/step - loss: 0.0740 - accuracy: 0.0073\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0650 - accuracy: 0.0066\n",
      "Epoch 3/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0581 - accuracy: 0.0050\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0565 - accuracy: 0.0050\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0558 - accuracy: 0.0047\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0554 - accuracy: 0.0049\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0551 - accuracy: 0.0050\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0548 - accuracy: 0.0048\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0546 - accuracy: 0.0049\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 32s 23ms/step - loss: 0.0545 - accuracy: 0.0050\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[0.060642658589285046]\n",
      "[False  True]      [0.1000067 0.8999933]\n",
      "[False  True]      [0.10420018 0.89579982]      [ 1166 10024]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11144    55]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [ 1042 10157]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11099   100]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [10222   971]\n",
      "0.9069559782123404\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_FPR={}\n",
    "TPR={}\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print(f'Number of devices: {strategy.num_replicas_in_sync}')\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    for f in file_names:    \n",
    "\n",
    "        #Training\n",
    "        print(\"Training model for \"+f)\n",
    "        model=generate_model()\n",
    "        es = EarlyStopping(monitor='loss', mode='min',patience=20)\n",
    "        mc = ModelCheckpoint('best_model_autoenc_'+f+'.h5', monitor='loss', mode='min', save_best_only=True)\n",
    "\n",
    "        history = model.fit(df_dict_train[f], df_dict_train[f], epochs=10, batch_size=32, verbose=1, callbacks=[es, mc])#, validation_data=(X_val, y_val), callbacks=[es, mc])\n",
    "\n",
    "        #Denoising\n",
    "        #noise_factor = 0.05\n",
    "        #X_train_noisy = df_dict_train[f] + noise_factor * np.random.normal(size=df_dict_train[f].shape)\n",
    "        #X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
    "        #history = model.fit(X_train_noisy, df_dict_train[f], epochs=10, batch_size=32, verbose=1, callbacks=[es, mc])#, validation_data=(X_val, y_val), callbacks=[es, mc])\n",
    "\n",
    "        model = load_model('best_model_autoenc_'+f+'.h5')\n",
    "\n",
    "        #Eval\n",
    "        max_FPR[f]=0\n",
    "\n",
    "        thresh = get_threshold_mse_percentage(model,df_dict_train[f],0.10)\n",
    "        print(thresh)\n",
    "\n",
    "        mad_outliers = detect_outliers(model, df_dict_train[f], thresh)\n",
    "        unique_elements, counts_elements = np.unique(mad_outliers, return_counts=True)\n",
    "        print(unique_elements,\"    \",counts_elements/mad_outliers[0].shape[0])        \n",
    "\n",
    "        mad_outliers = detect_outliers(model, df_dict_test_df[f][f], thresh)\n",
    "        unique_elements, counts_elements = np.unique(mad_outliers, return_counts=True)\n",
    "        print(unique_elements,\"    \",counts_elements/mad_outliers[0].shape[0],\"    \",counts_elements)\n",
    "\n",
    "        if len(counts_elements)==2:\n",
    "            TPR[f]=counts_elements[1]/mad_outliers[0].shape[0]\n",
    "        else:\n",
    "            TPR[f]=0\n",
    "\n",
    "        for f2 in file_names:\n",
    "            if f != f2 and f.startswith(f2[:10]):\n",
    "                mad_outliers = detect_outliers(model, df_dict_test_df[f][f2], thresh)\n",
    "                unique_elements, counts_elements = np.unique(mad_outliers, return_counts=True)\n",
    "                print(f2+\" \"+str(counts_elements))\n",
    "                if len(counts_elements)==2 and (counts_elements[1]/mad_outliers[0].shape[0])>max_FPR[f]:\n",
    "                    max_FPR[f]=counts_elements[1]/mad_outliers[0].shape[0]\n",
    "\n",
    "        print(max_FPR[f])\n",
    "\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f3c48aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate sample data\n",
    "\n",
    "series1 = list(TPR.values())\n",
    "series2 = list(max_FPR.values())\n",
    "\n",
    "# Calculate statistics\n",
    "series1_stats = {\n",
    "    'mean': np.mean(series1),\n",
    "    'q1': np.percentile(series1, 25),\n",
    "    'q3': np.percentile(series1, 75),\n",
    "    'std': np.std(series1)\n",
    "}\n",
    "\n",
    "series2_stats = {\n",
    "    'mean': np.mean(series2),\n",
    "    'q1': np.percentile(series2, 25),\n",
    "    'q3': np.percentile(series2, 75),\n",
    "    'std': np.std(series2)\n",
    "}\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "# Plot the box plots\n",
    "box_plot = ax.boxplot([series2, series1], patch_artist=True, vert=False)\n",
    "\n",
    "# Customize the box colors\n",
    "colors = ['lightgreen', 'lightblue']\n",
    "for patch, color in zip(box_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add a red diamond for the means\n",
    "#means = [series1_stats['mean'], series2_stats['mean']]\n",
    "#ax.plot(means, [1, 2], marker='D', color='red', markersize=8)\n",
    "\n",
    "# Set the axis labels and title\n",
    "ax.set_xticklabels(ax.get_xticks(), rotation=0)\n",
    "ax.set_yticklabels(['Max_FPR', 'TPR'], rotation=0)\n",
    "ax.set_xlabel('Value')\n",
    "#ax.set_title('Box Chart with Statistics')\n",
    "\n",
    "# Add a legend\n",
    "legend_text = ['Max_FPR', 'TPR']\n",
    "ax.legend(box_plot['boxes'] + [ax.lines[0]], legend_text)\n",
    "\n",
    "# Add text annotations for statistics\n",
    "stats_text = (\n",
    "    f\"TPR\\nMean: {series1_stats['mean']:.2f}\\nQ1: {series1_stats['q1']:.2f}\"\n",
    "    f\"\\nQ3: {series1_stats['q3']:.2f}\\nStd Dev: {series1_stats['std']:.2f}\\n\\n\"\n",
    "    f\"Max_FPR\\nMean: {series2_stats['mean']:.2f}\\nQ1: {series2_stats['q1']:.2f}\"\n",
    "    f\"\\nQ3: {series2_stats['q3']:.2f}\\nStd Dev: {series2_stats['std']:.2f}\"\n",
    ")\n",
    "ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=10, va='top', bbox={'facecolor': 'white'})\n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x:.2f}'))\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda88ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23096b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#38 128-50-128 n:10 sw\n",
    "#38 128-50-128 n:10 sw batch:16\n",
    "#37 128-50-128 n:10 z:15 sw\n",
    "#36 128-64-50-64-128 n:10\n",
    "#36 128-50-128 n:10 batch:8\n",
    "#35 128-30-128 n:5\n",
    "#34 128-40-128 n:4\n",
    "#34 128-30-128 n:3\n",
    "#33 128-50-125 n:25\n",
    "#33 128-30-128 z:15 n:3\n",
    "#33 128-40-128 n:5\n",
    "#31 64-30-64 n:3\n",
    "#31 128-30-128 n:2\n",
    "#31 64-20-64 z:10 n:2\n",
    "#30 128-20-128 n:10\n",
    "#29 128-20-128 z:15 n:5\n",
    "#26 128-50-128 n:10\n",
    "#28 128-30-128 n:10\n",
    "#23 64-30-64 n:10\n",
    "#22 128-40-128 z:inf n:5\n",
    "#21 32-30-32 n:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e04e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acf1722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Enable mixed precision training\n",
    "#mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b720caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled dot product attention\n",
    "def scaled_dot_product_attention(q, k, v):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32) #float32 \n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53f9df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-head attention\n",
    "class MultiHeadAttention(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = layers.Dense(d_model)\n",
    "        self.wk = layers.Dense(d_model)\n",
    "        self.wv = layers.Dense(d_model)\n",
    "\n",
    "        self.dense = layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, _ = scaled_dot_product_attention(q, k, v)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        output = self.dense(concat_attention)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9fb662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer encoder layer\n",
    "class EncoderLayer(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1, name=None, **kwargs):\n",
    "        super(EncoderLayer, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = models.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model)])\n",
    "\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training):\n",
    "        attn_output = self.mha(x, x, x)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4d5967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer encoder\n",
    "def create_encoder(input_shape, num_layers, d_model, num_heads, dff, rate=0.1):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = EncoderLayer(d_model, num_heads, dff, rate)(x, training=True)\n",
    "\n",
    "    encoder = models.Model(inputs=inputs, outputs=x)\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6ea7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer decoder layer\n",
    "class DecoderLayer(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1, name=None, **kwargs):\n",
    "        super(DecoderLayer, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.self_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = models.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model)])\n",
    "        \n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training):\n",
    "        attn_output1 = self.self_mha(x, x, x)\n",
    "        attn_output1 = self.dropout1(attn_output1, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output1)\n",
    "\n",
    "        attn_output2 = self.enc_dec_mha(out1, enc_output, enc_output)\n",
    "        attn_output2 = self.dropout2(attn_output2, training=training)\n",
    "        out2 = self.layernorm2(out1 + attn_output2)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(out2 + ffn_output)\n",
    "\n",
    "        return out3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97741422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decoder(input_shape, num_layers, d_model, num_heads, dff, rate=0.1):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    enc_outputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = inputs\n",
    "    for _ in range(num_layers):\n",
    "        x = DecoderLayer(d_model, num_heads, dff, rate)(x, enc_outputs, training=True)\n",
    "\n",
    "    x = layers.Dense(input_shape[-1])(x)\n",
    "    decoder = models.Model(inputs=[inputs, enc_outputs], outputs=x)\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c81c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {\n",
    "    'EncoderLayer': EncoderLayer,\n",
    "    'DecoderLayer': DecoderLayer\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61ba4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (100, 215)\n",
    "num_layers = 1\n",
    "d_model = 215\n",
    "num_heads = 5\n",
    "dff = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0de6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_values=[256,1024]\n",
    "num_layer_values=[1]\n",
    "epoch_values=[10,20,50]\n",
    "batch_values=[128,192,256,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a0d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_FPR={}\n",
    "with open('max_FPR.pkl', 'rb') as fp:\n",
    "    max_FPR=pickle.load(fp)\n",
    "\n",
    "TPR={}\n",
    "with open('TPR.pkl', 'rb') as fp:\n",
    "    TPR=pickle.load(fp)\n",
    "\n",
    "best_params={}\n",
    "with open('best_params.pkl', 'rb') as fp:\n",
    "    best_params=pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841ced1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e84e7c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "256 1 10 128\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "INFO:tensorflow:batch_all_reduce: 44 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 44 all-reduces with algorithm = nccl, num_packs = 1\n",
      "[0.005279474671492555]\n",
      "[False  True]      [0.17813132 0.82186868]      [1937 8937]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10833    39]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10870     7]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10755   120]\n",
      "0.011034482758620689\n",
      "0.8470663969100607 0.017195402298850575 dff: 128 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "INFO:tensorflow:batch_all_reduce: 44 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 44 all-reduces with algorithm = nccl, num_packs = 1\n",
      "[0.004890166081885447]\n",
      "[False  True]      [0.87426471 0.12573529]      [9512 1368]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10529   346]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10861     1]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10646   228]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.03181609195402299\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "INFO:tensorflow:batch_all_reduce: 44 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 44 all-reduces with algorithm = nccl, num_packs = 1\n",
      "[0.006210272781727752]\n",
      "[False  True]      [0.4352303 0.5647697]      [4734 6143]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7734 3128]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10868     6]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10758   119]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10864    11]\n",
      "0.2879764315963911\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "INFO:tensorflow:batch_all_reduce: 44 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 44 all-reduces with algorithm = nccl, num_packs = 1\n",
      "[0.004599469941375964]\n",
      "[False  True]      [0.2194023 0.7805977]      [2386 8489]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10772   105]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7773 3089]\n",
      "feat_gpu_80_1f_02_f1_e3_db [6426 4452]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [7989 2885]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.4092664092664093\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.004751101737603834]\n",
      "[False  True]      [0.23899834 0.76100166]      [2596 8266]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10862    15]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10873     5]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10798    76]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10849    28]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10823    52]\n",
      "0.0069891484274416035\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.004406071915493701]\n",
      "[False  True]      [0.45513881 0.54486119]      [4951 5927]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9961  914]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10849    13]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10327   547]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.08404597701149426\n",
      "0.520775877918735 0.03632183908045977 dff: 32 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.0051580432639488985]\n",
      "[False  True]      [0.37021707 0.62978293]      [4025 6847]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10612   262]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10775    87]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10253   621]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10875     2]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [4724 6151]\n",
      "0.5656091954022988\n",
      "0.7031824871228844 0.4175632183908046 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.00483323868014507]\n",
      "[False  True]      [0.39249586 0.60750414]      [4268 6606]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10852    22]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10840    35]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10252   610]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10772   106]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [9206 1666]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10874     3]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [8733 2142]\n",
      "0.1969655172413793\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.00540784931265034]\n",
      "[False  True]      [0.22791211 0.77208789]      [2479 8398]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0\n",
      "0.9020869725108026 0.03154313040279566 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.005309238097506164]\n",
      "[False  True]      [0.22611494 0.77388506]      [2459 8416]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10282   592]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [9893  969]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [6491 4381]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10340   534]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10873     4]\n",
      "0.4029617365710081\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.006818766808243855]\n",
      "[False  True]      [0.31832759 0.68167241]      [2680 5739]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.727402304311676 0 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.005392963322438341]\n",
      "[False  True]      [0.65015836 0.34984164]      [6774 3645]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.005858628583361345]\n",
      "[False  True]      [0.70712983 0.29287017]      [7369 3052]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [8471 1950]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.18712215718261202\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.005540760980962968]\n",
      "[False  True]      [0.62446043 0.37553957]      [6510 3915]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.576978417266187 0 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.006080593509643628]\n",
      "[False  True]      [0.5774729 0.4225271]      [6019 4404]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [6067 4354]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [7536 2884]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.4178101909605604\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.005359097085216336]\n",
      "[False  True]      [0.56017274 0.43982726]      [5837 4583]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.006403271804081658]\n",
      "[False  True]      [0.75299875 0.24700125]      [7847 2574]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10422     1]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10378    42]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.004030710172744722\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.0056360724286831625]\n",
      "[False  True]      [0.56996529 0.43003471]      [6733 5080]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [9974 1839]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.15567595022432912\n",
      "0.4506899178870736 0.08558367899771438 dff: 32 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.005460581390392416]\n",
      "[False  True]      [0.40450199 0.59549801]      [4780 7037]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11372   446]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.037739042139109835\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.00571859243140482]\n",
      "[False  True]      [0.54111889 0.45888111]      [5639 4782]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.005694228858024047]\n",
      "[False  True]      [0.26716329 0.73283671]      [3156 8657]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8291712520104969 0 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.010415503486004408]\n",
      "[False  True]      [0.47492114 0.52507886]      [3011 3329]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [8993 1427]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.1369481765834933\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.0039648822195459]\n",
      "[False  True]      [0.32904427 0.67095573]      [3887 7926]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [8283 3530]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.29882333022940827\n",
      "0.6485228138491492 0.17743164310505374 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.006878048091220349]\n",
      "[False  True]      [0.39788868 0.60211132]      [4146 6274]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5000 1340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2113564668769716\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.006563662996896715]\n",
      "[False  True]      [0.47514395 0.52485605]      [4951 5469]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [9777  646]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [6062 4359]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.41828999136359274\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.004865465401691024]\n",
      "[False  True]      [0.41436791 0.58563209]      [4897 6921]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11811     6]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0005077430820005078\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.010227444471609387]\n",
      "[False  True]      [0.48185981 0.51814019]      [2736 2942]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.0040821502954230164]\n",
      "[False  True]      [0.37845163 0.62154837]      [4468 7338]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8109435880060986 0.05812966734555329 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.006907464763576977]\n",
      "[False  True]      [0.1978329 0.8021671]      [2337 9476]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.004805221022302034]\n",
      "[False  True]      [0.33638832 0.66361168]      [3964 7820]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7782  637]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10770  1043]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10799  1014]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10735  1078]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10841   965]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11346   467]\n",
      "0.09125539659696943\n",
      "0.9948234894772573 0.22712266147464658 dff: 128 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.005563175921021373]\n",
      "[False  True]      [0.19346341 0.80653659]      [1983 8267]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9515  735]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.07170731707317073\n",
      "0.8554146341463414 0.11736585365853658 dff: 128 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.005713632826210452]\n",
      "[False  True]      [0.76980874 0.23019126]      [7889 2359]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.005562997425647536]\n",
      "[False  True]      [0.78136585 0.21863415]      [8009 2241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_dc_a6_32_14_a6_53 [4937 5313]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.5183414634146342\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.005236857721465042]\n",
      "[False  True]      [0.23590251 0.76409749]      [2623 8496]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.0060633883729889855]\n",
      "[False  True]      [0.30049801 0.69950199]      [3017 7023]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.00981229786323205]\n",
      "[False  True]      [0.42439974 0.57560026]      [3270 4435]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8511   32]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0037457567599204025\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.005046611985753005]\n",
      "[False  True]      [0.4870872 0.5129128]      [5413 5700]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8347  196]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.022942760154512465\n",
      "0.7256366417708989 0.03453119513051621 dff: 128 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.007374608679278741]\n",
      "[False  True]      [0.42842093 0.57157907]      [3660 4883]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [10657   456]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.041033024385854405\n",
      "0.6100901322720356 0.023126068568343382 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.006119422970230695]\n",
      "[False  True]      [0.3594784 0.6405216]      [3694 6582]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.005582319723156798]\n",
      "[False  True]      [0.28114954 0.71885046]      [2886 7379]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.7745737944471505 0.00575609756097561 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.0049435866215501315]\n",
      "[False  True]      [0.34197498 0.65802502]      [3799 7310]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8876586551444775 0.037897200468088935 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.005013215844001048]\n",
      "[False  True]      [0.45197588 0.54802412]      [5021 6088]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.004846990966794412]\n",
      "[False  True]      [0.41362859 0.58637141]      [4595 6514]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.0046262788022973286]\n",
      "[False  True]      [0.47284518 0.52715482]      [5250 5853]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.004823709424797196]\n",
      "[False  True]      [0.36468468 0.63531532]      [4048 7052]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 10 192\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.007806064979533839]\n",
      "[False  True]      [0.19008644 0.80991356]      [2067 8807]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10871     1]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10848    29]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10865    10]\n",
      "0.0026661763353865954\n",
      "0.8470663969100607 0.017195402298850575 dff: 128 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.009965370032459528]\n",
      "[False  True]      [0.81534926 0.18465074]      [8871 2009]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10871     6]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10685   190]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10800    62]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10874     4]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9947  927]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10829    46]\n",
      "0.08524921831892587\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.008346912473897645]\n",
      "[False  True]      [0.45895008 0.54104992]      [4992 5885]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10874     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7154 3708]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10769   108]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10874     1]\n",
      "0.3413735960228319\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.007703843688713013]\n",
      "[False  True]      [0.21011494 0.78988506]      [2285 8590]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10823    54]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [8335 2527]\n",
      "feat_gpu_80_1f_02_f1_e3_db [5811 5067]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9299 1575]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.46580253723110865\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.07278318819048052]\n",
      "[False  True]      [0.0320383 0.9679617]      [  348 10514]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [  674 10200]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [1899 8981]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [  499 10378]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [3937 6938]\n",
      "feat_gpu_80_1f_02_f1_e3_db [5659 5219]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [3758 7114]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [6884 3990]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [1072 9805]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [3127 7748]\n",
      "0.9541233796083479\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00779652890525917]\n",
      "[False  True]      [0.43224858 0.56775142]      [4702 6176]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9785 1090]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [9937  925]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [8959 1915]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.17610814787566673\n",
      "0.520775877918735 0.03632183908045977 dff: 32 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.008171157625726823]\n",
      "[False  True]      [0.3540287 0.6459713]      [3849 7023]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10656   218]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10791    71]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10670   204]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10874     3]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [4929 5946]\n",
      "0.5467586206896552\n",
      "0.7031824871228844 0.4175632183908046 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.007620340387364366]\n",
      "[False  True]      [0.38173625 0.61826375]      [4151 6723]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10561   314]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [8965 1897]\n",
      "feat_gpu_80_1f_02_f1_e3_db [6428 4450]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10656   216]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10176   699]\n",
      "0.4090825519396948\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.009557050540672615]\n",
      "[False  True]      [0.21044406 0.78955594]      [2289 8588]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10869     5]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10860     2]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.0004598123965422108\n",
      "0.9020869725108026 0.03154313040279566 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.007319954220340444]\n",
      "[False  True]      [0.22556322 0.77443678]      [2453 8422]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10601   273]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10454   408]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [7739 3133]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10474   400]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10868     9]\n",
      "0.2881714495952907\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.011411661380176928]\n",
      "[False  True]      [0.33828246 0.66171754]      [2848 5571]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.727402304311676 0 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.0103464505101437]\n",
      "[False  True]      [0.47922065 0.52077935]      [4993 5426]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.009361347646590516]\n",
      "[False  True]      [0.66625084 0.33374916]      [6943 3478]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [8416 2005]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6270   70]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.19239996161596776\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.009283933461534707]\n",
      "[False  True]      [0.57026379 0.42973621]      [5945 4480]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.576978417266187 0 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.00979577473407632]\n",
      "[False  True]      [0.61872781 0.38127219]      [6449 3974]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [7644 2777]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [9271 1149]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.26648114384416083\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.009187345097119973]\n",
      "[False  True]      [0.57332054 0.42667946]      [5974 4446]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.009772283828464588]\n",
      "[False  True]      [0.79934747 0.20065253]      [8330 2091]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10420     3]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.00028782500239854167\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.006528319435774112]\n",
      "[False  True]      [0.3960044 0.6039956]      [4678 7135]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [9907 1906]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.16134766782358417\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.007867612733881136]\n",
      "[False  True]      [0.39307777 0.60692223]      [4645 7172]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11574   244]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.02064647148417668\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.010007194058839507]\n",
      "[False  True]      [0.57959889 0.42040111]      [6040 4381]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10420     1]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "9.59600806064677e-05\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.006960183496119446]\n",
      "[False  True]      [0.31956319 0.68043681]      [3775 8038]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8291712520104969 0 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.017860741082141838]\n",
      "[False  True]      [0.46088328 0.53911672]      [2922 3418]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [9286 1134]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.10882917466410749\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.012410858732012881]\n",
      "[False  True]      [0.24168289 0.75831711]      [2855 8958]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [4217 7596]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.643020401252857\n",
      "0.6485228138491492 0.17743164310505374 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.009618337534731874]\n",
      "[False  True]      [0.37533589 0.62466411]      [3911 6509]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [4515 1825]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.28785488958990535\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.009299817083430861]\n",
      "[False  True]      [0.45220729 0.54779271]      [4712 5708]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10009   414]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [5786 4635]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.44477497361097784\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.007919013987105542]\n",
      "[False  True]      [0.39025216 0.60974784]      [4612 7206]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.017454879532239096]\n",
      "[False  True]      [0.42109898 0.57890102]      [2391 3287]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.007589502126134051]\n",
      "[False  True]      [0.36345926 0.63654074]      [4291 7515]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8109435880060986 0.05812966734555329 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.007553186114059193]\n",
      "[False  True]      [0.14390925 0.85609075]      [ 1700 10113]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.007977871793122777]\n",
      "[False  True]      [0.20358113 0.79641887]      [2399 9385]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7739  680]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10732  1081]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10780  1033]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10723  1090]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5651   27]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10748  1058]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11349   464]\n",
      "0.09227122661474646\n",
      "0.9948234894772573 0.22712266147464658 dff: 128 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.00983959944316155]\n",
      "[False  True]      [0.14341463 0.85658537]      [1470 8780]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9176 1074]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.10478048780487804\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.013131036015657335]\n",
      "[False  True]      [0.72921546 0.27078454]      [7473 2775]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10207    43]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0041951219512195125\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.00933088806146323]\n",
      "[False  True]      [0.7657561 0.2342439]      [7849 2401]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [5000 5250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.5121951219512195\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.008920958360934338]\n",
      "[False  True]      [0.20190665 0.79809335]      [2245 8874]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.010476924239813262]\n",
      "[False  True]      [0.27549801 0.72450199]      [2766 7274]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.014431958552455814]\n",
      "[False  True]      [0.45580792 0.54419208]      [3512 4193]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8378  165]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.019314058293339577\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.009062877103899115]\n",
      "[False  True]      [0.43732565 0.56267435]      [4860 6253]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8460   83]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.009715556596043545\n",
      "0.7256366417708989 0.03453119513051621 dff: 128 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.01194766772537054]\n",
      "[False  True]      [0.38159897 0.61840103]      [3260 5283]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [9908 1205]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.10843156663367227\n",
      "0.6100901322720356 0.023126068568343382 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.010469446404764883]\n",
      "[False  True]      [0.34964967 0.65035033]      [3593 6683]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10244     6]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10177    73]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10262     3]\n",
      "0.007121951219512195\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.010077432845911375]\n",
      "[False  True]      [0.31592791 0.68407209]      [3243 7022]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.7745737944471505 0.00575609756097561 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.008997127291212817]\n",
      "[False  True]      [0.43460257 0.56539743]      [4828 6281]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8876586551444775 0.037897200468088935 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.00852340179237132]\n",
      "[False  True]      [0.3784319 0.6215681]      [4204 6905]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.008617494983082747]\n",
      "[False  True]      [0.33441354 0.66558646]      [3715 7394]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.008934502729070506]\n",
      "[False  True]      [0.2642529 0.7357471]      [2934 8169]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.008438387298015541]\n",
      "[False  True]      [0.34945946 0.65054054]      [3879 7221]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 10 256\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.011098667618845547]\n",
      "[False  True]      [0.1639691 0.8360309]      [1783 9091]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10870     2]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10840    35]\n",
      "0.003218390804597701\n",
      "0.8360308993930476 0.003218390804597701 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.011520788995263927]\n",
      "[False  True]      [0.80340074 0.19659926]      [8741 2139]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10873     4]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10816    59]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10796    66]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10761   113]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10874     1]\n",
      "0.010391760161853964\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.013358726951449115]\n",
      "[False  True]      [0.42291073 0.57708927]      [4600 6277]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10869     6]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [4197 6665]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10863    11]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10705   172]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10862    13]\n",
      "0.6136070705210827\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.013389170249224773]\n",
      "[False  True]      [0.18234483 0.81765517]      [1983 8892]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10636   241]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7621 3241]\n",
      "feat_gpu_80_1f_02_f1_e3_db [4746 6132]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [7286 3588]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.5637065637065637\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.011384121305244908]\n",
      "[False  True]      [0.19333456 0.80666544]      [2100 8762]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10784    93]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10871     4]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10867    11]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10861    11]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10822    52]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10544   333]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10650   225]\n",
      "0.030615059299439185\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.010793821664436081]\n",
      "[False  True]      [0.4015444 0.5984556]      [4368 6510]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9801 1074]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10755   107]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9766 1108]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.1018944270737539\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.012088277539929193]\n",
      "[False  True]      [0.33388521 0.66611479]      [3630 7242]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [9746 1128]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10458   404]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10414   460]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10874     3]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [4909 5966]\n",
      "0.5485977011494253\n",
      "0.7031824871228844 0.4175632183908046 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.011545841841008753]\n",
      "[False  True]      [0.3463307 0.6536693]      [3766 7108]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10861    13]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10777    98]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [8474 2388]\n",
      "feat_gpu_80_1f_02_f1_e3_db [8168 2710]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [9023 1849]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10767   110]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [8342 2533]\n",
      "0.24912667769810626\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.012196278172053047]\n",
      "[False  True]      [0.18148387 0.81851613]      [1974 8903]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10872     2]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.0001839249586168843\n",
      "0.9020869725108026 0.03154313040279566 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.010903070905806543]\n",
      "[False  True]      [0.2102069 0.7897931]      [2286 8589]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10280   594]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10028   834]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [7333 3539]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10577   297]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "0.3255150846210449\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.01551852080600984]\n",
      "[False  True]      [0.28447559 0.71552441]      [2395 6024]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.727402304311676 0 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.014102495281210532]\n",
      "[False  True]      [0.49716863 0.50283137]      [5180 5239]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.013678193922202054]\n",
      "[False  True]      [0.62479608 0.37520392]      [6511 3910]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [8286 2135]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6325   15]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.20487477209480856\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.014321583932596273]\n",
      "[False  True]      [0.57860911 0.42139089]      [6032 4393]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.576978417266187 0 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.015243827201729244]\n",
      "[False  True]      [0.56308165 0.43691835]      [5869 4554]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [5862 4559]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10357    64]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [6478 3942]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.4374820074848863\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.013401450916553261]\n",
      "[False  True]      [0.51564299 0.48435701]      [5373 5047]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.014229338036126919]\n",
      "[False  True]      [0.87112561 0.12887439]      [9078 1343]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10418     2]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.00019193857965451057\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.010495952597366548]\n",
      "[False  True]      [0.36798442 0.63201558]      [4347 7466]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [9267 2546]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2155252687716922\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.010755798047487958]\n",
      "[False  True]      [0.36794449 0.63205551]      [4348 7469]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11671   147]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.012438652902352344\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.013743499768173507]\n",
      "[False  True]      [0.4531235 0.5468765]      [4722 5699]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.010163515588295877]\n",
      "[False  True]      [0.23397951 0.76602049]      [2764 9049]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8291712520104969 0 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.023682770544192225]\n",
      "[False  True]      [0.43343849 0.56656151]      [2748 3592]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [8403 2017]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.1935700575815739\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.010851676636038515]\n",
      "[False  True]      [0.30508762 0.69491238]      [3604 8209]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [9186 2627]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.22238212139168712\n",
      "0.6949123846609667 0.22238212139168712 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.013219413699576849]\n",
      "[False  True]      [0.36833013 0.63166987]      [3838 6582]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [4596 1744]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2750788643533123\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.01379223212281866]\n",
      "[False  True]      [0.40758157 0.59241843]      [4247 6173]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10119   304]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [6585 3836]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10411    10]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.3681028692064101\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.011356848600878575]\n",
      "[False  True]      [0.37764427 0.62235573]      [4463 7355]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11346   471]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.03985783193703986\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.025065499948693466]\n",
      "[False  True]      [0.34255019 0.65744981]      [1945 3733]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.011258313542617669]\n",
      "[False  True]      [0.26334067 0.73665933]      [3109 8697]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11751    33]\n",
      "0.00280040733197556\n",
      "0.8109435880060986 0.05812966734555329 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.01198726659396078]\n",
      "[False  True]      [0.20223483 0.79776517]      [2389 9424]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.013164650290848212]\n",
      "[False  True]      [0.17931093 0.82068907]      [2113 9671]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7544  875]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10726  1087]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10763  1050]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10713  1100]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5502  176]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10746  1060]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11103   710]\n",
      "0.10393158332343509\n",
      "0.9948234894772573 0.22712266147464658 dff: 128 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.013494672823374812]\n",
      "[False  True]      [0.15053659 0.84946341]      [1543 8707]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [8631 1619]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.15795121951219512\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.014088887533404568]\n",
      "[False  True]      [0.78005464 0.21994536]      [7994 2254]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [9933  317]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10249     1]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.030926829268292683\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.013479314068485434]\n",
      "[False  True]      [0.7524878 0.2475122]      [7713 2537]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [3927 6323]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.6168780487804878\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.013067911880673062]\n",
      "[False  True]      [0.16773091 0.83226909]      [1865 9254]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.015598549597196898]\n",
      "[False  True]      [0.2186255 0.7813745]      [2195 7845]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.020008327312144386]\n",
      "[False  True]      [0.41219987 0.58780013]      [3176 4529]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8521   22]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.002575207772445277\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.012870655727805855]\n",
      "[False  True]      [0.25339692 0.74660308]      [2816 8297]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8069  474]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.055484022006320965\n",
      "0.746603077476829 0.055484022006320965 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.01717642774283454]\n",
      "[False  True]      [0.30504507 0.69495493]      [2606 5937]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [9186 1927]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.17340052191127509\n",
      "0.6100901322720356 0.023126068568343382 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.014199354505002329]\n",
      "[False  True]      [0.35626703 0.64373297]      [3661 6615]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [9928  322]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9810  440]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10022   243]\n",
      "0.042926829268292686\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.013933165041976038]\n",
      "[False  True]      [0.33433999 0.66566001]      [3432 6833]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.7745737944471505 0.00575609756097561 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.0127709890419539]\n",
      "[False  True]      [0.17175263 0.82824737]      [1908 9201]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8876586551444775 0.037897200468088935 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.012178232276923419]\n",
      "[False  True]      [0.50202538 0.49797462]      [5577 5532]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.012332033646305014]\n",
      "[False  True]      [0.35538752 0.64461248]      [3948 7161]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.012578236686428308]\n",
      "[False  True]      [0.33864721 0.66135279]      [3760 7343]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.012544090185288658]\n",
      "[False  True]      [0.33027027 0.66972973]      [3666 7434]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 10 512\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.024595941986745244]\n",
      "[False  True]      [0.07826007 0.92173993]      [  851 10023]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10858    14]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10347   530]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10403   472]\n",
      "0.048726670957065364\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.024520809949568158]\n",
      "[False  True]      [0.47380515 0.52619485]      [5155 5725]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10866    11]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10693   182]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10238   624]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10840    38]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10133   741]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10811    64]\n",
      "0.06814419716755564\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.02722982033959816]\n",
      "[False  True]      [0.30504735 0.69495265]      [3318 7559]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10861    13]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10844    31]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [3343 7519]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10531   347]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10869     3]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10717   157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_80_1f_02_f1_e4_04 [7815 3062]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10832    43]\n",
      "0.6922297919351869\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.053346238063206784]\n",
      "[False  True]      [0.07558621 0.92441379]      [  822 10053]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [7885 2989]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [5223 5657]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [5723 5154]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [5917 4945]\n",
      "feat_gpu_80_1f_02_f1_e3_db [  855 10023]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [7754 3118]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [5118 5756]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [8799 2078]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [7183 3692]\n",
      "0.9214009928295642\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.023398443468551963]\n",
      "[False  True]      [0.09491806 0.90508194]      [1031 9831]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10684   190]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10418   459]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10847    28]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10711   167]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10423   449]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10060   814]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [8240 2637]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [8477 2398]\n",
      "0.24243817229015355\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.02531029421235964]\n",
      "[False  True]      [0.28029049 0.71970951]      [3049 7829]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10873     1]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10757   120]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9145 1730]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [5165 5697]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10849    23]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [6291 4583]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [9802 1075]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10516   359]\n",
      "0.524489044374885\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.023898379255585335]\n",
      "[False  True]      [0.21743929 0.78256071]      [2364 8508]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [6498 4376]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10875     2]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7698 3164]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10875     3]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9794 1080]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [9446 1431]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [3345 7530]\n",
      "0.6924137931034483\n",
      "0.7031824871228844 0.4175632183908046 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.02458415191038555]\n",
      "[False  True]      [0.26899025 0.73100975]      [2925 7949]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10458   416]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10871     6]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10019   856]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [5628 5234]\n",
      "feat_gpu_80_1f_02_f1_e3_db [5483 5395]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [7752 3120]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10682   195]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [6891 3984]\n",
      "0.49595513881228165\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.02554831243373976]\n",
      "[False  True]      [0.08127241 0.91872759]      [ 884 9993]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10381   493]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10848    14]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.045337502299061985\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.022147924005297612]\n",
      "[False  True]      [0.15429885 0.84570115]      [1678 9197]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [7290 3584]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [8732 2130]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [6560 4312]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10486   388]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10810    67]\n",
      "0.39661515820456217\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.03357691039195869]\n",
      "[False  True]      [0.22366077 0.77633923]      [1883 6536]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11470   343]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.02903580800812664\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.030033038469791516]\n",
      "[False  True]      [0.45004319 0.54995681]      [4689 5730]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.028759484613278236]\n",
      "[False  True]      [0.59264946 0.40735054]      [6176 4245]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [7964 2457]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6212  128]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.23577391805009115\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.576978417266187 0 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.030894315876138178]\n",
      "[False  True]      [0.4324091 0.5675909]      [4507 5916]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10408    13]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [3736 6685]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [9884  537]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [6232 4188]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.6414931388542366\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.027674841363726096]\n",
      "[False  True]      [0.44222649 0.55777351]      [4608 5812]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "[0.03018859391190245]\n",
      "[False  True]      [0.77151905 0.22848095]      [8040 2381]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10420     1]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6332    8]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10405    15]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0014395393474088292\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.024171057965834408]\n",
      "[False  True]      [0.29484466 0.70515534]      [3483 8330]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [6207 5606]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.47456192330483365\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.024331109878190888]\n",
      "[False  True]      [0.303038 0.696962]      [3581 8236]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11552   266]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.022508038585209004\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.029581624600787268]\n",
      "[False  True]      [0.36867863 0.63132137]      [3842 6579]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10395    26]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0024949620957681606\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.023019393878288465]\n",
      "[False  True]      [0.21222382 0.78777618]      [2507 9306]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8291712520104969 0 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.04510717306311432]\n",
      "[False  True]      [0.41388013 0.58611987]      [2624 3716]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10341    80]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [5692 4728]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.45374280230326297\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.02419296534150699]\n",
      "[False  True]      [0.21848811 0.78151189]      [2581 9232]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [6436 5377]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11807     6]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.4551765004655888\n",
      "0.6949123846609667 0.22238212139168712 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.028324877925111454]\n",
      "[False  True]      [0.17984645 0.82015355]      [1874 8546]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [4251 2089]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.32949526813880126\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.028416091784389825]\n",
      "[False  True]      [0.29913628 0.70086372]      [3117 7303]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10417     4]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [9660  763]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [3402 7019]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10215   206]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.6735438057767968\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.02554360928423905]\n",
      "[False  True]      [0.32687426 0.67312574]      [3863 7955]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [10062  1755]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.1485148514851485\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.04691809591360631]\n",
      "[False  True]      [0.26224023 0.73775977]      [1489 4189]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.02358136587185154]\n",
      "[False  True]      [0.23632051 0.76367949]      [2790 9016]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11787    26]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11662   122]\n",
      "0.010353021045485404\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.02515640446026971]\n",
      "[False  True]      [0.2199272 0.7800728]      [2598 9215]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.023137698029887428]\n",
      "[False  True]      [0.10183299 0.89816701]      [ 1200 10584]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7363 1056]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10729  1084]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11705   112]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10570  1243]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10682  1131]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11582   236]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4639 1039]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10752  1054]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [10754  1059]\n",
      "0.18298696724198663\n",
      "0.9948234894772573 0.22712266147464658 dff: 128 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.029873991639219236]\n",
      "[False  True]      [0.14468293 0.85531707]      [1483 8767]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [8295 1955]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.19073170731707317\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.026820174102907705]\n",
      "[False  True]      [0.66461749 0.33538251]      [6811 3437]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [5902 4348]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9257  993]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.4241951219512195\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.028727475409742406]\n",
      "[False  True]      [0.63229268 0.36770732]      [6481 3769]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [2721 7529]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.7345365853658536\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.02769318310602891]\n",
      "[False  True]      [0.09470276 0.90529724]      [ 1053 10066]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.03239434253561577]\n",
      "[False  True]      [0.14601594 0.85398406]      [1466 8574]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.04091599859532559]\n",
      "[False  True]      [0.30953926 0.69046074]      [2385 5320]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11107     6]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8295  248]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.02902961488938312\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.04348451726546884]\n",
      "[False  True]      [0.09124449 0.90875551]      [ 1014 10099]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [9918 1201]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [9411  629]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [6608 1097]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [2487 6056]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.7088844668149362\n",
      "0.746603077476829 0.055484022006320965 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03418505296476158]\n",
      "[False  True]      [0.23984549 0.76015451]      [2049 6494]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [7994 3119]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.28066228741114013\n",
      "0.6100901322720356 0.023126068568343382 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.02928063716611805]\n",
      "[False  True]      [0.28405995 0.71594005]      [2919 7357]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10076   174]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9693  557]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [9295  970]\n",
      "0.0944958597174866\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.03155147928937713]\n",
      "[False  True]      [0.19532392 0.80467608]      [2005 8260]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [9897  353]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10243     7]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0.034439024390243905\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.026397145098577823]\n",
      "[False  True]      [0.16320101 0.83679899]      [1813 9296]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8876586551444775 0.037897200468088935 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.02816031297647549]\n",
      "[False  True]      [0.34431542 0.65568458]      [3825 7284]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.025206085661731863]\n",
      "[False  True]      [0.24826717 0.75173283]      [2758 8351]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.028226826673784785]\n",
      "[False  True]      [0.19715392 0.80284608]      [2189 8914]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11103     6]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0.0005401026194977045\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.027903311436294657]\n",
      "[False  True]      [0.3072973 0.6927027]      [3411 7689]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 20 128\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.0013666755498919587]\n",
      "[False  True]      [0.30779842 0.69220158]      [3347 7527]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10858    14]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10869     8]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10842    33]\n",
      "0.0030344827586206895\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.001325295829526186]\n",
      "[False  True]      [0.85229779 0.14770221]      [9273 1607]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10273   602]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10860     2]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10870     8]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10344   530]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10854    21]\n",
      "0.05535632183908046\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.001415767897580168]\n",
      "[False  True]      [0.49820723 0.50179277]      [5419 5458]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10874     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7586 3276]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10873     1]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10761   116]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.3016019149327932\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.0017044168311633437]\n",
      "[False  True]      [0.3005977 0.6994023]      [3269 7606]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10874     3]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10470   392]\n",
      "feat_gpu_80_1f_02_f1_e3_db [8989 1889]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [8783 2091]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.19229354423395253\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.001505324015371525]\n",
      "[False  True]      [0.22666176 0.77333824]      [2462 8400]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10745   132]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10784    93]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.012135699181759677\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.0014971974312520805]\n",
      "[False  True]      [0.55341055 0.44658945]      [6020 4858]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9730 1145]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10854     8]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10376   498]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.10528735632183908\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.0020280921263445867]\n",
      "[False  True]      [0.14348786 0.85651214]      [1560 9312]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [3395 7479]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10103   774]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10826    49]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [5302 5560]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10829    49]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [7102 3772]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [7592 3285]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [1725 9150]\n",
      "0.8413793103448276\n",
      "0.7031824871228844 0.4175632183908046 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.0014651051668984002]\n",
      "[False  True]      [0.48795292 0.51204708]      [5306 5568]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10869     6]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10423   455]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10848    24]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10853    22]\n",
      "0.04182754182754183\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.00133416135730384]\n",
      "[False  True]      [0.42493335 0.57506665]      [4622 6255]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.001382207986203619]\n",
      "[False  True]      [0.30685057 0.69314943]      [3337 7538]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10700   174]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [8915 1947]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10877     1]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [8353 2519]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9791 1083]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10845    32]\n",
      "0.23169610007358352\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.0025765075625107593]\n",
      "[False  True]      [0.45622996 0.54377004]      [3841 4578]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.0017192120747585252]\n",
      "[False  True]      [0.65687686 0.34312314]      [6844 3575]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.0018283956899598735]\n",
      "[False  True]      [0.76614528 0.23385472]      [7984 2437]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [9663  758]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.07273774109970252\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.003406273918037735]\n",
      "[False  True]      [0.67625899 0.32374101]      [7050 3375]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.576978417266187 0 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.0025451350978476445]\n",
      "[False  True]      [0.74709776 0.25290224]      [7787 2636]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [9438  983]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [9936  484]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.09432875923615776\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.0015969674928029659]\n",
      "[False  True]      [0.64193858 0.35806142]      [6689 3731]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.00274196794733985]\n",
      "[False  True]      [0.73265522 0.26734478]      [7635 2786]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10420     1]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10405    15]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0014395393474088292\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.001978496518679176]\n",
      "[False  True]      [0.57817659 0.42182341]      [6830 4983]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [7794 4019]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.34021840345382204\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.0015434656860257767]\n",
      "[False  True]      [0.49437251 0.50562749]      [5842 5975]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11298   520]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.04400067693349129\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.0017082743268125597]\n",
      "[False  True]      [0.64091738 0.35908262]      [6679 3742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.0017120707895072727]\n",
      "[False  True]      [0.16710404 0.83289596]      [1974 9839]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.004035968650420523]\n",
      "[False  True]      [0.54321767 0.45678233]      [3444 2896]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [9476  944]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.09059500959692898\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.0012949701155731983]\n",
      "[False  True]      [0.39219504 0.60780496]      [4633 7180]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [9718 2095]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.17734699060357234\n",
      "0.6949123846609667 0.22238212139168712 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.0017278086995560292]\n",
      "[False  True]      [0.36919386 0.63080614]      [3847 6573]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [3218 3122]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.49242902208201894\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.003118576109380876]\n",
      "[False  True]      [0.57648752 0.42351248]      [6007 4413]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10408    13]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10115   308]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [5370 5051]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [9611  810]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6334    6]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10419     1]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.4846943671432684\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.001501288953723662]\n",
      "[False  True]      [0.54078524 0.45921476]      [6391 5427]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.004258007031012277]\n",
      "[False  True]      [0.48661501 0.51338499]      [2763 2915]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.0016431942310293735]\n",
      "[False  True]      [0.31594105 0.68405895]      [3730 8076]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.0010597144652628857]\n",
      "[False  True]      [0.52061288 0.47938712]      [6150 5663]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.0011957407077413135]\n",
      "[False  True]      [0.31763408 0.68236592]      [3743 8041]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8189  230]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10882   931]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11296   517]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10833   980]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11662   144]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11810     3]\n",
      "0.0829594514517904\n",
      "0.9948234894772573 0.22712266147464658 dff: 128 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.0030043212221787024]\n",
      "[False  True]      [0.25229268 0.74770732]      [2586 7664]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [9652  596]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [6865 3385]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.3302439024390244\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.0017034513459997201]\n",
      "[False  True]      [0.49677986 0.50322014]      [5091 5157]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10174    76]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.007414634146341463\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.0021474747386163997]\n",
      "[False  True]      [0.46156098 0.53843902]      [4731 5519]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [4355 5895]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.5751219512195122\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.006122878772994813]\n",
      "[False  True]      [0.26297329 0.73702671]      [2924 8195]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.0021634390895456357]\n",
      "[False  True]      [0.2623506 0.7376494]      [2634 7406]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.0034989270334112644]\n",
      "[False  True]      [0.59805321 0.40194679]      [4608 3097]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [7422 1121]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.1312185414959616\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.0022335715088122846]\n",
      "[False  True]      [0.03302439 0.96697561]      [  367 10746]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8033  510]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.059697998361231415\n",
      "0.9669756141455953 0.059697998361231415 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.002667047908320103]\n",
      "[False  True]      [0.5556596 0.4443404]      [4747 3796]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11103    10]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.000899847026005579\n",
      "0.6100901322720356 0.023126068568343382 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.00208760575063634]\n",
      "[False  True]      [0.42020241 0.57979759]      [4318 5958]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.0015936089070203827]\n",
      "[False  True]      [0.34427667 0.65572333]      [3534 6731]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.0014793851241205207]\n",
      "[False  True]      [0.58043028 0.41956972]      [6448 4661]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8876586551444775 0.037897200468088935 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.0032152860752660693]\n",
      "[False  True]      [0.45593663 0.54406337]      [5065 6044]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.0015177977097876989]\n",
      "[False  True]      [0.67485822 0.32514178]      [7497 3612]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.001561349366637669]\n",
      "[False  True]      [0.4678015 0.5321985]      [5194 5909]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.002563490819935912]\n",
      "[False  True]      [0.49585586 0.50414414]      [5504 5596]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 20 192\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.0029636012029322758]\n",
      "[False  True]      [0.28168107 0.71831893]      [3063 7811]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_80_1f_02_f1_e3_dd [10836    36]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10850    27]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10705   170]\n",
      "0.015632183908045976\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.003454634201841724]\n",
      "[False  True]      [0.75487132 0.24512868]      [8213 2667]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10871     6]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [5682 5193]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10846    16]\n",
      "feat_gpu_80_1f_02_f1_e3_db [8103 2775]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9286 1588]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.47751724137931034\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.00302580443619331]\n",
      "[False  True]      [0.48230211 0.51769789]      [5246 5631]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [6140 4722]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10872     6]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10871     3]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10843    34]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10871     4]\n",
      "0.434726569692506\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.0034126947690384236]\n",
      "[False  True]      [0.22721839 0.77278161]      [2471 8404]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10874     3]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10093   769]\n",
      "feat_gpu_80_1f_02_f1_e3_db [4506 6372]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9907  967]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.5857694429123\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.0029163531085797025]\n",
      "[False  True]      [0.24360155 0.75639845]      [2646 8216]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10852    25]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10873     2]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10876     2]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10846    28]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10840    37]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10864    11]\n",
      "0.0034016732554932425\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.0028795451917589905]\n",
      "[False  True]      [0.51332966 0.48667034]      [5584 5294]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9877  998]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10807    55]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10223   651]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.09177011494252874\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.0031634528372404165]\n",
      "[False  True]      [0.23335173 0.76664827]      [2537 8335]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [8979 1895]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10875     2]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10609   253]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10616   258]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10798    79]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [5558 5317]\n",
      "0.48891954022988504\n",
      "0.7031824871228844 0.4175632183908046 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.0034984264701676906]\n",
      "[False  True]      [0.43810925 0.56189075]      [4764 6110]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10658   217]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10323   539]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10396   482]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10731   141]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10509   366]\n",
      "0.04962253728595102\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.002759415988961504]\n",
      "[False  True]      [0.19242438 0.80757562]      [2093 8784]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10872     2]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.0001839249586168843\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.003161874873009732]\n",
      "[False  True]      [0.2948046 0.7051954]      [3206 7669]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10631   243]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10585   277]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [7795 3077]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10600   274]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10873     4]\n",
      "0.2830206033848418\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.004512258472681579]\n",
      "[False  True]      [0.36417627 0.63582373]      [3066 5353]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.004325063622607403]\n",
      "[False  True]      [0.61685382 0.38314618]      [6427 3992]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.004365936340190187]\n",
      "[False  True]      [0.75155935 0.24844065]      [7832 2589]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10224   197]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.01890413587947414\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.003708372285084082]\n",
      "[False  True]      [0.51980815 0.48019185]      [5419 5006]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.576978417266187 0 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.003959279349923881]\n",
      "[False  True]      [0.75784323 0.24215677]      [7899 2524]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [8842 1579]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [9938  482]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.15152096727761252\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.011798376891394114]\n",
      "[False  True]      [0.40681382 0.59318618]      [4239 6181]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.005814864181518804]\n",
      "[False  True]      [0.86517609 0.13482391]      [9016 1405]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10405    15]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0014395393474088292\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.0024781816808458145]\n",
      "[False  True]      [0.49868789 0.50131211]      [5891 5922]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [7869 3944]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.33386946584271565\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.002645776450944726]\n",
      "[False  True]      [0.45265296 0.54734704]      [5349 6468]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11102   716]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.060585547469961074\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.005276719709247203]\n",
      "[False  True]      [0.63304865 0.36695135]      [6597 3824]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.002361965792242512]\n",
      "[False  True]      [0.33945653 0.66054347]      [4010 7803]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.014940832377089437]\n",
      "[False  True]      [0.5555205 0.4444795]      [3522 2818]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10247   174]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [9700  720]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0690978886756238\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.002710320552211962]\n",
      "[False  True]      [0.30898163 0.69101837]      [3650 8163]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [8350 3463]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2931516126301532\n",
      "0.6949123846609667 0.22238212139168712 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.006507724203438264]\n",
      "[False  True]      [0.46238004 0.53761996]      [4818 5602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5500  840]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.13249211356466878\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.003796328697064634]\n",
      "[False  True]      [0.51497121 0.48502879]      [5366 5054]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10315   108]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [7171 3250]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.3118702619710201\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.003822396295120366]\n",
      "[False  True]      [0.45506854 0.54493146]      [5378 6440]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.008063654615552963]\n",
      "[False  True]      [0.46002113 0.53997887]      [2612 3066]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.0023232975026694024]\n",
      "[False  True]      [0.4056412 0.5943588]      [4789 7017]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.0032369700764580756]\n",
      "[False  True]      [0.18885973 0.81114027]      [2231 9582]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.0033164952331058107]\n",
      "[False  True]      [0.58138153 0.41861847]      [6851 4933]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8181  238]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11743    70]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11698   115]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11737    76]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10778  1028]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11733    80]\n",
      "0.08707436896493309\n",
      "0.9948234894772573 0.22712266147464658 dff: 128 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.004098535030007909]\n",
      "[False  True]      [0.18556098 0.81443902]      [1902 8348]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9548  702]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.06848780487804879\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.0034990553922115584]\n",
      "[False  True]      [0.69818501 0.30181499]      [7155 3093]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10196    54]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.00526829268292683\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.003311818365118605]\n",
      "[False  True]      [0.78156098 0.21843902]      [8011 2239]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [5993 4257]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.4153170731707317\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.0037039321954164903]\n",
      "[False  True]      [0.2846479 0.7153521]      [3165 7954]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.004985477739352816]\n",
      "[False  True]      [0.27978088 0.72021912]      [2809 7231]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.006031232814346441]\n",
      "[False  True]      [0.5174562 0.4825438]      [3987 3718]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8498   45]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.005267470443638066\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.00380303739898564]\n",
      "[False  True]      [0.70206065 0.29793935]      [7802 3311]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [4779 3764]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.4405946388856374\n",
      "0.9669756141455953 0.059697998361231415 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.004960995776922902]\n",
      "[False  True]      [0.47559405 0.52440595]      [4063 4480]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [10958   155]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.013947628903086476\n",
      "0.6100901322720356 0.023126068568343382 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.0032132618388599618]\n",
      "[False  True]      [0.51080187 0.48919813]      [5249 5027]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.0037941914110116628]\n",
      "[False  True]      [0.38421822 0.61578178]      [3944 6321]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.0034095596240640725]\n",
      "[False  True]      [0.57862994 0.42137006]      [6428 4681]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8876586551444775 0.037897200468088935 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.0030181905727280317]\n",
      "[False  True]      [0.59969394 0.40030606]      [6662 4447]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.004146359708579198]\n",
      "[False  True]      [0.45170582 0.54829418]      [5018 6091]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.0029538860645267053]\n",
      "[False  True]      [0.4701432 0.5298568]      [5220 5883]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.004562113592922053]\n",
      "[False  True]      [0.44207207 0.55792793]      [4907 6193]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 20 256\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.004365986715322127]\n",
      "[False  True]      [0.26264484 0.73735516]      [2856 8018]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10862    10]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10833    42]\n",
      "0.0038620689655172414\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.0047570734672719005]\n",
      "[False  True]      [0.88382353 0.11617647]      [9616 1264]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10677   198]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10860     2]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10497   377]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.034669854699282694\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.004829610085976146]\n",
      "[False  True]      [0.44074653 0.55925347]      [4794 6083]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7917 2945]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10867     5]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10872     2]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10762   115]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10864    11]\n",
      "0.27112870557908303\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.0046657272296345]\n",
      "[False  True]      [0.19181609 0.80818391]      [2086 8789]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10867    10]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10288   574]\n",
      "feat_gpu_80_1f_02_f1_e3_db [4959 5919]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [6943 3931]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.5441257584114727\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.005914210030763616]\n",
      "[False  True]      [0.17409317 0.82590683]      [1891 8971]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10800    77]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10874     1]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10868    10]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10866     6]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10584   290]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10106   771]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10721   154]\n",
      "0.0708835156752781\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.004439543967785918]\n",
      "[False  True]      [0.4756389 0.5243611]      [5174 5704]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10302   573]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10800    62]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10095   779]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.07163877138127644\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.00434701858765082]\n",
      "[False  True]      [0.37012509 0.62987491]      [4024 6848]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10677   197]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10815    47]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10525   349]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10875     2]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [4591 6284]\n",
      "0.5778390804597701\n",
      "0.7031824871228844 0.4175632183908046 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004701897345069188]\n",
      "[False  True]      [0.3975538 0.6024462]      [4323 6551]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10721   154]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10469   393]\n",
      "feat_gpu_80_1f_02_f1_e3_db [9681 1197]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10771   101]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10606   269]\n",
      "0.11003861003861004\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.004597569827178676]\n",
      "[False  True]      [0.22285557 0.77714443]      [2424 8453]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.005147456651661318]\n",
      "[False  True]      [0.27209195 0.72790805]      [2959 7916]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10010   864]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10261   601]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [7677 3195]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10426   448]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10875     2]\n",
      "0.29387417218543044\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.007643311673001049]\n",
      "[False  True]      [0.38579404 0.61420596]      [3248 5171]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.0069978645303505815]\n",
      "[False  True]      [0.60696804 0.39303196]      [6324 4095]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.005618347924691781]\n",
      "[False  True]      [0.71653392 0.28346608]      [7467 2954]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10172   249]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.02389406007101046\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.006293793117353511]\n",
      "[False  True]      [0.33688249 0.66311751]      [3512 6913]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.007704140506809136]\n",
      "[False  True]      [0.65365058 0.34634942]      [6813 3610]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [8363 2058]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [9151 1269]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.19748584588811055\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.005786239503733166]\n",
      "[False  True]      [0.53119002 0.46880998]      [5535 4885]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.005863323801551665]\n",
      "[False  True]      [0.91507533 0.08492467]      [9536  885]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10419     1]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "9.596928982725528e-05\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.003956576203777412]\n",
      "[False  True]      [0.50444426 0.49555574]      [5959 5854]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [8225 3588]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.30373317531533056\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.004127859765034587]\n",
      "[False  True]      [0.42032665 0.57967335]      [4967 6850]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11403   415]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.035115924860382466\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.005345766134282903]\n",
      "[False  True]      [0.50878035 0.49121965]      [5302 5119]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10420     1]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "9.59600806064677e-05\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.004308229214651297]\n",
      "[False  True]      [0.404385 0.595615]      [4777 7036]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.01041944361669761]\n",
      "[False  True]      [0.55347003 0.44652997]      [3509 2831]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [7885 2535]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.24328214971209214\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.0045374306901358845]\n",
      "[False  True]      [0.35706425 0.64293575]      [4218 7595]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [8878 2935]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2484550918479641\n",
      "0.6949123846609667 0.22238212139168712 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.006198054770774419]\n",
      "[False  True]      [0.37898273 0.62101727]      [3949 6471]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5010 1330]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.20977917981072555\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.005173310113294805]\n",
      "[False  True]      [0.46362764 0.53637236]      [4831 5589]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [9856  567]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [7577 2844]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2729104692447942\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.00444900915746676]\n",
      "[False  True]      [0.43932984 0.56067016]      [5192 6626]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11816     1]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "8.462384700008462e-05\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.011169884060491462]\n",
      "[False  True]      [0.43219443 0.56780557]      [2454 3224]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.004575900251049468]\n",
      "[False  True]      [0.31899034 0.68100966]      [3766 8040]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11782     2]\n",
      "0.00016972165648336727\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.004017294635816494]\n",
      "[False  True]      [0.35850334 0.64149666]      [4235 7578]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.004423764889229493]\n",
      "[False  True]      [0.33392736 0.66607264]      [3935 7849]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7762  657]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10783  1030]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10841   972]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10751  1062]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10753  1053]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11361   452]\n",
      "0.08990095657326674\n",
      "0.9948234894772573 0.22712266147464658 dff: 128 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.006716622599066537]\n",
      "[False  True]      [0.29190244 0.70809756]      [2992 7258]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9595  655]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.06390243902439025\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.0053829661563647175]\n",
      "[False  True]      [0.70940671 0.29059329]      [7270 2978]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.005164411751713382]\n",
      "[False  True]      [0.78858537 0.21141463]      [8083 2167]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [5572 4678]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.45639024390243904\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.005017417740011266]\n",
      "[False  True]      [0.26890907 0.73109093]      [2990 8129]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.005898120968642069]\n",
      "[False  True]      [0.27918327 0.72081673]      [2803 7237]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.008365328341453546]\n",
      "[False  True]      [0.6155743 0.3844257]      [4743 2962]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8516   27]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0031604822661828397\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.005524535570672761]\n",
      "[False  True]      [0.33510303 0.66489697]      [3724 7389]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8249  294]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0344141402317687\n",
      "0.9669756141455953 0.059697998361231415 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.007115548463145404]\n",
      "[False  True]      [0.2987241 0.7012759]      [2552 5991]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [9646 1467]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.13200755871501846\n",
      "0.6100901322720356 0.023126068568343382 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.0058579975544252195]\n",
      "[False  True]      [0.43830284 0.56169716]      [4504 5772]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.005671444373200206]\n",
      "[False  True]      [0.36249391 0.63750609]      [3721 6544]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10248     2]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0.0001951219512195122\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.0047070580798547765]\n",
      "[False  True]      [0.49203349 0.50796651]      [5466 5643]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8876586551444775 0.037897200468088935 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.005083305650281274]\n",
      "[False  True]      [0.35853812 0.64146188]      [3983 7126]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004944951763515088]\n",
      "[False  True]      [0.49851472 0.50148528]      [5538 5571]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.005040621321267824]\n",
      "[False  True]      [0.41790507 0.58209493]      [4640 6463]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.004702005515839018]\n",
      "[False  True]      [0.32873874 0.67126126]      [3649 7451]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 20 512\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.012421197338632804]\n",
      "[False  True]      [0.14796763 0.85203237]      [1609 9265]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10857    15]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10440   437]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10729   146]\n",
      "0.0401765192608256\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.011118666152887272]\n",
      "[False  True]      [0.81148897 0.18851103]      [8829 2051]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10576   299]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10858     4]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10870     8]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10495   379]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.034853779657899576\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.011349931919699982]\n",
      "[False  True]      [0.40130551 0.59869449]      [4365 6512]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10874     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [6081 4781]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10804    73]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.4401583502117474\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.01167193172542882]\n",
      "[False  True]      [0.17471264 0.82528736]      [1900 8975]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10758   119]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [6600 4262]\n",
      "feat_gpu_80_1f_02_f1_e3_db [6324 4554]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [8457 2417]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.4186431329288472\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.011295316394399185]\n",
      "[False  True]      [0.16608359 0.83391641]      [1804 9058]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10856    21]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10870     2]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10830    44]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10371   506]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10713   162]\n",
      "0.04652018019674543\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.0116867141169547]\n",
      "[False  True]      [0.40503769 0.59496231]      [4406 6472]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9754 1121]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10315   547]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [8114 2760]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10872     3]\n",
      "0.25381644289130034\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.012101767459650886]\n",
      "[False  True]      [0.31870861 0.68129139]      [3465 7407]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [9019 1855]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10600   262]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10653   221]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10710   167]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [4469 6406]\n",
      "0.5890574712643678\n",
      "0.7031824871228844 0.4175632183908046 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.011562619812780235]\n",
      "[False  True]      [0.3345595 0.6654405]      [3638 7236]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10788    87]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [9952  910]\n",
      "feat_gpu_80_1f_02_f1_e3_db [9049 1829]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10212   660]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [9742 1133]\n",
      "0.16813752528038242\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.010326283111118778]\n",
      "[False  True]      [0.16916429 0.83083571]      [1840 9037]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10866     8]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.0007356998344675372\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.010669469154054418]\n",
      "[False  True]      [0.18951724 0.81048276]      [2061 8814]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [9816 1058]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10006   856]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [6712 4160]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10592   282]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10871     6]\n",
      "0.3826342899190581\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.01643126257073983]\n",
      "[False  True]      [0.32640456 0.67359544]      [2748 5671]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.014076156376379788]\n",
      "[False  True]      [0.47048661 0.52951339]      [4902 5517]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.01386871455006214]\n",
      "[False  True]      [0.59965454 0.40034546]      [6249 4172]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [6648 3773]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6311   29]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.36205738412820265\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.012704431925808071]\n",
      "[False  True]      [0.51827338 0.48172662]      [5403 5022]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.014889647382857774]\n",
      "[False  True]      [0.37234961 0.62765039]      [3881 6542]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10377    44]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [6338 4083]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10378    43]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [7063 3357]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.39180500911620764\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.013662640559311882]\n",
      "[False  True]      [0.48646833 0.51353167]      [5069 5351]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.01468086509743504]\n",
      "[False  True]      [0.75299875 0.24700125]      [7847 2574]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10421     2]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10384    36]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.00345489443378119\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.010229410250324915]\n",
      "[False  True]      [0.3569796 0.6430204]      [4217 7596]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [7544 4269]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.36138152882417673\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.01103128301061503]\n",
      "[False  True]      [0.3832614 0.6167386]      [4529 7288]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11498   320]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.02707733965137925\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.013518504208728587]\n",
      "[False  True]      [0.40571922 0.59428078]      [4228 6193]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10418     3]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0002878802418194031\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.010400715679274114]\n",
      "[False  True]      [0.25175654 0.74824346]      [2974 8839]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.02392506847507818]\n",
      "[False  True]      [0.42839117 0.57160883]      [2716 3624]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [8972 1448]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.13896353166986564\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.010305853781647641]\n",
      "[False  True]      [0.27478202 0.72521798]      [3246 8567]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [8459 3354]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2839244899686786\n",
      "0.6949123846609667 0.22238212139168712 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.013330892044822034]\n",
      "[False  True]      [0.36545106 0.63454894]      [3808 6612]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5194 1146]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.1807570977917981\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.01392983277638923]\n",
      "[False  True]      [0.43464491 0.56535509]      [4529 5891]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10420     1]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10019   404]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [3999 6422]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10350    71]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.6162556376547357\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.011228792858639213]\n",
      "[False  True]      [0.36935184 0.63064816]      [4365 7453]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.024139269479943534]\n",
      "[False  True]      [0.38358577 0.61641423]      [2178 3500]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.010639742941547613]\n",
      "[False  True]      [0.28205997 0.71794003]      [3330 8476]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11777     7]\n",
      "0.0005940257976917854\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.010355488885122619]\n",
      "[False  True]      [0.26115297 0.73884703]      [3085 8728]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.011042645178035047]\n",
      "[False  True]      [0.17116429 0.82883571]      [2017 9767]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7442  977]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10731  1082]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10769  1044]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10722  1091]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5127  551]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10749  1057]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11166   647]\n",
      "0.11604703646513838\n",
      "0.9948234894772573 0.22712266147464658 dff: 128 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.01354934393786774]\n",
      "[False  True]      [0.17082927 0.82917073]      [1751 8499]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [8661 1589]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.15502439024390244\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.013747047516491334]\n",
      "[False  True]      [0.70540593 0.29459407]      [7229 3019]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10240    10]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.000975609756097561\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.013642988676566579]\n",
      "[False  True]      [0.72526829 0.27473171]      [7434 2816]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [6124 4126]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.4025365853658537\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.012858003502913789]\n",
      "[False  True]      [0.18481878 0.81518122]      [2055 9064]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.015436292469648762]\n",
      "[False  True]      [0.17679283 0.82320717]      [1775 8265]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.02054535012965642]\n",
      "[False  True]      [0.42517846 0.57482154]      [3276 4429]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8439  104]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.012173709469741308\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.0131245460434576]\n",
      "[False  True]      [0.34635112 0.65364888]      [3849 7264]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8358  185]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.02165515626828983\n",
      "0.9669756141455953 0.059697998361231415 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.01675030010824693]\n",
      "[False  True]      [0.30598151 0.69401849]      [2614 5929]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [10443   670]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0602897507423738\n",
      "0.6940184946740021 0.0602897507423738 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.015327824625953484]\n",
      "[False  True]      [0.35899183 0.64100817]      [3689 6587]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10157    93]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9970  280]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10260     5]\n",
      "0.027317073170731707\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.01432948476616027]\n",
      "[False  True]      [0.31095957 0.68904043]      [3192 7073]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.013766689326615867]\n",
      "[False  True]      [0.14321721 0.85678279]      [1591 9518]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8567827887298587 0 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.013348302115817666]\n",
      "[False  True]      [0.63750113 0.36249887]      [7082 4027]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.012649652630690813]\n",
      "[False  True]      [0.38275272 0.61724728]      [4252 6857]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.013301588236946094]\n",
      "[False  True]      [0.29937855 0.70062145]      [3324 7779]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.01189268682977781]\n",
      "[False  True]      [0.33837838 0.66162162]      [3756 7344]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 50 128\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.0005902182034071477]\n",
      "[False  True]      [0.3205812 0.6794188]      [3486 7388]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10160   712]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10845    32]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [9547 1328]\n",
      "0.12211494252873563\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.001028845360271814]\n",
      "[False  True]      [0.20542279 0.79457721]      [2235 8645]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10855    19]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10675   202]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [1509 9366]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [9573 1289]\n",
      "feat_gpu_80_1f_02_f1_e3_db [  656 10222]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10551   321]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [3693 7181]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10858    19]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [9532 1343]\n",
      "0.939694796837654\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.0004626187598731972]\n",
      "[False  True]      [0.43982716 0.56017284]      [4784 6093]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10871     3]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10652   223]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [8458 2404]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10871     7]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10836    36]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10613   261]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10300   577]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10257   618]\n",
      "0.2213220401399374\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.00044413014811777856]\n",
      "[False  True]      [0.29158621 0.70841379]      [3171 7704]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10870    10]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [9627 1250]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7033 3829]\n",
      "feat_gpu_80_1f_02_f1_e3_db [7004 3874]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10845    27]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [6059 4815]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10721   156]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10626   249]\n",
      "0.44279933787014897\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.0004869981152893878]\n",
      "[False  True]      [0.35076413 0.64923587]      [3810 7052]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10351   526]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10372   503]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10658   220]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_80_1f_02_f1_e3_e0 [10161   713]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10221   656]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10743   132]\n",
      "0.06556924774691926\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.0006473676391039694]\n",
      "[False  True]      [0.56287921 0.43712079]      [6123 4755]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9722 1153]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10747   115]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10576   298]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.10602298850574712\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.0005111667226963274]\n",
      "[False  True]      [0.31576527 0.68423473]      [3433 7439]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [9751 1123]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10782    95]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10727   148]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7807 3055]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10604   274]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [6283 4591]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10285   592]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [3082 7793]\n",
      "0.7165977011494253\n",
      "0.7031824871228844 0.4175632183908046 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.0004292383180905847]\n",
      "[False  True]      [0.30669487 0.69330513]      [3335 7539]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10870     4]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10774   103]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [7050 3825]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7903 2959]\n",
      "feat_gpu_80_1f_02_f1_e3_db [9665 1213]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10167   705]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10718   159]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [9067 1808]\n",
      "0.35172413793103446\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.0005136600631842274]\n",
      "[False  True]      [0.35101591 0.64898409]      [3818 7059]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10868     6]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10874     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10692   170]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10863    15]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10869     3]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10855    19]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10840    35]\n",
      "0.015650893021542996\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.0006249839568139562]\n",
      "[False  True]      [0.22813793 0.77186207]      [2481 8394]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [8395 2479]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [9006 1871]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [8863 2012]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [2664 8198]\n",
      "feat_gpu_80_1f_02_f1_e3_db [9352 1526]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [6701 4171]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [4024 6850]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [7457 3420]\n",
      "0.7547412999447616\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.000946343834488296]\n",
      "[False  True]      [0.46383181 0.53616819]      [3905 4514]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.0008919236108268986]\n",
      "[False  True]      [0.61368653 0.38631347]      [6394 4025]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.0007331629051705339]\n",
      "[False  True]      [0.62537185 0.37462815]      [6517 3904]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [8931 1490]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.14298052010363688\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.0007006634993443037]\n",
      "[False  True]      [0.62609113 0.37390887]      [6527 3898]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.0012675875933153052]\n",
      "[False  True]      [0.76004989 0.23995011]      [7922 2501]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10216   205]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10214   206]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.019769673704414587\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.0005677576279080158]\n",
      "[False  True]      [0.52101727 0.47898273]      [5429 4991]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.0009513384990096928]\n",
      "[False  True]      [0.80548892 0.19451108]      [8394 2027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10400    23]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10350    70]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0067178502879078695\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.001027566840529195]\n",
      "[False  True]      [0.64175061 0.35824939]      [7581 4232]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [9734 2079]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.17599255057986962\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.0005961611514223539]\n",
      "[False  True]      [0.52949141 0.47050859]      [6257 5560]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [10724  1094]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.09257065493315282\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.0011635679221449879]\n",
      "[False  True]      [0.39833029 0.60166971]      [4151 6270]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10405    16]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0015353612897034833\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.0006177788541585437]\n",
      "[False  True]      [0.32929823 0.67070177]      [3890 7923]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.000922819584925203]\n",
      "[False  True]      [0.79921136 0.20078864]      [5067 1273]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10417     3]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.00028790786948176584\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.0006569082945093142]\n",
      "[False  True]      [0.25835943 0.74164057]      [3052 8761]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [7116 4697]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.397612799458224\n",
      "0.6949123846609667 0.22238212139168712 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.0008663974471237853]\n",
      "[False  True]      [0.40278311 0.59721689]      [4197 6223]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5414  926]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.14605678233438485\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.0006206933209808181]\n",
      "[False  True]      [0.57111324 0.42888676]      [5951 4469]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10173   250]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [7398 3023]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2900873236733519\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.000912467641812374]\n",
      "[False  True]      [0.45117617 0.54882383]      [5332 6486]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11815     2]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.00016924769400016924\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.0015848291753547085]\n",
      "[False  True]      [0.67418105 0.32581895]      [3828 1850]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.0005254187916589881]\n",
      "[False  True]      [0.52142978 0.47857022]      [6156 5650]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.00041513678810030776]\n",
      "[False  True]      [0.6209261 0.3790739]      [7335 4478]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.0028792105037138945]\n",
      "[False  True]      [0.27885268 0.72114732]      [3286 8498]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7815  604]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10755  1058]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10790  1023]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10731  1082]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11443   363]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11476   337]\n",
      "0.09159400660289511\n",
      "0.9948234894772573 0.22712266147464658 dff: 128 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.0006751610609281441]\n",
      "[False  True]      [0.39473171 0.60526829]      [4046 6204]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [8532 1718]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.16760975609756099\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.000707862845590476]\n",
      "[False  True]      [0.74697502 0.25302498]      [7655 2593]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.0004975866798219601]\n",
      "[False  True]      [0.86585366 0.13414634]      [8875 1375]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [7549 2701]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.26351219512195123\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.0008671485212329068]\n",
      "[False  True]      [0.48529544 0.51470456]      [5396 5723]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.001004722589028616]\n",
      "[False  True]      [0.42440239 0.57559761]      [4261 5779]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.005361074426304858]\n",
      "[False  True]      [0.05256327 0.94743673]      [ 405 7300]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [  668 10451]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [6167 3873]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [   53 11060]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [2174 6369]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.9952308107621705\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.000682759496942165]\n",
      "[False  True]      [0.50760371 0.49239629]      [5641 5472]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [7789  754]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.08825939365562449\n",
      "0.9669756141455953 0.059697998361231415 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.0009350207584150945]\n",
      "[False  True]      [0.356081 0.643919]      [3042 5501]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [10350   763]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.06865832808422569\n",
      "0.6940184946740021 0.0602897507423738 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.0006470300345700423]\n",
      "[False  True]      [0.46788634 0.53211366]      [4808 5468]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.0005794205973364942]\n",
      "[False  True]      [0.3518753 0.6481247]      [3612 6653]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10248     2]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0.0001951219512195122\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.0006475566690416614]\n",
      "[False  True]      [0.67440814 0.32559186]      [7492 3617]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8567827887298587 0 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.0006906374510648344]\n",
      "[False  True]      [0.63146998 0.36853002]      [7015 4094]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.0007658324592808001]\n",
      "[False  True]      [0.66540643 0.33459357]      [7392 3717]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.0006689637798774075]\n",
      "[False  True]      [0.46672071 0.53327929]      [5182 5921]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.0006336257176118832]\n",
      "[False  True]      [0.48981982 0.51018018]      [5437 5663]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 50 192\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.000682875766361345]\n",
      "[False  True]      [0.29906198 0.70093802]      [3252 7622]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10137   735]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10676   201]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10030   845]\n",
      "0.07770114942528736\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.0008055504804350166]\n",
      "[False  True]      [0.85625 0.14375]      [9316 1564]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [8735 2140]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10755   123]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [8069 2805]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10830    45]\n",
      "0.25795475446018024\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.0005133422767119282]\n",
      "[False  True]      [0.43238025 0.56761975]      [4703 6174]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10873     1]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10850    25]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [8598 2264]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10870     2]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10820    54]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10702   175]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10754   121]\n",
      "0.20843306941631376\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.000510463874026006]\n",
      "[False  True]      [0.31328736 0.68671264]      [3407 7468]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10408   454]\n",
      "feat_gpu_80_1f_02_f1_e3_db [7387 3491]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [7909 2965]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.32092296378010665\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.0006071014394616188]\n",
      "[False  True]      [0.28143988 0.71856012]      [3057 7805]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10517   360]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10497   378]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10639   239]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10858    14]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10236   638]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10380   497]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10709   166]\n",
      "0.0586720617987861\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.0006434393640885852]\n",
      "[False  True]      [0.45716124 0.54283876]      [4973 5905]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9485 1390]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10636   238]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.127816091954023\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.000598708983745216]\n",
      "[False  True]      [0.44674393 0.55325607]      [4857 6015]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10149   725]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10856    21]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10665   197]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10877     1]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10232   642]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10804    73]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [5040 5835]\n",
      "0.5365517241379311\n",
      "0.7031824871228844 0.4175632183908046 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.0008550477900898804]\n",
      "[False  True]      [0.42468273 0.57531727]      [4618 6256]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9908  967]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10817    45]\n",
      "feat_gpu_80_1f_02_f1_e3_db [9531 1347]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10871     1]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10835    40]\n",
      "0.12382790954219526\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.000685864293498622]\n",
      "[False  True]      [0.25889492 0.74110508]      [2816 8061]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10849    25]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10753   109]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10871     3]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10873     2]\n",
      "0.010034984349106978\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.0007373751667581704]\n",
      "[False  True]      [0.25756322 0.74243678]      [2801 8074]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10080   794]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [9962  900]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [5985 4887]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9663 1211]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10865    12]\n",
      "0.44950331125827814\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.0017186487709246869]\n",
      "[False  True]      [0.48069842 0.51930158]      [4047 4372]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.001486129125269302]\n",
      "[False  True]      [0.5250024 0.4749976]      [5470 4949]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10410    10]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10418     3]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0009596928982725527\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.006527752579837111]\n",
      "[False  True]      [0.73198349 0.26801651]      [7628 2793]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [9438  983]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.09432875923615776\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.0006656875683167455]\n",
      "[False  True]      [0.68642686 0.31357314]      [7156 3269]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.000604097381496313]\n",
      "[False  True]      [0.60990118 0.39009882]      [6357 4066]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [9202 1219]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [8327 2093]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2008637236084453\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.0007390815636804068]\n",
      "[False  True]      [0.72766529 0.27233471]      [7583 2838]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10417     6]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10411     9]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0008637236084452975\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.0007750552804592626]\n",
      "[False  True]      [0.69389655 0.30610345]      [8197 3616]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10640  1173]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.09929738423770422\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.0012197328449624794]\n",
      "[False  True]      [0.40898705 0.59101295]      [4833 6984]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11431   387]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.03274665764088678\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.0010505162607459652]\n",
      "[False  True]      [0.57777565 0.42222435]      [6021 4400]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10389    32]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0030707225794069665\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0005208353632404763]\n",
      "[False  True]      [0.40413104 0.59586896]      [4774 7039]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.0015736237997218791]\n",
      "[False  True]      [0.67444795 0.32555205]      [4276 2064]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10233   187]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.017946257197696738\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.0005856252022533715]\n",
      "[False  True]      [0.30246339 0.69753661]      [3573 8240]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [8148 3665]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.3102514179293998\n",
      "0.6949123846609667 0.22238212139168712 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.0007728957114918075]\n",
      "[False  True]      [0.48800384 0.51199616]      [5085 5335]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5985  355]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.055993690851735015\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.0010095067440296904]\n",
      "[False  True]      [0.50403071 0.49596929]      [5252 5168]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10201   222]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [7836 2585]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.24805680836771904\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.0005283976087388695]\n",
      "[False  True]      [0.45083771 0.54916229]      [5328 6490]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.0032818773740154036]\n",
      "[False  True]      [0.58559352 0.41440648]      [3325 2353]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.0006937467674740933]\n",
      "[False  True]      [0.44841606 0.55158394]      [5294 6512]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.0009648293905145391]\n",
      "[False  True]      [0.2858715 0.7141285]      [3377 8436]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.0020780067859769106]\n",
      "[False  True]      [0.05863883 0.94136117]      [  691 11093]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8347   72]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10748  1065]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10786  1027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10613  1200]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "0.10158300177770253\n",
      "0.9413611676849966 0.10158300177770253 dff: 256 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.0008663970257161982]\n",
      "[False  True]      [0.36058537 0.63941463]      [3696 6554]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9561  689]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.06721951219512196\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.0007338430902558241]\n",
      "[False  True]      [0.80601093 0.19398907]      [8260 1988]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10238    12]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0011707317073170731\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.0011500111954686272]\n",
      "[False  True]      [0.78204878 0.21795122]      [8016 2234]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [5051 5199]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.507219512195122\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.0009078257189697506]\n",
      "[False  True]      [0.39706808 0.60293192]      [4415 6704]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.0008084385872701343]\n",
      "[False  True]      [0.462251 0.537749]      [4641 5399]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.001273128760745988]\n",
      "[False  True]      [0.71031798 0.28968202]      [5473 2232]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8498   45]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.005267470443638066\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.0011521150117965286]\n",
      "[False  True]      [0.71069918 0.28930082]      [7898 3215]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [4283 4260]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.4986538686644036\n",
      "0.9669756141455953 0.059697998361231415 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.003932623369031956]\n",
      "[False  True]      [0.39342151 0.60657849]      [3361 5182]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [10685   428]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.038513452713038784\n",
      "0.6940184946740021 0.0602897507423738 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.0010793998138532905]\n",
      "[False  True]      [0.44569872 0.55430128]      [4580 5696]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.0006759637274231072]\n",
      "[False  True]      [0.31183634 0.68816366]      [3201 7064]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.000772572125502186]\n",
      "[False  True]      [0.60410478 0.39589522]      [6711 4398]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8567827887298587 0 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.0006846912780404604]\n",
      "[False  True]      [0.65298407 0.34701593]      [7254 3855]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.001540469750951298]\n",
      "[False  True]      [0.61958772 0.38041228]      [6883 4226]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.0008060119276451447]\n",
      "[False  True]      [0.69179501 0.30820499]      [7681 3422]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.0009556930957271288]\n",
      "[False  True]      [0.48243243 0.51756757]      [5355 5745]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 50 256\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.0009883975856428884]\n",
      "[False  True]      [0.33915762 0.66084238]      [3688 7186]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10800    72]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10840    37]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10846    29]\n",
      "0.006622516556291391\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.00085367698660834]\n",
      "[False  True]      [0.76875 0.23125]      [8364 2516]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9301 1574]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10857    21]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10444   430]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10866     9]\n",
      "0.14473563218390806\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.0008390086970140636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]      [0.39873127 0.60126873]      [4337 6540]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10870     4]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10844    31]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [8417 2445]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10874     4]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10849    23]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10671   203]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10403   474]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10141   734]\n",
      "0.22509666728042718\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.0010785328791364226]\n",
      "[False  True]      [0.16248276 0.83751724]      [1767 9108]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10848    29]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10148   714]\n",
      "feat_gpu_80_1f_02_f1_e3_db [5457 5421]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [7082 3792]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.4983452840595698\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.0028018415773870932]\n",
      "[False  True]      [0.1635058 0.8364942]      [1776 9086]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10864    10]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [9836 1044]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [7574 3303]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [1443 9432]\n",
      "feat_gpu_80_1f_02_f1_e3_db [1186 9692]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [9427 1445]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [2788 8086]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [9731 1146]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [9896  979]\n",
      "0.8909726052583196\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.0009406423442721668]\n",
      "[False  True]      [0.5471594 0.4528406]      [5952 4926]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9846 1029]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10854     8]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10562   312]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.09462068965517241\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.0010798909826953656]\n",
      "[False  True]      [0.19168506 0.80831494]      [2084 8788]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [9579 1295]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10489   373]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10578   296]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10717   160]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [6137 4738]\n",
      "0.4356781609195402\n",
      "0.8083149374540103 0.4356781609195402 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.0008944626425297583]\n",
      "[False  True]      [0.41686592 0.58313408]      [4533 6341]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10005   870]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [9830 1032]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10281   597]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10767   105]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10835    42]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10310   565]\n",
      "0.09501012704842571\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.0009886238183486283]\n",
      "[False  True]      [0.42125586 0.57874414]      [4582 6295]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.000988739937063813]\n",
      "[False  True]      [0.28468966 0.71531034]      [3096 7779]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [9407 1467]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10809    53]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [2942 7930]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9588 1286]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "0.7293966151582045\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.0019931935379933286]\n",
      "[False  True]      [0.47832284 0.52167716]      [4027 4392]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.0015475462075547756]\n",
      "[False  True]      [0.54851713 0.45148287]      [5715 4704]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.0008943105685524932]\n",
      "[False  True]      [0.74647347 0.25352653]      [7779 2642]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [8732 1689]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.16207657614432397\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.0008317087258656319]\n",
      "[False  True]      [0.80374101 0.19625899]      [8379 2046]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.001771302181305735]\n",
      "[False  True]      [0.6787873 0.3212127]      [7075 3348]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [9845  576]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10071   349]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0552730064293254\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.0016134700484191492]\n",
      "[False  True]      [0.53262956 0.46737044]      [5550 4870]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.0010412852733481994]\n",
      "[False  True]      [0.91661069 0.08338931]      [9552  869]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10419     1]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "9.596928982725528e-05\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.0008532145021326275]\n",
      "[False  True]      [0.62507407 0.37492593]      [7384 4429]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [9639 2174]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.18403453822060442\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.0009544614313965221]\n",
      "[False  True]      [0.49708048 0.50291952]      [5874 5943]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11578   240]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.02030800473853444\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.001797553759400612]\n",
      "[False  True]      [0.56750792 0.43249208]      [5914 4507]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10417     4]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0003838403224258708\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.0009273919266350051]\n",
      "[False  True]      [0.48692119 0.51307881]      [5752 6061]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.004057581726162889]\n",
      "[False  True]      [0.51182965 0.48817035]      [3245 3095]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [9877  543]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.052111324376199614\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.0013996145887979908]\n",
      "[False  True]      [0.38576145 0.61423855]      [4557 7256]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10723  1090]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.09227122661474646\n",
      "0.6142385507491747 0.09227122661474646 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.0032578109632152665]\n",
      "[False  True]      [0.43598848 0.56401152]      [4543 5877]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [4528 1812]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2858044164037855\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0015305475955564019]\n",
      "[False  True]      [0.67274472 0.32725528]      [7010 3410]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10322   101]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [8582 1839]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.17647058823529413\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.001322874696295451]\n",
      "[False  True]      [0.47097648 0.52902352]      [5566 6252]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.003619762685723728]\n",
      "[False  True]      [0.52624163 0.47375837]      [2988 2690]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.000921462627751239]\n",
      "[False  True]      [0.48687108 0.51312892]      [5748 6058]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.001342450356777832]\n",
      "[False  True]      [0.41479726 0.58520274]      [4900 6913]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.0006505077916412713]\n",
      "[False  True]      [0.33562458 0.66437542]      [3955 7829]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8381   38]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10988   825]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11302   511]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10868   945]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "0.07999661389994074\n",
      "0.9413611676849966 0.10158300177770253 dff: 256 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.0015784777529835353]\n",
      "[False  True]      [0.31853659 0.68146341]      [3265 6985]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10235    13]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [5142 5108]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10271     5]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.49834146341463414\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.0012379214724911958]\n",
      "[False  True]      [0.81723263 0.18276737]      [8375 1873]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.0013253915337819615]\n",
      "[False  True]      [0.78604878 0.21395122]      [8057 2193]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [3755 6495]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.6336585365853659\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.0011343066951799885]\n",
      "[False  True]      [0.43484126 0.56515874]      [4835 6284]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.0013817807092870635]\n",
      "[False  True]      [0.42689243 0.57310757]      [4286 5754]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.0021906198238047098]\n",
      "[False  True]      [0.63296561 0.36703439]      [4877 2828]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8285  258]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.030200163876858248\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001206083275990885]\n",
      "[False  True]      [0.6693962 0.3306038]      [7439 3674]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8524   19]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.002224043076202739\n",
      "0.9669756141455953 0.059697998361231415 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.002273467185702004]\n",
      "[False  True]      [0.44995903 0.55004097]      [3844 4699]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [10987   126]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.011338072527670296\n",
      "0.6940184946740021 0.0602897507423738 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.0012607905477156891]\n",
      "[False  True]      [0.48043986 0.51956014]      [4937 5339]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.00107861821546461]\n",
      "[False  True]      [0.36999513 0.63000487]      [3798 6467]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.0009997167917224806]\n",
      "[False  True]      [0.57142857 0.42857143]      [6348 4761]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8567827887298587 0 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.0015329743523497781]\n",
      "[False  True]      [0.61814745 0.38185255]      [6867 4242]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.0009173984353739186]\n",
      "[False  True]      [0.63507066 0.36492934]      [7055 4054]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.0009581302495499569]\n",
      "[False  True]      [0.58776907 0.41223093]      [6526 4577]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.0010530141390225091]\n",
      "[False  True]      [0.60315315 0.39684685]      [6695 4405]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "256 1 50 512\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.003576616772165096]\n",
      "[False  True]      [0.20112194 0.79887806]      [2187 8687]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10758   114]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10769   106]\n",
      "0.010485651214128035\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.0035363131809394064]\n",
      "[False  True]      [0.84503676 0.15496324]      [9194 1686]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10259   616]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10837    25]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10877     1]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10233   641]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10873     2]\n",
      "0.05894794923671142\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.003492849271954781]\n",
      "[False  True]      [0.4287947 0.5712053]      [4664 6213]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10868     7]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [4843 6019]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10873     1]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10859    18]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10874     1]\n",
      "0.5541336770392193\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.0034325093468724932]\n",
      "[False  True]      [0.24193103 0.75806897]      [2631 8244]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10845    32]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10228   634]\n",
      "feat_gpu_80_1f_02_f1_e3_db [8469 2409]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9083 1791]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.2214561500275786\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.003683488905594079]\n",
      "[False  True]      [0.21432517 0.78567483]      [2328 8534]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10843    31]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10454   423]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10871     4]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10830    48]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10332   540]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10123   751]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [9326 1551]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [8371 2504]\n",
      "0.23025287356321839\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.0033331992383922714]\n",
      "[False  True]      [0.51259423 0.48740577]      [5576 5302]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9042 1833]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10710   152]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9293 1581]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.16855172413793104\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.0031191390172163836]\n",
      "[False  True]      [0.36433039 0.63566961]      [3961 6911]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10319   555]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10687   175]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10578   296]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10864    13]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [5264 5611]\n",
      "0.5159540229885058\n",
      "0.8083149374540103 0.4356781609195402 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.0031823824502639417]\n",
      "[False  True]      [0.41649807 0.58350193]      [4529 6345]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10667   208]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10029   833]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10396   482]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10692   180]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10563   312]\n",
      "0.07668937580556066\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.002952433859768063]\n",
      "[False  True]      [0.26468695 0.73531305]      [2879 7998]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.003418590157063549]\n",
      "[False  True]      [0.28349425 0.71650575]      [3083 7792]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10491   383]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10810    52]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [6874 3998]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10814    60]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "0.36773362766740253\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.005043345979388771]\n",
      "[False  True]      [0.40551134 0.59448866]      [3414 5005]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.005388820331000042]\n",
      "[False  True]      [0.43055955 0.56944045]      [4486 5933]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.0036763825570594343]\n",
      "[False  True]      [0.70645811 0.29354189]      [7362 3059]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [9668  753]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.07225794069667019\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.005390738742043452]\n",
      "[False  True]      [0.57851319 0.42148681]      [6031 4394]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.003712608988151667]\n",
      "[False  True]      [0.74220474 0.25779526]      [7736 2687]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [8584 1837]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [9281 1139]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.17627866807408119\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.004127735508666228]\n",
      "[False  True]      [0.59836852 0.40163148]      [6235 4185]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.008915773903745582]\n",
      "[False  True]      [0.69475098 0.30524902]      [7240 3181]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10304   119]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10416     5]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10267   153]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.014683301343570057\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.004045298156416597]\n",
      "[False  True]      [0.4958097 0.5041903]      [5857 5956]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [8284 3529]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.29873867772792684\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.0035134843984872747]\n",
      "[False  True]      [0.40517898 0.59482102]      [4788 7029]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11146   672]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.05686241326789643\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.006308670619263277]\n",
      "[False  True]      [0.62249304 0.37750696]      [6487 3934]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.002676915648352295]\n",
      "[False  True]      [0.36578346 0.63421654]      [4321 7492]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.008371152683684428]\n",
      "[False  True]      [0.49242902 0.50757098]      [3122 3218]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [8209 2211]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.21218809980806141\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.0027041982483320083]\n",
      "[False  True]      [0.25776687 0.74223313]      [3045 8768]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [6920 4893]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.41420468974858204\n",
      "0.6142385507491747 0.09227122661474646 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.0037001167104244136]\n",
      "[False  True]      [0.39318618 0.60681382]      [4097 6323]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [4775 1565]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.24684542586750788\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.0047475798709913815]\n",
      "[False  True]      [0.57581574 0.42418426]      [6000 4420]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10271   152]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [8168 2253]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.21619806160637176\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.002727506834124941]\n",
      "[False  True]      [0.42299882 0.57700118]      [4999 6819]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11802    15]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0012693577050012694\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.008494549787238173]\n",
      "[False  True]      [0.46512857 0.53487143]      [2641 3037]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.002917939667417974]\n",
      "[False  True]      [0.39479925 0.60520075]      [4661 7145]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.0028248419745910917]\n",
      "[False  True]      [0.32498095 0.67501905]      [3839 7974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.002960940900338773]\n",
      "[False  True]      [0.32807196 0.67192804]      [3866 7918]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7870  549]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10784  1029]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10826   987]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10767  1046]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10882   924]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11444   369]\n",
      "0.08854651654956404\n",
      "0.9413611676849966 0.10158300177770253 dff: 256 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.0038806445001485293]\n",
      "[False  True]      [0.24887805 0.75112195]      [2551 7699]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9712  538]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.05248780487804878\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.0038509258920363314]\n",
      "[False  True]      [0.73507026 0.26492974]      [7533 2715]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.003954229714325405]\n",
      "[False  True]      [0.77043902 0.22956098]      [7897 2353]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [6388 3862]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.37678048780487805\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.0037686195991492085]\n",
      "[False  True]      [0.30020685 0.69979315]      [3338 7781]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.00384846580642278]\n",
      "[False  True]      [0.32031873 0.67968127]      [3216 6824]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.006694769694005541]\n",
      "[False  True]      [0.56469825 0.43530175]      [4351 3354]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8535    8]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0009364391899801006\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.005675773066877726]\n",
      "[False  True]      [0.02897507 0.97102493]      [  322 10791]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8403  140]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.016387685824651763\n",
      "0.9710249257626203 0.016387685824651763 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.005297295421874333]\n",
      "[False  True]      [0.41636427 0.58363573]      [3557 4986]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11048    65]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.005849005669036264\n",
      "0.6940184946740021 0.0602897507423738 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.00412394591121977]\n",
      "[False  True]      [0.45260802 0.54739198]      [4651 5625]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.004192207092155331]\n",
      "[False  True]      [0.36941062 0.63058938]      [3792 6473]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.004626076957745669]\n",
      "[False  True]      [0.09055721 0.90944279]      [ 1006 10103]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.9094427941308849 0 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.004082762001177229]\n",
      "[False  True]      [0.58277073 0.41722927]      [6474 4635]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.004087219662351088]\n",
      "[False  True]      [0.4952741 0.5047259]      [5502 5607]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.0034729880715687216]\n",
      "[False  True]      [0.59425381 0.40574619]      [6598 4505]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.005891052190929823]\n",
      "[False  True]      [0.49810811 0.50189189]      [5529 5571]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "1024 1 10 128\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004744204444586923]\n",
      "[False  True]      [0.20516829 0.79483171]      [2231 8643]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10651   221]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10287   588]\n",
      "0.05406896551724138\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.004500269286893686]\n",
      "[False  True]      [0.86755515 0.13244485]      [9439 1441]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10615   260]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10826    36]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10228   646]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10869     6]\n",
      "0.05940776163325363\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.004588060966716436]\n",
      "[False  True]      [0.45462903 0.54537097]      [4945 5932]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10874     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [6293 4569]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10872     2]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10824    53]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.4206407659731173\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.004469182027666724]\n",
      "[False  True]      [0.19255172 0.80744828]      [2094 8781]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10875     2]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10561   301]\n",
      "feat_gpu_80_1f_02_f1_e3_db [5387 5491]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [8090 2784]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.5047802904945762\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.004888593646529641]\n",
      "[False  True]      [0.20649972 0.79350028]      [2243 8619]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10753   124]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10872     3]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10871     7]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10835    39]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10627   250]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10826    49]\n",
      "0.02298427875333272\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.004445220651662389]\n",
      "[False  True]      [0.44309616 0.55690384]      [4820 6058]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9095 1780]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10740   122]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9568 1306]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.16367816091954024\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.004624246252235028]\n",
      "[False  True]      [0.35807579 0.64192421]      [3893 6979]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10605   269]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10782    80]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10450   424]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [4483 6392]\n",
      "0.5877701149425287\n",
      "0.8083149374540103 0.4356781609195402 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.004453621696677092]\n",
      "[False  True]      [0.35957329 0.64042671]      [3910 6964]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10632   243]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10069   793]\n",
      "feat_gpu_80_1f_02_f1_e3_db [9134 1744]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10603   269]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10099   776]\n",
      "0.16032358889501747\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.004936921598654082]\n",
      "[False  True]      [0.19656155 0.80343845]      [2138 8739]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.00487306365799883]\n",
      "[False  True]      [0.23337931 0.76662069]      [2538 8337]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10445   429]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10630   232]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [7028 3844]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10625   249]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "0.35356880058866813\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.006229426858550306]\n",
      "[False  True]      [0.54032545 0.45967455]      [4549 3870]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.006167562628615101]\n",
      "[False  True]      [0.63422593 0.36577407]      [6608 3811]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.0058960465781603775]\n",
      "[False  True]      [0.75837252 0.24162748]      [7903 2518]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [8101 2320]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6245   95]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.22262738700700507\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.005747923172645006]\n",
      "[False  True]      [0.65592326 0.34407674]      [6838 3587]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.0063174825363766255]\n",
      "[False  True]      [0.56931785 0.43068215]      [5934 4489]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [8717 1704]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [9033 1387]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.16351597735342097\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.005523533966375076]\n",
      "[False  True]      [0.65268714 0.34731286]      [6801 3619]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.005804140872881204]\n",
      "[False  True]      [0.91776221 0.08223779]      [9564  857]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10408    12]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0011516314779270633\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.0049039005109229135]\n",
      "[False  True]      [0.6141539 0.3858461]      [7255 4558]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [9574 2239]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.18953695081689664\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.00489419540903785]\n",
      "[False  True]      [0.45299145 0.54700855]      [5353 6464]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11530   288]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.024369605686241327\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.005475232071826453]\n",
      "[False  True]      [0.76595336 0.23404664]      [7982 2439]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.004391099548355238]\n",
      "[False  True]      [0.472107 0.527893]      [5577 6236]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.009385350182422782]\n",
      "[False  True]      [0.58769716 0.41230284]      [3726 2614]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10115   305]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.02927063339731286\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.005392130816803442]\n",
      "[False  True]      [0.42173876 0.57826124]      [4982 6831]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [9867 1946]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.16473376788284094\n",
      "0.6142385507491747 0.09227122661474646 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.005882493906798975]\n",
      "[False  True]      [0.45019194 0.54980806]      [4691 5729]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5512  828]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.1305993690851735\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.005667102245793636]\n",
      "[False  True]      [0.67476008 0.32523992]      [7031 3389]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10323   100]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [7461 2960]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2840418385951444\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.00470847805924735]\n",
      "[False  True]      [0.46234557 0.53765443]      [5464 6354]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.008800683728582956]\n",
      "[False  True]      [0.57308912 0.42691088]      [3254 2424]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.004779394522967596]\n",
      "[False  True]      [0.59249534 0.40750466]      [6995 4811]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.004439174024670781]\n",
      "[False  True]      [0.48615932 0.51384068]      [5743 6070]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.005889820693355324]\n",
      "[False  True]      [0.01230482 0.98769518]      [  145 11639]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7474  945]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10719  1094]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10504  1309]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10497  1316]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5274  404]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10761  1045]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11055   758]\n",
      "0.1122461099893099\n",
      "0.9876951799049559 0.1122461099893099 dff: 1024 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.005268980051660554]\n",
      "[False  True]      [0.25326829 0.74673171]      [2596 7654]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9577  673]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.06565853658536586\n",
      "0.8565853658536585 0.10478048780487804 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.005502111601205229]\n",
      "[False  True]      [0.72501952 0.27498048]      [7430 2818]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10086   164]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.016\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.005387708937634062]\n",
      "[False  True]      [0.772 0.228]      [7913 2337]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [5258 4992]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.4870243902439024\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.005436084084738382]\n",
      "[False  True]      [0.20532422 0.79467578]      [2283 8836]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.006113903807058269]\n",
      "[False  True]      [0.28276892 0.71723108]      [2839 7201]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.007968435547094307]\n",
      "[False  True]      [0.52900714 0.47099286]      [4076 3629]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8485   58]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0067891841273557295\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.0055736237670309914]\n",
      "[False  True]      [0.4699901 0.5300099]      [5223 5890]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8113  430]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.05033360646143041\n",
      "0.9710249257626203 0.016387685824651763 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.0064223277857431245]\n",
      "[False  True]      [0.39412384 0.60587616]      [3367 5176]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [10849   264]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.023755961486547288\n",
      "0.6940184946740021 0.0602897507423738 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.005552035121578842]\n",
      "[False  True]      [0.38662904 0.61337096]      [3973 6303]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.005608882989041841]\n",
      "[False  True]      [0.31933755 0.68066245]      [3278 6987]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "[0.004897836203442098]\n",
      "[False  True]      [0.47132955 0.52867045]      [5236 5873]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.9094427941308849 0 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.005658504312093159]\n",
      "[False  True]      [0.56764785 0.43235215]      [6306 4803]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.004906948935020371]\n",
      "[False  True]      [0.54415339 0.45584661]      [6045 5064]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.004990157123311405]\n",
      "[False  True]      [0.57470954 0.42529046]      [6381 4722]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.005205990135604565]\n",
      "[False  True]      [0.40351351 0.59648649]      [4479 6621]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "1024 1 10 192\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.00679691133278724]\n",
      "[False  True]      [0.22576789 0.77423211]      [2455 8419]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10869     3]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10838    39]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10757   118]\n",
      "0.010850574712643678\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.006608817879226987]\n",
      "[False  True]      [0.85183824 0.14816176]      [9268 1612]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9952  923]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10788    74]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10877     1]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10148   726]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10872     3]\n",
      "0.0848735632183908\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.006393485562840098]\n",
      "[False  True]      [0.41629126 0.58370874]      [4528 6349]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [8113 2749]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10871     4]\n",
      "0.2530841465660099\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.006866542443060085]\n",
      "[False  True]      [0.19457471 0.80542529]      [2116 8759]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10836    41]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10681   181]\n",
      "feat_gpu_80_1f_02_f1_e3_db [7415 3463]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10516   358]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.31834896120610406\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.006356162010573457]\n",
      "[False  True]      [0.19075677 0.80924323]      [2072 8790]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10714   163]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10870     5]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10877     1]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10862    10]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10614   260]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10365   512]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10654   221]\n",
      "0.047071802886825415\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.006719633902887554]\n",
      "[False  True]      [0.40466998 0.59533002]      [4402 6476]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9130 1745]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10218   644]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [7082 3792]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.34872172153761266\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.006927431698183974]\n",
      "[False  True]      [0.29976085 0.70023915]      [3259 7613]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10129   745]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10696   178]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [5346 5529]\n",
      "0.5084137931034483\n",
      "0.8083149374540103 0.4356781609195402 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.006470408128867041]\n",
      "[False  True]      [0.35810189 0.64189811]      [3894 6980]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10836    39]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10481   381]\n",
      "feat_gpu_80_1f_02_f1_e3_db [9756 1122]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10360   512]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10114   761]\n",
      "0.10314396028681742\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.006845908646899374]\n",
      "[False  True]      [0.23480739 0.76519261]      [2554 8323]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.006849460286658579]\n",
      "[False  True]      [0.19328736 0.80671264]      [2102 8773]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10551   323]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10269   593]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [7139 3733]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10736   138]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10873     4]\n",
      "0.3433590875643856\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.00903604421768334]\n",
      "[False  True]      [0.45848676 0.54151324]      [3860 4559]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.008948960264963985]\n",
      "[False  True]      [0.57539111 0.42460889]      [5995 4424]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.008867534288842618]\n",
      "[False  True]      [0.57633624 0.42366376]      [6006 4415]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [9753  668]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.06410133384512043\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.008748235985991889]\n",
      "[False  True]      [0.60268585 0.39731415]      [6283 4142]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.008630984999999999]\n",
      "[False  True]      [0.62314113 0.37685887]      [6495 3928]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [8889 1532]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [9590  830]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.14701084348910853\n",
      "0.41091816175765133 0.04135879474138758 dff: 32 num_layers: 1 e: 50 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.008300321526769256]\n",
      "[False  True]      [0.54856046 0.45143954]      [5716 4704]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.00859760336661809]\n",
      "[False  True]      [0.88705499 0.11294501]      [9244 1177]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10419     1]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "9.596928982725528e-05\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.00642657700195237]\n",
      "[False  True]      [0.59874714 0.40125286]      [7073 4740]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10405  1408]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.11919072208583764\n",
      "0.603995598069923 0.16134766782358417 dff: 256 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.007051836626050621]\n",
      "[False  True]      [0.47820936 0.52179064]      [5651 6166]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11742    76]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.006430868167202572\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.00873081771329076]\n",
      "[False  True]      [0.57278572 0.42721428]      [5969 4452]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10420     1]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "9.59600806064677e-05\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.006597428727964017]\n",
      "[False  True]      [0.28028443 0.71971557]      [3311 8502]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.012801887568870495]\n",
      "[False  True]      [0.54511041 0.45488959]      [3456 2884]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [9874  546]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.05239923224568138\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.00634552657667427]\n",
      "[False  True]      [0.41505121 0.58494879]      [4903 6910]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10556  1257]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.1064081943621434\n",
      "0.6142385507491747 0.09227122661474646 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.008695590061722134]\n",
      "[False  True]      [0.3756238 0.6243762]      [3914 6506]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5347  993]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.15662460567823344\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.008452343340870997]\n",
      "[False  True]      [0.52101727 0.47898273]      [5429 4991]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10339    84]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [9135 1286]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.12340466365991748\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.0072333584562808]\n",
      "[False  True]      [0.46446099 0.53553901]      [5489 6329]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.013394506719689133]\n",
      "[False  True]      [0.43237055 0.56762945]      [2455 3223]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.006929946174968082]\n",
      "[False  True]      [0.36108758 0.63891242]      [4263 7543]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.007210843621059462]\n",
      "[False  True]      [0.40540083 0.59459917]      [4789 7024]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.006514723482004419]\n",
      "[False  True]      [0.13840801 0.86159199]      [ 1631 10153]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7642  777]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10739  1074]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10781  1032]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10736  1077]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10769  1037]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11278   535]\n",
      "0.09229124599121036\n",
      "0.9876951799049559 0.1122461099893099 dff: 1024 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.009436955710001887]\n",
      "[False  True]      [0.16058537 0.83941463]      [1646 8604]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [9483  767]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.07482926829268292\n",
      "0.8394146341463414 0.07482926829268292 dff: 1024 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.009863492212721921]\n",
      "[False  True]      [0.71994536 0.28005464]      [7378 2870]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.007961200209679279]\n",
      "[False  True]      [0.76897561 0.23102439]      [7882 2368]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [5431 4819]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.4701463414634146\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.008010560328219528]\n",
      "[False  True]      [0.20109722 0.79890278]      [2236 8883]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.008457616542061185]\n",
      "[False  True]      [0.2623506 0.7376494]      [2634 7406]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.011344364522074296]\n",
      "[False  True]      [0.40973394 0.59026606]      [3157 4548]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8534    9]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0010534940887276132\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.007870042066860527]\n",
      "[False  True]      [0.37739584 0.62260416]      [4194 6919]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8502   41]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.004799250848648016\n",
      "0.9710249257626203 0.016387685824651763 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.009517635950519257]\n",
      "[False  True]      [0.46646377 0.53353623]      [3985 4558]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11077    36]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0032394492936200846\n",
      "0.6940184946740021 0.0602897507423738 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.008033150582712771]\n",
      "[False  True]      [0.38302842 0.61697158]      [3936 6340]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.008207581222702898]\n",
      "[False  True]      [0.31690209 0.68309791]      [3253 7012]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.0071254535005537065]\n",
      "[False  True]      [0.42362049 0.57637951]      [4706 6403]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.9094427941308849 0 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.00874005663258609]\n",
      "[False  True]      [0.38509317 0.61490683]      [4278 6831]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.007898102207884507]\n",
      "[False  True]      [0.27635251 0.72364749]      [3070 8039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.007908064757213633]\n",
      "[False  True]      [0.22489417 0.77510583]      [2497 8606]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.007644285534514157]\n",
      "[False  True]      [0.38423423 0.61576577]      [4265 6835]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "1024 1 10 256\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.008495768437692392]\n",
      "[False  True]      [0.2115137 0.7884863]      [2300 8574]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10865     7]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10871     6]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10710   165]\n",
      "0.015172413793103448\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.008670009377556931]\n",
      "[False  True]      [0.83887868 0.16112132]      [9127 1753]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10875     2]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10272   603]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10847    15]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10876     2]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10871     1]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10240   634]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10871     4]\n",
      "0.058304211881552326\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.008763830978932928]\n",
      "[False  True]      [0.42263492 0.57736508]      [4597 6280]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [6571 4291]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10877     1]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10806    71]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10872     3]\n",
      "0.39504695267906464\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.008489822607857803]\n",
      "[False  True]      [0.2045977 0.7954023]      [2225 8650]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10823    54]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [9254 1608]\n",
      "feat_gpu_80_1f_02_f1_e3_db [6815 4063]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9249 1625]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.37350615922044494\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.008234851326130822]\n",
      "[False  True]      [0.20788068 0.79211932]      [2258 8604]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10855    22]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10867     8]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10877     1]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10871     1]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10805    69]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10814    63]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10769   106]\n",
      "0.00974712643678161\n",
      "0.8539863745166636 0.06619472280959823 dff: 32 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.008884489249031527]\n",
      "[False  True]      [0.37764295 0.62235705]      [4108 6770]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9733 1142]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10035   827]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [7837 3037]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.2792900496597388\n",
      "0.5984555984555985 0.1018944270737539 dff: 256 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.00977653964157326]\n",
      "[False  True]      [0.32928624 0.67071376]      [3580 7292]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [9141 1733]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10707   155]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10310   564]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10793    84]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [5452 5423]\n",
      "0.49866666666666665\n",
      "0.8083149374540103 0.4356781609195402 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.00857729834671176]\n",
      "[False  True]      [0.32517933 0.67482067]      [3536 7338]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10823    52]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10248   614]\n",
      "feat_gpu_80_1f_02_f1_e3_db [9566 1312]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10294   578]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10155   720]\n",
      "0.12061040632469204\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.008597109248083596]\n",
      "[False  True]      [0.15362692 0.84637308]      [1671 9206]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10873     1]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "9.196247930844215e-05\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.008339309764051341]\n",
      "[False  True]      [0.1737931 0.8262069]      [1890 8985]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [9664 1210]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [9923  939]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [6163 4709]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10382   492]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10809    68]\n",
      "0.43313097866078\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.011573366134610432]\n",
      "[False  True]      [0.34921012 0.65078988]      [2940 5479]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.011828130402381627]\n",
      "[False  True]      [0.54717343 0.45282657]      [5701 4718]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.01123345870498844]\n",
      "[False  True]      [0.63410421 0.36589579]      [6608 3813]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [9273 1148]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.11016217253622493\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.01035648257190092]\n",
      "[False  True]      [0.59434053 0.40565947]      [6196 4229]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.013099620262382108]\n",
      "[False  True]      [0.37129425 0.62870575]      [3870 6553]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [9468  953]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [8713 1707]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.16381957773512476\n",
      "0.6287057469058812 0.16381957773512476 dff: 1024 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.009937653552675056]\n",
      "[False  True]      [0.52293666 0.47706334]      [5449 4971]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.012092592570512595]\n",
      "[False  True]      [0.89377219 0.10622781]      [9314 1107]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10418     2]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.00019193857965451057\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.008993644812007196]\n",
      "[False  True]      [0.33869466 0.66130534]      [4001 7812]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [9372 2441]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.20663675611614324\n",
      "0.6613053415728435 0.20663675611614324 dff: 1024 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.010316010077406164]\n",
      "[False  True]      [0.43716679 0.56283321]      [5166 6651]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11399   419]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.03545439160602471\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.011268341415591117]\n",
      "[False  True]      [0.52806832 0.47193168]      [5503 4918]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.008906485482035926]\n",
      "[False  True]      [0.19774824 0.80225176]      [2336 9477]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.01754720719624199]\n",
      "[False  True]      [0.49921136 0.50078864]      [3165 3175]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [9407 1013]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0972168905950096\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.008707963621834111]\n",
      "[False  True]      [0.31050538 0.68949462]      [3668 8145]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [8571 3242]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.27444340980275966\n",
      "0.6142385507491747 0.09227122661474646 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.010791245254244228]\n",
      "[False  True]      [0.35287908 0.64712092]      [3677 6743]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5259 1081]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.17050473186119874\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.010773628925754784]\n",
      "[False  True]      [0.48138196 0.51861804]      [5016 5404]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10283   140]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [7383 3038]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2915267248824489\n",
      "0.4216890595009597 0.06045485078207466 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.009318355991939437]\n",
      "[False  True]      [0.42384498 0.57615502]      [5009 6809]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11813     4]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0003384953880003385\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.017049198694060488]\n",
      "[False  True]      [0.42004227 0.57995773]      [2385 3293]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.008839501894308542]\n",
      "[False  True]      [0.34152126 0.65847874]      [4032 7774]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.00965481897073653]\n",
      "[False  True]      [0.32277999 0.67722001]      [3813 8000]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.009963593266156718]\n",
      "[False  True]      [0.26756619 0.73243381]      [3153 8631]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7617  802]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10761  1052]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10804  1009]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10734  1079]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10746  1060]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11036   777]\n",
      "0.09526071980045137\n",
      "0.9876951799049559 0.1122461099893099 dff: 1024 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.01109893356274512]\n",
      "[False  True]      [0.14507317 0.85492683]      [1487 8763]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [8815 1435]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.14\n",
      "0.8394146341463414 0.07482926829268292 dff: 1024 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.010054794476322649]\n",
      "[False  True]      [0.69447697 0.30552303]      [7117 3131]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.010679607748976867]\n",
      "[False  True]      [0.77112195 0.22887805]      [7904 2346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_dc_a6_32_14_a6_53 [4204 6046]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.5898536585365853\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.01011429401352559]\n",
      "[False  True]      [0.15819768 0.84180232]      [1759 9360]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.012332734590082446]\n",
      "[False  True]      [0.20199203 0.79800797]      [2028 8012]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.01484535605497287]\n",
      "[False  True]      [0.53614536 0.46385464]      [4131 3574]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8523   20]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0023410979749502515\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.009952955538890166]\n",
      "[False  True]      [0.45631243 0.54368757]      [5071 6042]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8108  435]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.05091888095516797\n",
      "0.9710249257626203 0.016387685824651763 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.013055910168695223]\n",
      "[False  True]      [0.31417535 0.68582465]      [2684 5859]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [9940 1173]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.10555205615045442\n",
      "0.6940184946740021 0.0602897507423738 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.010837415907305708]\n",
      "[False  True]      [0.32142857 0.67857143]      [3303 6973]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.011849790264927424]\n",
      "[False  True]      [0.29069654 0.70930346]      [2984 7281]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10245     5]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0.0004878048780487805\n",
      "0.8046760837798344 0.034439024390243905 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.009632301606210756]\n",
      "[False  True]      [0.28598434 0.71401566]      [3177 7932]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.9094427941308849 0 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.009643994234618349]\n",
      "[False  True]      [0.54199298 0.45800702]      [6021 5088]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7436312899450895 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.009113876060066214]\n",
      "[False  True]      [0.38626339 0.61373661]      [4291 6818]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.010625461607203268]\n",
      "[False  True]      [0.57470954 0.42529046]      [6381 4722]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.009913197479754329]\n",
      "[False  True]      [0.38081081 0.61918919]      [4227 6873]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "1024 1 10 512\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.015214153352133735]\n",
      "[False  True]      [0.13785176 0.86214824]      [1499 9375]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10855    17]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10864    13]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10826    49]\n",
      "0.004505747126436781\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.016503583320755945]\n",
      "[False  True]      [0.76920956 0.23079044]      [8369 2511]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10859    18]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10403   472]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10700   162]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10863    15]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10143   731]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.06722457237447121\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.015602535509768208]\n",
      "[False  True]      [0.34099476 0.65900524]      [3709 7168]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7546 3316]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10869     8]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10866     9]\n",
      "0.3052844779966857\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.015566792736719366]\n",
      "[False  True]      [0.1394023 0.8605977]      [1516 9359]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10837    40]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [8237 2625]\n",
      "feat_gpu_80_1f_02_f1_e3_db [6375 4503]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9419 1455]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.41395477109762824\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.015342269665381082]\n",
      "[False  True]      [0.12888971 0.87111029]      [1400 9462]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10822    55]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10874     4]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10869     3]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10775    99]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10707   170]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10608   267]\n",
      "0.024551724137931035\n",
      "0.8711102927637636 0.024551724137931035 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0151111069124731]\n",
      "[False  True]      [0.32460011 0.67539989]      [3531 7347]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10029   846]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10628   234]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [9415 1459]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.1341732573110171\n",
      "0.6753998896856039 0.1341732573110171 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.015069388588654389]\n",
      "[False  True]      [0.26646431 0.73353569]      [2897 7975]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10123   751]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10733   129]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10783    91]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10858    19]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [5007 5868]\n",
      "0.5395862068965517\n",
      "0.8083149374540103 0.4356781609195402 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.015730580324411665]\n",
      "[False  True]      [0.29694685 0.70305315]      [3229 7645]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10862    12]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10871     6]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10440   435]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [7058 3804]\n",
      "feat_gpu_80_1f_02_f1_e3_db [5581 5297]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10153   719]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10807    70]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [8669 2206]\n",
      "0.4869461298032727\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.01716095250086502]\n",
      "[False  True]      [0.21927002 0.78072998]      [2385 8492]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10862    12]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.001103549751701306\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.015758638571133084]\n",
      "[False  True]      [0.15935632 0.84064368]      [1733 9142]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [8568 2306]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [9276 1586]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [6593 4279]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10469   405]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10823    54]\n",
      "0.39357983811626196\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.02274942172634201]\n",
      "[False  True]      [0.27960565 0.72039435]      [2354 6065]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.02037763652719031]\n",
      "[False  True]      [0.48939438 0.51060562]      [5099 5320]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.020579377229556505]\n",
      "[False  True]      [0.58209385 0.41790615]      [6066 4355]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [8709 1712]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6296   44]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.16428365799827271\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.019634537068705236]\n",
      "[False  True]      [0.48393285 0.51606715]      [5045 5380]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.020819528979259646]\n",
      "[False  True]      [0.38578144 0.61421856]      [4021 6402]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [7600 2821]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10411    10]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [8594 1826]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.27070338739084543\n",
      "0.6287057469058812 0.16381957773512476 dff: 1024 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.020022614426147108]\n",
      "[False  True]      [0.49433781 0.50566219]      [5151 5269]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.020258577035268517]\n",
      "[False  True]      [0.70712983 0.29287017]      [7369 3052]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10422     1]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10408    12]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0011516314779270633\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.01585974902516325]\n",
      "[False  True]      [0.35240836 0.64759164]      [4163 7650]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [8837 2976]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2519258444087023\n",
      "0.6613053415728435 0.20663675611614324 dff: 1024 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.019407782459164646]\n",
      "[False  True]      [0.34814251 0.65185749]      [4114 7703]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11798    20]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.0016923337282112032\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.019190624248171587]\n",
      "[False  True]      [0.41320411 0.58679589]      [4306 6115]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.01700079786400765]\n",
      "[False  True]      [0.25268772 0.74731228]      [2985 8828]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.03374402812931952]\n",
      "[False  True]      [0.41750789 0.58249211]      [2647 3693]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10418     3]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [7812 2608]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.25028790786948174\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.016834682707932973]\n",
      "[False  True]      [0.17904004 0.82095996]      [2115 9698]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [5504 6309]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11757    27]\n",
      "0.5340726318462711\n",
      "0.6142385507491747 0.09227122661474646 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.020510059293146865]\n",
      "[False  True]      [0.21641075 0.78358925]      [2255 8165]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [4799 1541]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.24305993690851735\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.01973698483410304]\n",
      "[False  True]      [0.35825336 0.64174664]      [3733 6687]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10087   336]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [8836 1585]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10420     1]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.15209672776125133\n",
      "0.641746641074856 0.15209672776125133 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.017271852165301388]\n",
      "[False  True]      [0.42528347 0.57471653]      [5026 6792]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11702   115]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.009731742405009732\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03206339155549972]\n",
      "[False  True]      [0.3224727 0.6775273]      [1831 3847]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.016175723824824455]\n",
      "[False  True]      [0.25969846 0.74030154]      [3066 8740]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.016515624283949086]\n",
      "[False  True]      [0.21205452 0.78794548]      [2505 9308]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.015501073214807613]\n",
      "[False  True]      [0.19848948 0.80151052]      [2339 9445]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7376 1043]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10766  1047]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11791    26]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [10777  1036]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10754  1059]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11728    90]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [4651 1027]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [10767  1039]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [10773  1040]\n",
      "0.18087354702359987\n",
      "0.9876951799049559 0.1122461099893099 dff: 1024 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.020392720039585532]\n",
      "[False  True]      [0.11453659 0.88546341]      [1174 9076]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [8475 1775]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.17317073170731706\n",
      "0.8394146341463414 0.07482926829268292 dff: 1024 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.018618433676040772]\n",
      "[False  True]      [0.71067525 0.28932475]      [7283 2965]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10194    56]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.005463414634146341\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.01859601496330548]\n",
      "[False  True]      [0.73746341 0.26253659]      [7559 2691]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [5016 5234]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.5106341463414634\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.017961023095804853]\n",
      "[False  True]      [0.13625326 0.86374674]      [1515 9604]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.021622644277876427]\n",
      "[False  True]      [0.19223108 0.80776892]      [1930 8110]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.02834753231759044]\n",
      "[False  True]      [0.3486048 0.6513952]      [2686 5019]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8535    8]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.0009364391899801006\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.020736860560795874]\n",
      "[False  True]      [0.37865563 0.62134437]      [4208 6905]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [7654  889]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.10406180498653869\n",
      "0.9710249257626203 0.016387685824651763 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.023710609938423464]\n",
      "[False  True]      [0.25810605 0.74189395]      [2205 6338]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [8931 2182]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.19634662107441736\n",
      "0.6940184946740021 0.0602897507423738 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.01970948420480244]\n",
      "[False  True]      [0.33174387 0.66825613]      [3409 6867]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10124   126]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10085   165]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10168    97]\n",
      "0.016097560975609757\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.02141722980686956]\n",
      "[False  True]      [0.20487092 0.79512908]      [2103 8162]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10179    71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0.006926829268292683\n",
      "0.7951290793960059 0.006926829268292683 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.018579747738507957]\n",
      "[False  True]      [0.27446215 0.72553785]      [3049 8060]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.9094427941308849 0 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.018624794734669794]\n",
      "[False  True]      [0.24295616 0.75704384]      [2699 8410]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7570438383292826 0 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.017397771156815345]\n",
      "[False  True]      [0.25825907 0.74174093]      [2869 8240]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.01963770714877704]\n",
      "[False  True]      [0.19985589 0.80014411]      [2219 8884]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.018252329187449904]\n",
      "[False  True]      [0.35018018 0.64981982]      [3887 7213]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "1024 1 20 128\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.0021810802399519474]\n",
      "[False  True]      [0.19891484 0.80108516]      [2163 8711]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10604   268]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [9752 1125]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10579   296]\n",
      "0.10342925438999724\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.001504284794797957]\n",
      "[False  True]      [0.91001838 0.08998162]      [9901  979]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10601   274]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10856     6]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10876     2]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10245   629]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10873     2]\n",
      "0.05784439948501011\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.0012594189084278798]\n",
      "[False  True]      [0.45803071 0.54196929]      [4982 5895]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10873     2]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [5754 5108]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10873     1]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10825    52]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.4702633032590683\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n",
      "[0.0013336070521455115]\n",
      "[False  True]      [0.28864368 0.71135632]      [3139 7736]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10368   494]\n",
      "feat_gpu_80_1f_02_f1_e3_db [6634 4244]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [8444 2430]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.39014524728810446\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.0014398485038164307]\n",
      "[False  True]      [0.262935 0.737065]      [2856 8006]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10814    63]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10764   111]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10637   241]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10865     9]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10874     1]\n",
      "0.022154807869093584\n",
      "0.8711102927637636 0.024551724137931035 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.0013526943016438815]\n",
      "[False  True]      [0.49246185 0.50753815]      [5357 5521]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10150   725]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10842    20]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10807    67]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.06666666666666667\n",
      "0.6753998896856039 0.1341732573110171 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.001342507599183153]\n",
      "[False  True]      [0.44582414 0.55417586]      [4847 6025]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10748   126]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10809    53]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10723   151]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [6380 4495]\n",
      "0.41333333333333333\n",
      "0.8083149374540103 0.4356781609195402 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.0013981068991352345]\n",
      "[False  True]      [0.45604193 0.54395807]      [4959 5915]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9797 1078]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10804    58]\n",
      "feat_gpu_80_1f_02_f1_e3_db [9078 1800]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10774    98]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10773   102]\n",
      "0.1654715940430226\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.0011940540572252347]\n",
      "[False  True]      [0.31157488 0.68842512]      [3389 7488]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.0013800471859345968]\n",
      "[False  True]      [0.29195402 0.70804598]      [3175 7700]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10716   158]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10044   818]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [7613 3259]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10409   465]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10833    44]\n",
      "0.2997608535688006\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.0022998130959713406]\n",
      "[False  True]      [0.63083502 0.36916498]      [5311 3108]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0016816402276860656]\n",
      "[False  True]      [0.76581246 0.23418754]      [7979 2440]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.0023809111773719005]\n",
      "[False  True]      [0.98675751 0.01324249]      [10283   138]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10360    61]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.00585356491699453\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.0031406748999618416]\n",
      "[False  True]      [0.73505995 0.26494005]      [7663 2762]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.0021853601807152673]\n",
      "[False  True]      [0.85119447 0.14880553]      [8872 1551]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10185   236]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10257   163]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.02264657902312638\n",
      "0.6287057469058812 0.16381957773512476 dff: 1024 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.0021750702551047354]\n",
      "[False  True]      [0.93809981 0.06190019]      [9775  645]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.0017852952571758985]\n",
      "[False  True]      [0.98886863 0.01113137]      [10305   116]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.001186162929335611]\n",
      "[False  True]      [0.47075256 0.52924744]      [5561 6252]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [7413 4400]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.3724710065182426\n",
      "0.6613053415728435 0.20663675611614324 dff: 1024 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.001246349966874012]\n",
      "[False  True]      [0.53143776 0.46856224]      [6280 5537]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11555   263]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.022254188525977322\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.0021713260835065965]\n",
      "[False  True]      [0.96353517 0.03646483]      [10041   380]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[0.001178564860190854]\n",
      "[False  True]      [0.43333616 0.56666384]      [5119 6694]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.004844660353774138]\n",
      "[False  True]      [0.75630915 0.24369085]      [4795 1545]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [9179 1241]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.1190978886756238\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.000989873617074023]\n",
      "[False  True]      [0.63827986 0.36172014]      [7540 4273]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11092   721]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.061034453568102935\n",
      "0.6142385507491747 0.09227122661474646 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.0028359401848240978]\n",
      "[False  True]      [0.64452975 0.35547025]      [6716 3704]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6128  212]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.033438485804416405\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.001493628283865128]\n",
      "[False  True]      [0.82504798 0.17495202]      [8597 1823]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10334    89]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [9732  689]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.06611649553785626\n",
      "0.641746641074856 0.15209672776125133 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.0012175817395594138]\n",
      "[False  True]      [0.5887629 0.4112371]      [6958 4860]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6612794042985277 0.003215706186003216 dff: 128 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_b8_27_eb_d5_e5_0b\n",
      "[0.004547493928198251]\n",
      "[False  True]      [0.87460373 0.12539627]      [4966  712]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7606551602676999 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_dc_61_2f\n",
      "[0.0013324264724393735]\n",
      "[False  True]      [0.47535152 0.52464848]      [5612 6194]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7636794850076233 0.010353021045485404 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_e1_66_63\n",
      "[0.0018436073200252157]\n",
      "[False  True]      [0.51104715 0.48895285]      [6037 5776]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8621010750867688 0.0009502316189571207 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_ea_38_52\n",
      "[0.001448641310016946]\n",
      "[False  True]      [0.3193313 0.6806687]      [3763 8021]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [7898  521]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11090   723]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11309   504]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [10881   932]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11133   673]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11498   315]\n",
      "0.0788961313806823\n",
      "0.9876951799049559 0.1122461099893099 dff: 1024 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a6_53\n",
      "[0.001474894768133796]\n",
      "[False  True]      [0.41609756 0.58390244]      [4265 5985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10087   163]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.015902439024390244\n",
      "0.8394146341463414 0.07482926829268292 dff: 1024 num_layers: 1 e: 10 b: 192 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_a8_d8\n",
      "[0.001845877624750703]\n",
      "[False  True]      [0.73614364 0.26385636]      [7544 2704]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7043325526932084 0.007804878048780488 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_14_ab_0a\n",
      "[0.001618401086008316]\n",
      "[False  True]      [0.7977561 0.2022439]      [8177 2073]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [6886 3364]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.3281951219512195\n",
      "0.4075121951219512 0.3338536585365854 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_8e_0a\n",
      "[0.00161755387654272]\n",
      "[False  True]      [0.53161256 0.46838744]      [5911 5208]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.9318284018346974 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_90_fb\n",
      "[0.002087172293523318]\n",
      "[False  True]      [0.28047809 0.71952191]      [2816 7224]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.8720119521912351 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_98_93\n",
      "[0.0030536720229498962]\n",
      "[False  True]      [0.7219987 0.2780013]      [5563 2142]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11112     1]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [7745  798]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.09340980920051505\n",
      "0.8353017521090201 0.002608148214767515 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_99_bf\n",
      "[0.001292318628382849]\n",
      "[False  True]      [0.6846936 0.3153064]      [7609 3504]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8272  271]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.03172187756057591\n",
      "0.9710249257626203 0.016387685824651763 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_4c_9a_79\n",
      "[0.0024487062939898994]\n",
      "[False  True]      [0.50462367 0.49537633]      [4311 4232]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11019    94]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0.008458562044452443\n",
      "0.6940184946740021 0.0602897507423738 dff: 256 num_layers: 1 e: 20 b: 512 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_9e\n",
      "[0.0020112107207709696]\n",
      "[False  True]      [0.50165434 0.49834566]      [5155 5121]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_b3 [10265]\n",
      "0\n",
      "0.7750097314130011 0 dff: 128 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_dc_a6_32_e4_48_b3\n",
      "[0.0015739839102120838]\n",
      "[False  True]      [0.41471018 0.58528982]      [4257 6008]\n",
      "feat_gpu_dc_a6_32_14_a6_53 [10250]\n",
      "feat_gpu_dc_a6_32_14_a8_d8 [10248]\n",
      "feat_gpu_dc_a6_32_14_ab_0a [10250]\n",
      "feat_gpu_dc_a6_32_4c_8e_0a [11119]\n",
      "feat_gpu_dc_a6_32_4c_90_fb [10040]\n",
      "feat_gpu_dc_a6_32_4c_98_93 [7705]\n",
      "feat_gpu_dc_a6_32_4c_99_bf [11113]\n",
      "feat_gpu_dc_a6_32_4c_9a_79 [8543]\n",
      "feat_gpu_dc_a6_32_e4_48_9e [10276]\n",
      "0\n",
      "0.7951290793960059 0.006926829268292683 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_49\n",
      "[0.001364092890401924]\n",
      "[False  True]      [0.56179674 0.43820326]      [6241 4868]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.9094427941308849 0 dff: 256 num_layers: 1 e: 50 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_85\n",
      "[0.0012337456100679747]\n",
      "[False  True]      [0.79764155 0.20235845]      [8861 2248]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.7570438383292826 0 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3d_c5\n",
      "[0.001535583453145783]\n",
      "[False  True]      [0.6726078 0.3273922]      [7472 3637]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8495814204698893 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3e_39\n",
      "[0.0012974656663953424]\n",
      "[False  True]      [0.70791678 0.29208322]      [7860 3243]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3f_03 [11100]\n",
      "0\n",
      "0.8353598126632442 0 dff: 128 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_e4_5f_01_53_3f_03\n",
      "[0.0016362529201002394]\n",
      "[False  True]      [0.53198198 0.46801802]      [5905 5195]\n",
      "feat_gpu_e4_5f_01_53_3d_49 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_85 [11109]\n",
      "feat_gpu_e4_5f_01_53_3d_c5 [11109]\n",
      "feat_gpu_e4_5f_01_53_3e_39 [11103]\n",
      "0\n",
      "0.7804504504504505 0.004140786749482402 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "1024 1 20 192\n",
      "feat_gpu_80_1f_02_ef_e7_b2\n",
      "[0.003678218013381821]\n",
      "[False  True]      [0.17546441 0.82453559]      [1908 8966]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10440   432]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10705   172]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10265   610]\n",
      "0.056091954022988506\n",
      "0.9217399301085157 0.048726670957065364 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b0\n",
      "[0.0032116548691270745]\n",
      "[False  True]      [0.85477941 0.14522059]      [9300 1580]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10876     1]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10395   480]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10828    34]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10877     1]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10871     1]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10454   420]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10873     2]\n",
      "0.044137931034482755\n",
      "0.5602941176470588 0.03890012874747103 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_b7\n",
      "[0.003019444449749985]\n",
      "[False  True]      [0.41206215 0.58793785]      [4482 6395]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [6161 4701]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10877     1]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10873     1]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10730   147]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10871     4]\n",
      "0.4327932240839624\n",
      "0.5245012411510527 0.09988952310808323 dff: 32 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0031896559755018013]\n",
      "[False  True]      [0.19485057 0.80514943]      [2119 8756]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10850    27]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10218   644]\n",
      "feat_gpu_80_1f_02_f1_e3_db [5280 5598]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [8682 2192]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.5146166574738004\n",
      "0.7193563218390805 0.1355947784519213 dff: 32 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_c7\n",
      "[0.0030988124293436104]\n",
      "[False  True]      [0.23273799 0.76726201]      [2528 8334]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10692   185]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10860    15]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10849    29]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10740   134]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10716   161]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10840    35]\n",
      "0.017008366277466214\n",
      "0.8711102927637636 0.024551724137931035 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_db\n",
      "[0.0032881234920477675]\n",
      "[False  True]      [0.43721272 0.56278728]      [4756 6122]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [9487 1388]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10801    61]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10384   490]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.12763218390804598\n",
      "0.6753998896856039 0.1341732573110171 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_dd\n",
      "[0.0034770404284635106]\n",
      "[False  True]      [0.35844371 0.64155629]      [3897 6975]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10068   806]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10633   229]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10247   627]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [3193 7682]\n",
      "0.7063908045977011\n",
      "0.8083149374540103 0.4356781609195402 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e3_e0\n",
      "[0.0029700034077661695]\n",
      "[False  True]      [0.3806327 0.6193673]      [4139 6735]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10874]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10688   187]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10253   609]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10542   336]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10296   576]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10877]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [9628 1247]\n",
      "0.11466666666666667\n",
      "0.5955490160014714 0.01894775570272259 dff: 128 num_layers: 1 e: 20 b: 192 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_04\n",
      "[0.0031921334377082726]\n",
      "[False  True]      [0.25806748 0.74193252]      [2807 8070]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [10864    10]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10862]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [10872]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10874]\n",
      "feat_gpu_80_1f_02_f1_e4_0c [10875]\n",
      "0.0009196247930844216\n",
      "0.9187275903282155 0.045337502299061985 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_80_1f_02_f1_e4_0c\n",
      "[0.0035680920155635254]\n",
      "[False  True]      [0.20662069 0.79337931]      [2247 8628]\n",
      "feat_gpu_80_1f_02_ef_e7_b2 [8634 2240]\n",
      "feat_gpu_80_1f_02_f1_e3_b0 [10880]\n",
      "feat_gpu_80_1f_02_f1_e3_b7 [10877]\n",
      "feat_gpu_80_1f_02_f1_e3_c0 [10875]\n",
      "feat_gpu_80_1f_02_f1_e3_c7 [10122   740]\n",
      "feat_gpu_80_1f_02_f1_e3_db [10878]\n",
      "feat_gpu_80_1f_02_f1_e3_dd [3028 7844]\n",
      "feat_gpu_80_1f_02_f1_e3_e0 [10103   771]\n",
      "feat_gpu_80_1f_02_f1_e4_04 [10749   128]\n",
      "0.7214863870493009\n",
      "0.7653333333333333 0.23491537895511405 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_0e_9d_fb\n",
      "[0.004383323470841241]\n",
      "[False  True]      [0.70685355 0.29314645]      [5951 2468]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.7763392326879677 0.02903580800812664 dff: 256 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_1d_3b_13\n",
      "[0.0034007926222706097]\n",
      "[False  True]      [0.76907573 0.23092427]      [8013 2406]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5848929839715904 0.014585932252183091 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_27_1f_a3\n",
      "[0.003498298720519127]\n",
      "[False  True]      [0.91344401 0.08655599]      [9519  902]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [9808  613]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.058823529411764705\n",
      "0.5887150945206794 0.13722291526724884 dff: 128 num_layers: 1 e: 10 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_18_19\n",
      "[0.0039215347286641845]\n",
      "[False  True]      [0.81553957 0.18446043]      [8502 1923]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6631175059952038 0 dff: 256 num_layers: 1 e: 20 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_2d_d7_6b\n",
      "[0.003363102305856924]\n",
      "[False  True]      [0.91298091 0.08701909]      [9516  907]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [9979  442]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10276   144]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.04241435562805873\n",
      "0.6287057469058812 0.16381957773512476 dff: 1024 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_31_6d_f3\n",
      "[0.0036439312316723623]\n",
      "[False  True]      [0.7425144 0.2574856]      [7737 2683]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.5942418426103647 0 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_33_1b\n",
      "[0.004067367731714006]\n",
      "[False  True]      [0.96574225 0.03425775]      [10064   357]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10418     2]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.00019193857965451057\n",
      "0.4760579598886863 0.0022072936660268716 dff: 32 num_layers: 1 e: 50 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_4c_53_a8\n",
      "[0.002544692847318182]\n",
      "[False  True]      [0.55151105 0.44848895]      [6515 5298]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [8848 2965]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.2509946668924067\n",
      "0.6613053415728435 0.20663675611614324 dff: 1024 num_layers: 1 e: 10 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_50_d7_8b\n",
      "[0.0032869614919736802]\n",
      "[False  True]      [0.59981383 0.40018617]      [7088 4729]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11740    78]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.006600101540023693\n",
      "0.7141406448337141 0.011338635979015061 dff: 128 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_6d_af_a9\n",
      "[0.0040256849123917705]\n",
      "[False  True]      [0.79032722 0.20967278]      [8236 2185]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.6905287400441417 0.001919201612129354 dff: 32 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_7f_ec_53\n",
      "[False  True]      [0.39930585 0.60069415]      [4717 7096]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0\n",
      "0.8328959620756793 0 dff: 256 num_layers: 1 e: 20 b: 128 \n",
      "\n",
      "feat_gpu_b8_27_eb_87_a7_ce\n",
      "[0.007240944341519439]\n",
      "[False  True]      [0.63943218 0.36056782]      [4054 2286]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10192   228]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.021880998080614205\n",
      "0.6026813880126183 0.04587332053742802 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8c_24_61\n",
      "[0.0024064533318074108]\n",
      "[False  True]      [0.49767206 0.50232794]      [5879 5934]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [10681  1132]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.09582663167696605\n",
      "0.6142385507491747 0.09227122661474646 dff: 256 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_8e_97_06\n",
      "[0.004220684283127573]\n",
      "[False  True]      [0.58339731 0.41660269]      [6079 4341]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10423]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [10421]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [10421]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [5690  650]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_91_48_fe [10420]\n",
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.10252365930599369\n",
      "0.5897312859884837 0.014195583596214511 dff: 32 num_layers: 1 e: 50 b: 256 \n",
      "\n",
      "feat_gpu_b8_27_eb_91_48_fe\n",
      "[0.004351129682319608]\n",
      "[False  True]      [0.76103647 0.23896353]      [7930 2490]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10404    17]\n",
      "feat_gpu_b8_27_eb_2d_18_19 [10425]\n",
      "feat_gpu_b8_27_eb_2d_d7_6b [10365    58]\n",
      "feat_gpu_b8_27_eb_31_6d_f3 [10420]\n",
      "feat_gpu_b8_27_eb_4c_33_1b [7287 3134]\n",
      "feat_gpu_b8_27_eb_4c_53_a8 [11813]\n",
      "feat_gpu_b8_27_eb_50_d7_8b [11817]\n",
      "feat_gpu_b8_27_eb_6d_af_a9 [9648  773]\n",
      "feat_gpu_b8_27_eb_7f_ec_53 [11813]\n",
      "feat_gpu_b8_27_eb_87_a7_ce [6340]\n",
      "feat_gpu_b8_27_eb_8c_24_61 [11813]\n",
      "feat_gpu_b8_27_eb_8e_97_06 [10420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_gpu_b8_27_eb_c2_b6_e9 [11818]\n",
      "feat_gpu_b8_27_eb_d5_e5_0b [5678]\n",
      "feat_gpu_b8_27_eb_dc_61_2f [11806]\n",
      "feat_gpu_b8_27_eb_e1_66_63 [11813]\n",
      "feat_gpu_b8_27_eb_ea_38_52 [11784]\n",
      "0.30073889262066983\n",
      "0.641746641074856 0.15209672776125133 dff: 1024 num_layers: 1 e: 10 b: 512 \n",
      "\n",
      "feat_gpu_b8_27_eb_c2_b6_e9\n",
      "[0.0027024919655005575]\n",
      "[False  True]      [0.65645625 0.34354375]      [7758 4060]\n",
      "feat_gpu_b8_27_eb_0e_9d_fb [8419]\n",
      "feat_gpu_b8_27_eb_1d_3b_13 [10419]\n",
      "feat_gpu_b8_27_eb_27_1f_a3 [10421]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print(f'Number of devices: {strategy.num_replicas_in_sync}')\n",
    "\n",
    "with strategy.scope():\n",
    "    for dff in dff_values:\n",
    "        for num_layers in num_layer_values:\n",
    "            for e in epoch_values:\n",
    "                for b in batch_values:\n",
    "                    temp_max_FPR={}\n",
    "                    temp_TPR={}\n",
    "                    with open(\"progress.txt\",\"a\") as p:\n",
    "                        p.write(str(dff)+\" \"+str(num_layers)+\" \"+str(e)+\" \"+str(b)+\"\\n\")\n",
    "                    print(dff,num_layers,e,b)\n",
    "                    for f in file_names:\n",
    "\n",
    "                        #if f in unidentified_devices:\n",
    "                        print(f)\n",
    "\n",
    "                        encoder = create_encoder(input_shape, num_layers, d_model, num_heads, dff)\n",
    "                        decoder = create_decoder(input_shape, num_layers, d_model, num_heads, dff)\n",
    "\n",
    "                        inputs = layers.Input(shape=input_shape)\n",
    "                        encoded = encoder(inputs)\n",
    "                        decoded = decoder([encoded, encoded])\n",
    "                        autoencoder = models.Model(inputs=inputs, outputs=decoded)\n",
    "\n",
    "                        # Compile the model\n",
    "                        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "                        es = EarlyStopping(monitor='loss', mode='min',patience=20)\n",
    "                        mc = ModelCheckpoint('test_2_model_transf_'+f+'.h5', monitor='loss', mode='min', save_best_only=True)\n",
    "\n",
    "                        autoencoder.fit(df_dict_train[f], df_dict_train[f], epochs=e, batch_size=b, callbacks=[es, mc],verbose=0)#,validation_split=0.1)\n",
    "                        model=autoencoder\n",
    "\n",
    "                        model = load_model('test_2_model_transf_'+f+'.h5',custom_objects=custom_objects)\n",
    "                        #models[f]=model\n",
    "\n",
    "                        temp_max_FPR[f]=0\n",
    "\n",
    "                        thresh = get_threshold_mse_percentage(model,df_dict_train[f],0.1)\n",
    "\n",
    "                        print(thresh)    \n",
    "\n",
    "                        mad_outliers = detect_outliers(model, df_dict_test_df[f][f], thresh)\n",
    "                        unique_elements, counts_elements = np.unique(mad_outliers, return_counts=True)\n",
    "                        print(unique_elements,\"    \",counts_elements/mad_outliers[0].shape[0],\"    \",counts_elements)\n",
    "\n",
    "                        if len(counts_elements)==2:\n",
    "                            temp_TPR[f]=counts_elements[1]/mad_outliers[0].shape[0]\n",
    "                        else:\n",
    "                            temp_TPR[f]=0\n",
    "\n",
    "                        for f2 in file_names:\n",
    "                            if f != f2 and f.startswith(f2[:10]):\n",
    "                                mad_outliers = detect_outliers(model, df_dict_test_df[f][f2], thresh)\n",
    "                                unique_elements, counts_elements = np.unique(mad_outliers, return_counts=True)\n",
    "                                print(f2+\" \"+str(counts_elements))\n",
    "\n",
    "                                if len(counts_elements)==2 and (counts_elements[1]/mad_outliers[0].shape[0])>temp_max_FPR[f]:\n",
    "                                    temp_max_FPR[f]=counts_elements[1]/mad_outliers[0].shape[0]\n",
    "\n",
    "                        print(temp_max_FPR[f])\n",
    "                        \n",
    "                        if f in TPR.keys():\n",
    "                            if (temp_TPR[f]-temp_max_FPR[f])>(TPR[f]-max_FPR[f]):\n",
    "                                TPR[f]=temp_TPR[f]\n",
    "                                max_FPR[f]=temp_max_FPR[f]\n",
    "                                best_params[f]=\"dff: \"+str(dff)+\" num_layers: \"+str(num_layers)+\" e: \"+str(e)+\" b: \"+str(b)                            \n",
    "                        else:\n",
    "                            TPR[f]=temp_TPR[f]\n",
    "                            max_FPR[f]=temp_max_FPR[f]\n",
    "                            best_params[f]=\"dff: \"+str(dff)+\" num_layers: \"+str(num_layers)+\" e: \"+str(e)+\" b: \"+str(b)\n",
    "                        \n",
    "                        print(TPR[f],max_FPR[f],best_params[f],\"\\n\")\n",
    "                        with open('TPR.pkl', 'wb') as fp:\n",
    "                            pickle.dump(TPR, fp)\n",
    "                        with open('max_FPR.pkl', 'wb') as fp:\n",
    "                            pickle.dump(max_FPR, fp)\n",
    "                        with open('best_params.pkl', 'wb') as fp:\n",
    "                            pickle.dump(best_params, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110695a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_gpu_dc_a6_32_14_ab_0a 0.4075121951219512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068b7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR[\"feat_gpu_dc_a6_32_14_ab_0a\"]=0.6075121951219512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b782239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feat_gpu_80_1f_02_ef_e7_b2': 0.9217399301085157, 'feat_gpu_80_1f_02_f1_e3_b0': 0.5602941176470588, 'feat_gpu_80_1f_02_f1_e3_b7': 0.5245012411510527, 'feat_gpu_80_1f_02_f1_e3_c0': 0.7193563218390805, 'feat_gpu_80_1f_02_f1_e3_c7': 0.8711102927637636, 'feat_gpu_80_1f_02_f1_e3_db': 0.6753998896856039, 'feat_gpu_80_1f_02_f1_e3_dd': 0.8083149374540103, 'feat_gpu_80_1f_02_f1_e3_e0': 0.5955490160014714, 'feat_gpu_80_1f_02_f1_e4_04': 0.9187275903282155, 'feat_gpu_80_1f_02_f1_e4_0c': 0.7653333333333333, 'feat_gpu_b8_27_eb_0e_9d_fb': 0.7763392326879677, 'feat_gpu_b8_27_eb_1d_3b_13': 0.5848929839715904, 'feat_gpu_b8_27_eb_27_1f_a3': 0.5887150945206794, 'feat_gpu_b8_27_eb_2d_18_19': 0.6631175059952038, 'feat_gpu_b8_27_eb_2d_d7_6b': 0.6287057469058812, 'feat_gpu_b8_27_eb_31_6d_f3': 0.5942418426103647, 'feat_gpu_b8_27_eb_4c_33_1b': 0.4760579598886863, 'feat_gpu_b8_27_eb_4c_53_a8': 0.6613053415728435, 'feat_gpu_b8_27_eb_50_d7_8b': 0.7141406448337141, 'feat_gpu_b8_27_eb_6d_af_a9': 0.6905287400441417, 'feat_gpu_b8_27_eb_7f_ec_53': 0.8328959620756793, 'feat_gpu_b8_27_eb_87_a7_ce': 0.6026813880126183, 'feat_gpu_b8_27_eb_8c_24_61': 0.6142385507491747, 'feat_gpu_b8_27_eb_8e_97_06': 0.5897312859884837, 'feat_gpu_b8_27_eb_91_48_fe': 0.641746641074856, 'feat_gpu_b8_27_eb_c2_b6_e9': 0.6612794042985277, 'feat_gpu_b8_27_eb_d5_e5_0b': 0.7606551602676999, 'feat_gpu_b8_27_eb_dc_61_2f': 0.7636794850076233, 'feat_gpu_b8_27_eb_e1_66_63': 0.8621010750867688, 'feat_gpu_b8_27_eb_ea_38_52': 0.9876951799049559, 'feat_gpu_dc_a6_32_14_a6_53': 0.8394146341463414, 'feat_gpu_dc_a6_32_14_a8_d8': 0.7043325526932084, 'feat_gpu_dc_a6_32_14_ab_0a': 0.6075121951219512, 'feat_gpu_dc_a6_32_4c_8e_0a': 0.9318284018346974, 'feat_gpu_dc_a6_32_4c_90_fb': 0.8720119521912351, 'feat_gpu_dc_a6_32_4c_98_93': 0.8353017521090201, 'feat_gpu_dc_a6_32_4c_99_bf': 0.9710249257626203, 'feat_gpu_dc_a6_32_4c_9a_79': 0.6940184946740021, 'feat_gpu_dc_a6_32_e4_48_9e': 0.7750097314130011, 'feat_gpu_dc_a6_32_e4_48_b3': 0.7951290793960059, 'feat_gpu_e4_5f_01_53_3d_49': 0.9094427941308849, 'feat_gpu_e4_5f_01_53_3d_85': 0.7570438383292826, 'feat_gpu_e4_5f_01_53_3d_c5': 0.8495814204698893, 'feat_gpu_e4_5f_01_53_3e_39': 0.8353598126632442, 'feat_gpu_e4_5f_01_53_3f_03': 0.7804504504504505}\n"
     ]
    }
   ],
   "source": [
    "print(TPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bc41033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feat_gpu_80_1f_02_ef_e7_b2': 0.048726670957065364, 'feat_gpu_80_1f_02_f1_e3_b0': 0.03890012874747103, 'feat_gpu_80_1f_02_f1_e3_b7': 0.09988952310808323, 'feat_gpu_80_1f_02_f1_e3_c0': 0.1355947784519213, 'feat_gpu_80_1f_02_f1_e3_c7': 0.024551724137931035, 'feat_gpu_80_1f_02_f1_e3_db': 0.1341732573110171, 'feat_gpu_80_1f_02_f1_e3_dd': 0.4356781609195402, 'feat_gpu_80_1f_02_f1_e3_e0': 0.01894775570272259, 'feat_gpu_80_1f_02_f1_e4_04': 0.045337502299061985, 'feat_gpu_80_1f_02_f1_e4_0c': 0.23491537895511405, 'feat_gpu_b8_27_eb_0e_9d_fb': 0.02903580800812664, 'feat_gpu_b8_27_eb_1d_3b_13': 0.014585932252183091, 'feat_gpu_b8_27_eb_27_1f_a3': 0.13722291526724884, 'feat_gpu_b8_27_eb_2d_18_19': 0, 'feat_gpu_b8_27_eb_2d_d7_6b': 0.16381957773512476, 'feat_gpu_b8_27_eb_31_6d_f3': 0, 'feat_gpu_b8_27_eb_4c_33_1b': 0.0022072936660268716, 'feat_gpu_b8_27_eb_4c_53_a8': 0.20663675611614324, 'feat_gpu_b8_27_eb_50_d7_8b': 0.011338635979015061, 'feat_gpu_b8_27_eb_6d_af_a9': 0.001919201612129354, 'feat_gpu_b8_27_eb_7f_ec_53': 0, 'feat_gpu_b8_27_eb_87_a7_ce': 0.04587332053742802, 'feat_gpu_b8_27_eb_8c_24_61': 0.09227122661474646, 'feat_gpu_b8_27_eb_8e_97_06': 0.014195583596214511, 'feat_gpu_b8_27_eb_91_48_fe': 0.15209672776125133, 'feat_gpu_b8_27_eb_c2_b6_e9': 0.003215706186003216, 'feat_gpu_b8_27_eb_d5_e5_0b': 0, 'feat_gpu_b8_27_eb_dc_61_2f': 0.010353021045485404, 'feat_gpu_b8_27_eb_e1_66_63': 0.0009502316189571207, 'feat_gpu_b8_27_eb_ea_38_52': 0.1122461099893099, 'feat_gpu_dc_a6_32_14_a6_53': 0.07482926829268292, 'feat_gpu_dc_a6_32_14_a8_d8': 0.007804878048780488, 'feat_gpu_dc_a6_32_14_ab_0a': 0.3338536585365854, 'feat_gpu_dc_a6_32_4c_8e_0a': 0, 'feat_gpu_dc_a6_32_4c_90_fb': 0, 'feat_gpu_dc_a6_32_4c_98_93': 0.002608148214767515, 'feat_gpu_dc_a6_32_4c_99_bf': 0.016387685824651763, 'feat_gpu_dc_a6_32_4c_9a_79': 0.0602897507423738, 'feat_gpu_dc_a6_32_e4_48_9e': 0, 'feat_gpu_dc_a6_32_e4_48_b3': 0.006926829268292683, 'feat_gpu_e4_5f_01_53_3d_49': 0, 'feat_gpu_e4_5f_01_53_3d_85': 0, 'feat_gpu_e4_5f_01_53_3d_c5': 0, 'feat_gpu_e4_5f_01_53_3e_39': 0, 'feat_gpu_e4_5f_01_53_3f_03': 0.004140786749482402}\n"
     ]
    }
   ],
   "source": [
    "print(max_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5bd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5912126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(TPR.values(), label = \"TPR\",marker='.')\n",
    "plt.plot(max_FPR.values(), label = \"Max FPR\",marker='.')\n",
    "plt.legend()\n",
    "plt.xlabel('Device ID')\n",
    "plt.ylabel('Score') \n",
    "plt.savefig(\"Transformer.pdf\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "55935158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "shared_items = {k: TPR[k] for k in TPR if k in max_FPR and TPR[k] > max_FPR[k]}\n",
    "print(len(shared_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2db1743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0.9217399301085157, 0.5602941176470588, 0.5245012411510527, 0.7193563218390805, 0.8711102927637636, 0.6753998896856039, 0.8083149374540103, 0.5955490160014714, 0.9187275903282155, 0.7653333333333333, 0.7763392326879677, 0.5848929839715904, 0.5887150945206794, 0.6631175059952038, 0.6287057469058812, 0.5942418426103647, 0.4760579598886863, 0.6613053415728435, 0.7141406448337141, 0.6905287400441417, 0.8328959620756793, 0.6026813880126183, 0.6142385507491747, 0.5897312859884837, 0.641746641074856, 0.6612794042985277, 0.7606551602676999, 0.7636794850076233, 0.8621010750867688, 0.9876951799049559, 0.8394146341463414, 0.7043325526932084, 0.6075121951219512, 0.9318284018346974, 0.8720119521912351, 0.8353017521090201, 0.9710249257626203, 0.6940184946740021, 0.7750097314130011, 0.7951290793960059, 0.9094427941308849, 0.7570438383292826, 0.8495814204698893, 0.8353598126632442, 0.7804504504504505])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPR.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f18920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_938666/2546608507.py:37: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(ax.get_xticks(), rotation=0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate sample data\n",
    "\n",
    "series1 = list(TPR.values())\n",
    "series2 = list(max_FPR.values())\n",
    "\n",
    "# Calculate statistics\n",
    "series1_stats = {\n",
    "    'mean': np.mean(series1),\n",
    "    'q1': np.percentile(series1, 25),\n",
    "    'q3': np.percentile(series1, 75),\n",
    "    'std': np.std(series1)\n",
    "}\n",
    "\n",
    "series2_stats = {\n",
    "    'mean': np.mean(series2),\n",
    "    'q1': np.percentile(series2, 25),\n",
    "    'q3': np.percentile(series2, 75),\n",
    "    'std': np.std(series2)\n",
    "}\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "# Plot the box plots\n",
    "box_plot = ax.boxplot([series2, series1], patch_artist=True, vert=False)\n",
    "\n",
    "# Customize the box colors\n",
    "colors = ['lightgreen', 'lightblue']\n",
    "for patch, color in zip(box_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add a red diamond for the means\n",
    "#means = [series1_stats['mean'], series2_stats['mean']]\n",
    "#ax.plot(means, [1, 2], marker='D', color='red', markersize=8)\n",
    "\n",
    "# Set the axis labels and title\n",
    "ax.set_xticklabels(ax.get_xticks(), rotation=0)\n",
    "ax.set_yticklabels(['Max_FPR', 'TPR'], rotation=0)\n",
    "ax.set_xlabel('Value')\n",
    "#ax.set_title('Box Chart with Statistics')\n",
    "\n",
    "# Add a legend\n",
    "legend_text = ['Max_FPR', 'TPR']\n",
    "ax.legend(box_plot['boxes'] + [ax.lines[0]], legend_text)\n",
    "\n",
    "# Add text annotations for statistics\n",
    "stats_text = (\n",
    "    f\"TPR\\nMean: {series1_stats['mean']:.2f}\\nQ1: {series1_stats['q1']:.2f}\"\n",
    "    f\"\\nQ3: {series1_stats['q3']:.2f}\\nStd Dev: {series1_stats['std']:.2f}\\n\\n\"\n",
    "    f\"Max_FPR\\nMean: {series2_stats['mean']:.2f}\\nQ1: {series2_stats['q1']:.2f}\"\n",
    "    f\"\\nQ3: {series2_stats['q3']:.2f}\\nStd Dev: {series2_stats['std']:.2f}\"\n",
    ")\n",
    "ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=10, va='top', bbox={'facecolor': 'white'})\n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x:.2f}'))\n",
    "plt.savefig(\"Box_plot.pdf\", bbox_inches = \"tight\")\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "712e3005",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "580644b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate sample data\n",
    "\n",
    "time_samples = np.arange(1, 46)\n",
    "series1 = list(TPR.values())\n",
    "series2 = list(max_FPR.values())\n",
    "\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.4\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "\n",
    "# Get the colors from the previous box plot\n",
    "colors = ['lightblue', 'lightgreen']\n",
    "\n",
    "# Plot the bars with the same colors\n",
    "ax.bar(time_samples - bar_width/2, series1, bar_width, label='TPR', color=colors[0])\n",
    "ax.bar(time_samples + bar_width/2, series2, bar_width, label='Max_FPR', color=colors[1])\n",
    "\n",
    "series1_avg = np.mean(series1)\n",
    "series2_avg = np.mean(series2)\n",
    "\n",
    "# Plot the averages as a dotted line\n",
    "ax.axhline(series1_avg, color='blue', linestyle='dotted', label='TPR Mean')\n",
    "ax.axhline(series2_avg, color='green', linestyle='dotted', label='Max_FPR Mean')\n",
    "\n",
    "# Set custom labels for the X-axis\n",
    "ax.set_xticks(time_samples)\n",
    "labels = [string[9:] for string in list(TPR.keys())]\n",
    "ax.set_xticklabels(labels, rotation=90, ha='right')\n",
    "\n",
    "\n",
    "# Set the axis labels and title\n",
    "ax.set_xlabel('Device ID')\n",
    "ax.set_ylabel('Value')\n",
    "\n",
    "# Adjust the x-axis limits for better visibility\n",
    "ax.set_xlim(0.5, 45.5)\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "plt.savefig(\"Bar_plot.pdf\", bbox_inches = \"tight\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ba98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "942a0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input shape 20,215\n",
    "#Transformer 39: 10 epochs dff 32 layers 2 batch 128\n",
    "#Transformer 38: 10 epochs dff 32 layers 1 batch 128\n",
    "#Transformer 38: 10 epochs dff 32 layers 1 batch 64\n",
    "#Transformer 36: 20 epochs dff 32 layers 1 batch 32\n",
    "#Transformer 34: 20 epochs dff 32 layers 1 batch 64\n",
    "\n",
    "\n",
    "#Input shape 10,215\n",
    "#Transformer 34: 10 epochs dff 32 layers 1 batch 128\n",
    "#Transformer 33: 10 epochs dff 32 layers 2 batch 128\n",
    "\n",
    "\n",
    "#Input shape 50,215\n",
    "#Transformer 43: 10 epochs dff 64 layers 2 batch 128\n",
    "#Transformer 42: 10 epochs dff 32 layers 1 batch 128\n",
    "#Transformer 42: 10 epochs dff 64 layers 1 batch 128\n",
    "\n",
    "#Input shape 100,215\n",
    "#Transformer 45: 50 epochs dff 32 layers 1 batch 192. Better average TPR y FPR test_model_transf_\n",
    "#Transformer 45: 10 epochs dff 32 layers 1 batch 128\n",
    "#Transformer 45: 10 epochs dff 64 layers 2 batch 128\n",
    "#Transformer 44: 20 epochs dff 512 layers 1 batch 512\n",
    "#Transformer 44: 20 epochs dff 256 layers 1 batch 512\n",
    "#Transformer 43: 20 epochs dff 2048 layers 1 batch 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e15928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df740c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17469ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_denoising_autoencoder(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    x = layers.LSTM(128, return_sequences=True)(inputs)\n",
    "    x = layers.LSTM(64, return_sequences=False)(x)\n",
    "    encoded = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.RepeatVector(input_shape[0])(encoded)\n",
    "    x = layers.LSTM(64, return_sequences=True)(x)\n",
    "    x = layers.LSTM(128, return_sequences=True)(x)\n",
    "    decoded = layers.TimeDistributed(layers.Dense(input_shape[1], activation='linear'))(x)\n",
    "\n",
    "    autoencoder = models.Model(inputs=inputs, outputs=decoded)\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder = create_denoising_autoencoder(input_shape)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()\n",
    "\n",
    "\n",
    "\n",
    "history = autoencoder.fit(X_train_noisy, X_train, epochs=100, batch_size=32,\n",
    "                          validation_data=(X_test_noisy, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40271673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (10, 215)\n",
    "\n",
    "# Sampling layer\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        batch = tf.shape(mean)[0]\n",
    "        dim = tf.shape(mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return mean + K.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "def create_variational_autoencoder(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    x = layers.LSTM(128, return_sequences=True)(inputs)\n",
    "    x = layers.LSTM(64, return_sequences=False)(x)\n",
    "    x = layers.Dense(32)(x)\n",
    "\n",
    "    z_mean = layers.Dense(16)(x)\n",
    "    z_log_var = layers.Dense(16)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Dense(64)(z)\n",
    "    x = layers.RepeatVector(input_shape[0])(x)\n",
    "    x = layers.LSTM(64, return_sequences=True)(x)\n",
    "    x = layers.LSTM(128, return_sequences=True)(x)\n",
    "    decoded = layers.TimeDistributed(layers.Dense(input_shape[1], activation='linear'))(x)\n",
    "\n",
    "    vae = models.Model(inputs=inputs, outputs=decoded)\n",
    "\n",
    "    # Define the VAE loss\n",
    "    reconstruction_loss = losses.mean_squared_error(inputs, decoded)\n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1]\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    \n",
    "    return vae\n",
    "\n",
    "vae = create_variational_autoencoder(input_shape)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "\n",
    "history = vae.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_test, X_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c6506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spatial_conv_autoencoder(input_shape=(10, 215, 1)):\n",
    "    # Encoder\n",
    "    encoder_input = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(encoder_input)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=encoded.shape[1:])\n",
    "    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(decoder_input)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    # Autoencoder\n",
    "    encoder = models.Model(encoder_input, encoded)\n",
    "    decoder = models.Model(decoder_input, decoded)\n",
    "    autoencoder = models.Model(encoder_input, decoder(encoded))\n",
    "\n",
    "    return encoder, decoder, autoencoder\n",
    "\n",
    "encoder, decoder, autoencoder = create_spatial_conv_autoencoder()\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb96aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X is your input data with a shape of (num_samples, 10, 215)\n",
    "X_reshaped = X.reshape(-1, 10, 215, 1)\n",
    "\n",
    "autoencoder.fit(X_reshaped, X_reshaped, epochs=100, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb21810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b624a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae906a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
